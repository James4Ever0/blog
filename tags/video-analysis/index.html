<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>video analysis | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">video analysis</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-07-10 </div>
			<div class="article-title"><a href="/blog/2022/07/10/8c6377e8-8e0c-4049-9a7c-fa214745dc92/" title="This article highlights discussions on resources for creating video effects, transitions, and shot detection tools, including slideshow creators and AI-powered software.">Video Effects Transitions</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>slideshows:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/gre/diaporama">https://github.com/gre/diaporama</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/h2non/videoshow">https://github.com/h2non/videoshow</a></p>
<p>after effects like video effects</p>
<p><a target="_blank" rel="noopener" href="https://github.com/NatronGitHub/Natron">https://github.com/NatronGitHub/Natron</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/brianchirls/Seriously.js">https://github.com/brianchirls/Seriously.js</a></p>
<p>video ai transition tool using pose estimation</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jungdj/AI-Effects">https://github.com/jungdj/AI-Effects</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/IronSpiderMan/VideoSpecialEffects">https://github.com/IronSpiderMan/VideoSpecialEffects</a></p>
<p>video transitions:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/advplyr/img2vid">https://github.com/advplyr/img2vid</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/ice45571/video-transition">https://github.com/ice45571/video-transition</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/povdocs/video-transitions">https://github.com/povdocs/video-transitions</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/transitive-bullshit/ffmpeg-concat">https://github.com/transitive-bullshit/ffmpeg-concat</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/transitive-bullshit/ffmpeg-gl-transition">https://github.com/transitive-bullshit/ffmpeg-gl-transition</a></p>
<p>shot detect key frame saving:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/yu239-zz/shotdetect">https://github.com/yu239-zz/shotdetect</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/AnyiRao/ShotDetection">https://github.com/AnyiRao/ShotDetection</a></p>

	
	</div>
  <a type="button" href="/blog/2022/07/10/8c6377e8-8e0c-4049-9a7c-fa214745dc92/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-06-13 </div>
			<div class="article-title"><a href="/blog/2022/06/13/b2e4e778-9f36-4ea8-815e-324e3fc41364/" title="This article delves into the difficulties of detecting picture-in-picture (PiP) videos, a common technique used in generating fake content. It highlights a Chinese patent related to PiP detection and an international research paper that explores this topic.">Video Picture In Picture Detection</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>视频画中画是流行的伪原创方法 但是检测很难 同时加大了二次利用的难度（或许可以再加一层画中画？？）</p>
<p>目前找到了一个国内画中画检测专利，以及国外画中画检测论文</p>

	
	</div>
  <a type="button" href="/blog/2022/06/13/b2e4e778-9f36-4ea8-815e-324e3fc41364/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-31 </div>
			<div class="article-title"><a href="/blog/2022/05/31/bf760350-ca1d-4029-ae38-368cad3d1cc4/" title="The text explores Optical Flow, a technique used in computer vision to estimate motion between frames of video sequences. It highlights &#39;flownet&#39; by NVIDIA, an optical flow SDK compatible with most Turing GPUs but excluding GTX1650(tu117). Additionally, it introduces mmflow from OpenMMLab, available at the provided link.">Optical Flow</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>flownet nvidia</p>
<p>nvidia optical flow sdk supports all turing gpus (like gtx1660) and above except for gtx1650(tu117).</p>
<p>mmflow from openmmlab:</p>
<p><a target="_blank" rel="noopener" href="https://mmflow.readthedocs.io/en/latest/">https://mmflow.readthedocs.io/en/latest/</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/31/bf760350-ca1d-4029-ae38-368cad3d1cc4/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-29 </div>
			<div class="article-title"><a href="/blog/2022/05/29/d36d0103-e7ec-4681-ae05-55c10b1d84a9/" title="This article offers a compilation of resources for facial expression detection, including GitHub repositories, deep learning models, and a Python library. These tools can be utilized to accomplish tasks like identifying emotions, detecting smiles, and analyzing facial expressions.">Facial Expression Detector</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://github.com/MauryaRitesh/Facial-Expression-Detection">https://github.com/MauryaRitesh/Facial-Expression-Detection</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/valterlucena/facial-expression-detector">https://github.com/valterlucena/facial-expression-detector</a></p>
<p>deepface:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/serengil/deepface">https://github.com/serengil/deepface</a></p>
<p>cnn based facial expression recognizer:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch/issues">https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch/issues</a></p>
<p>predict human emotion:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/thoughtworksarts/EmoPy">https://github.com/thoughtworksarts/EmoPy</a></p>
<p>facial expression recognization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/phamquiluan/ResidualMaskingNetwork">https://github.com/phamquiluan/ResidualMaskingNetwork</a></p>
<p>smile detection using opencv:</p>
<p><a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/python-smile-detection-using-opencv/">https://www.geeksforgeeks.org/python-smile-detection-using-opencv/</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/29/d36d0103-e7ec-4681-ae05-55c10b1d84a9/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-29 </div>
			<div class="article-title"><a href="/blog/2022/05/29/0a0e6520-c166-4e30-819f-b9705c059350/" title="NeuralDiff is a Pytorch-based solution designed to differentiate between actors and objects in 3D videos captured from an egocentric viewpoint. This implementation leverages advanced neural network techniques to accurately identify and categorize the elements present within such videos.">Neuraldiff: Discriminate Actor And Objects In Video</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>Neuraldiff:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/dichotomies/NeuralDiff?ref=pythonawesome.com">https://github.com/dichotomies/NeuralDiff?ref=pythonawesome.com</a></p>
<p><a target="_blank" rel="noopener" href="https://pythonawesome.com/official-pytorch-implementation-of-neuraldiff-segmenting-3d-objects-that-move-in-egocentric-videos/">https://pythonawesome.com/official-pytorch-implementation-of-neuraldiff-segmenting-3d-objects-that-move-in-egocentric-videos/</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/29/0a0e6520-c166-4e30-819f-b9705c059350/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-05 </div>
			<div class="article-title"><a href="/blog/2022/05/05/4270a682-c3e5-4e98-96f5-a8ada556dabd/" title="This passage explores various video processing tools such as Fastai/PyTorch, OpenNLPLab, MasterBin-IIAU, and PaddlePaddle. These tools are utilized for tasks including image translation, object segmentation, tracking, action recognition, and generating descriptive information.">Video Database</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="Video-Database-For-Video-Generation"><a href="#Video-Database-For-Video-Generation" class="headerlink" title="Video Database For Video Generation"></a>Video Database For Video Generation</h1><p>A fastai&#x2F;PyTorch package for unpaired image-to-image translation.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/tmabraham/UPIT?auto_subscribed=false&email_source=explore">https://github.com/tmabraham/UPIT?auto_subscribed=false&amp;email_source=explore</a></p>
<p>视听分割 视频注意力机制</p>
<p>only segment video objects that make sounds, video&#x2F;audio combined segmentation:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/OpenNLPLab/AVSBench">https://github.com/OpenNLPLab/AVSBench</a></p>
<p>video object tracking and segmentation unified framework:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/MasterBin-IIAU/Unicorn">https://github.com/MasterBin-IIAU/Unicorn</a></p>
<p>video object segmentation handle long video with ease:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/hkchengrex/XMem">https://github.com/hkchengrex/XMem</a></p>
<p>when removing video watermarks, remember to ease in&#x2F;out. that is said, do not stop blurring immediately after the end mark. instead, extend the blur time and decrease blur level incrementally. also, the blur ease-in is needed for the start mark, blur ahead of the start mark and ease in incrementally.</p>
<p>descriptive information generation from video&#x2F;image:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/BAAI-WuDao/CogView">https://github.com/BAAI-WuDao/CogView</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/BAAI-WuDao/BriVL">https://github.com/BAAI-WuDao/BriVL</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/install.md">https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/install.md</a></p>
<p>video understanding&#x2F;captioning:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/rohit-gupta/Video2Language">https://github.com/rohit-gupta/Video2Language</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/byeongjokim/Automatic-Baseball-Commentary-Generation-Using-DeepLearning">https://github.com/byeongjokim/Automatic-Baseball-Commentary-Generation-Using-DeepLearning</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shhdSU/Image_Captioning_DeepLearning">https://github.com/shhdSU/Image_Captioning_DeepLearning</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/jayleicn/recurrent-transformer">https://github.com/jayleicn/recurrent-transformer</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/terry-r123/Awesome-Captioning">https://github.com/terry-r123/Awesome-Captioning</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/vijayvee/video-captioning">https://github.com/vijayvee/video-captioning</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/scopeInfinity/Video2Description">https://github.com/scopeInfinity/Video2Description</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/xiadingZ/video-caption.pytorch">https://github.com/xiadingZ/video-caption.pytorch</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/YehLi/xmodaler">https://github.com/YehLi/xmodaler</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/sujiongming/awesome-video-understanding">https://github.com/sujiongming/awesome-video-understanding</a></p>
<p>action recognition:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/temporal-shift-module">https://github.com/mit-han-lab/temporal-shift-module</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/yjxiong/temporal-segment-networks">https://github.com/yjxiong/temporal-segment-networks</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/yjxiong/tsn-pytorch">https://github.com/yjxiong/tsn-pytorch</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmaction">https://github.com/open-mmlab/mmaction</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/jinwchoi/awesome-action-recognition">https://github.com/jinwchoi/awesome-action-recognition</a></p>
<p>The data remaining only have texts, danmaku, likes, titles, intros, comments, tags, image&#x2F;video analysis results(short description). You can only generate video from generated metadata or given rules. Find similar words, similar danmaku, similar features, comments or the inverse, according to the selected topic and main idea.</p>
<p>Analyze video when downloaded, mark its highlights, analyze texts and danmaku. Get video segments and audio segments.</p>
<p>Collect pictures&#x2F;videos with given rules, namely finding the head of somebody, with how many likes, keywords.</p>
<p>Split audio and grab the main speaker. clone the voice and perhaps changes the gender.</p>
<p>Split video and do human&#x2F;image segmentation if human&#x2F;target is found. put it onto another human&#x2F;target’s background masking the original human, with similar areas and movements.</p>
<p>Analyze video with off-topic(offline) and of-topic(online) sources.</p>
<p>Remove watermark according to username.</p>
<p>Generate danmaku and generate video accordingly. Generate texts and generate video accordingly. Doing faceswap, talking head and human&#x2F;image segmentation accordingly.</p>

	
	</div>
  <a type="button" href="/blog/2022/05/05/4270a682-c3e5-4e98-96f5-a8ada556dabd/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-04-21 </div>
			<div class="article-title"><a href="/blog/2022/04/21/72d65a7d-5c77-44d9-9e51-77796f0f25c8/" title="This article discusses the use of MMDetection for creating 3D avatars with accurate human pose detection. It provides detailed explanations and GitHub resources to help readers implement this technique effectively.">Mmdetection And Mmd Dancing</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>3d 虚拟形象动作生成 视频生成 虚拟偶像 Vtuber:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/xianfei/SysMocap">https://github.com/xianfei/SysMocap</a></p>
<p>human pose detection:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/VideoPose3D">https://github.com/facebookresearch/VideoPose3D</a></p>
<p>opengl recording:</p>
<p><a target="_blank" rel="noopener" href="https://lencerf.github.io/post/2019-09-21-save-the-opengl-rendering-to-image-file/">https://lencerf.github.io/post/2019-09-21-save-the-opengl-rendering-to-image-file/</a></p>
<p><a target="_blank" rel="noopener" href="http://www.songho.ca/opengl/gl_pbo.html#pack">http://www.songho.ca/opengl/gl_pbo.html#pack</a></p>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/7634966/save-opengl-rendering-to-video">https://stackoverflow.com/questions/7634966/save-opengl-rendering-to-video</a></p>
<p><a target="_blank" rel="noopener" href="https://www.codeproject.com/articles/15941/recording-directx-and-opengl-rendered-animations">https://www.codeproject.com/articles/15941/recording-directx-and-opengl-rendered-animations</a></p>
<p><a target="_blank" rel="noopener" href="https://www.glfw.org/documentation.html">https://www.glfw.org/documentation.html</a></p>
<p>download expose models:</p>
<p><a target="_blank" rel="noopener" href="https://expose.is.tue.mpg.de/downloads">https://expose.is.tue.mpg.de/downloads</a></p>
<p>smpl-x model download:</p>
<p><a target="_blank" rel="noopener" href="https://smpl-x.is.tue.mpg.de/download.php">https://smpl-x.is.tue.mpg.de/download.php</a></p>
<p>model zoo:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Zhongdao/Towards-Realtime-MOT/blob/master/DATASET_ZOO.md">https://github.com/Zhongdao/Towards-Realtime-MOT/blob/master/DATASET_ZOO.md</a></p>
<p>mmd auto tracking:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/errno-mmd/mmdmatic/blob/master/setup.bat">https://github.com/errno-mmd/mmdmatic/blob/master/setup.bat</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/miu200521358/expose_mmd">https://github.com/miu200521358/expose_mmd</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/miu200521358/AlphaPose-MMD">https://github.com/miu200521358/AlphaPose-MMD</a></p>
<p>smplx expose alternative body tracker:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/vchoutas/smplx">https://github.com/vchoutas/smplx</a></p>
<p>face tracking:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Aditya-Khadilkar/Face-tracking-with-Anime-characters">https://github.com/Aditya-Khadilkar/Face-tracking-with-Anime-characters</a></p>
<p>anime face detector:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/nagadomi/lbpcascade_animeface">https://github.com/nagadomi/lbpcascade_animeface</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/qhgz2013/anime-face-detector">https://github.com/qhgz2013/anime-face-detector</a></p>
<p>anime facial features:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/pranau97/anime-detection">https://github.com/pranau97/anime-detection</a></p>
<p>repair anime images:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/youyuge34/Anime-InPainting">https://github.com/youyuge34/Anime-InPainting</a></p>
<p>paint manga from sketch (with color blocks):</p>
<p><a target="_blank" rel="noopener" href="https://github.com/youyuge34/PI-REC">https://github.com/youyuge34/PI-REC</a></p>
<p>if we can re-trace the action&#x2F;expression done by vtubers, we can monetize those “highlight cuts”.</p>
<p>you can firstly find points in datasets and then generate mmd videos, and then create trainset. you can also generate pose from raw video and then create dataset.</p>
<p>found occasionally when browsing MMD, but found this with so many stars, which is an instance detection&#x2F;segmentation library.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmdetection">https://github.com/open-mmlab/mmdetection</a></p>
<p>while rendering mmd can be done with mmd viewer like <a target="_blank" rel="noopener" href="https://github.com/benikabocha/saba">https://github.com/benikabocha/saba</a> or could use renderer like blender or unity. we must bake physics before dancing.</p>
<p>found other dedicated renderer for mmd, with bullet physics:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jinfagang/mmc">https://github.com/jinfagang/mmc</a></p>
<p>found interesting repo of poetry composing:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jinfagang/tensorflow_poems">https://github.com/jinfagang/tensorflow_poems</a></p>
<p>mediapipe&#x2F;paddlevideo alike:</p>
<p><a target="_blank" rel="noopener" href="https://pypi.org/project/alfred-py/">https://pypi.org/project/alfred-py/</a></p>
<p>three.js has multiple loaders:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mrdoob/three.js/tree/dev/examples/js/loaders">https://github.com/mrdoob/three.js/tree/dev/examples/js/loaders</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/hanakla/three-mmd-loader">https://github.com/hanakla/three-mmd-loader</a></p>
<p>render MMD using saba lib:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/WLiangJun/MMD-Desktop-mascot">https://github.com/WLiangJun/MMD-Desktop-mascot</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/miu200521358/expose_mmd/fork">https://github.com/miu200521358/expose_mmd/fork</a></p>
<p>music based dance:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/DeepVTuber/DanceNet3D">https://github.com/DeepVTuber/DanceNet3D</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/ColbyZhuang/music2dance_DanceNet">https://github.com/ColbyZhuang/music2dance_DanceNet</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/caijianfei/Music2Dance">https://github.com/caijianfei/Music2Dance</a></p>
<p>characters:</p>
<p><a target="_blank" rel="noopener" href="https://www.mixamo.com/#/?page=1&type=Character">https://www.mixamo.com/#/?page=1&amp;type=Character</a></p>

	
	</div>
  <a type="button" href="/blog/2022/04/21/72d65a7d-5c77-44d9-9e51-77796f0f25c8/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-04-05 </div>
			<div class="article-title"><a href="/blog/2022/04/05/94bb28e3-8296-4cda-bde5-0fd0da8b7646/" title="This article explores the application of fall detection technology in media filtering, specifically focusing on selecting falling videos for entertainment. The technique utilizes human pose classification to identify suitable content.">Fall Detection Can Be Used For Media Filtering</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>we can select falling videos collection for fun.</p>
<p>it is based on human pose classification.</p>

	
	</div>
  <a type="button" href="/blog/2022/04/05/94bb28e3-8296-4cda-bde5-0fd0da8b7646/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2023 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>