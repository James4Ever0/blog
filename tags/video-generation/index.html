<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>video generation | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">video generation</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2024-03-10 </div>
			<div class="article-title"><a href="/blog/2024/03/10/593f71cb-ce66-4236-85f1-4256bf2b9f0a/" title="This article explores the advancements in AI-assisted content creation, including video generation, voice cloning, and upscaling/interpolation tools. Additionally, it delves into AI-powered content restoration techniques for image and video processing, game optimization, screen resolution adjustment, prediction models, recommendation engines, and image editing.">Ai Assisted Content Creation, Gameplay Video Recording, Trending Topics</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>code to video</p>
<p><a target="_blank" rel="noopener" href="https://github.com/redotvideo/revideo">https://github.com/redotvideo/revideo</a></p>
<hr>
<p>fishaudio voice cloning</p>
<p><a target="_blank" rel="noopener" href="https://github.com/adithya-s-k/omniparse">omniparse</a> data serialization</p>
<hr>
<p>Video understanding and video embedding can be achieved with ViViT (in huggingface).</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv33613833/">Video generation agent tutorial</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/harry0703/MoneyPrinterTurbo">MoneyPrinterTurbo</a></p>
<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/dvlab-research/MGM">Mini Gemini</a></p>
<hr>
<p>Use <a target="_blank" rel="noopener" href="https://github.com/mafiosnik777/enhancr">enhancr</a> for frame interpolation, super resolution and scaling. The pro version contains faster models.</p>
<p>The app is built using <a target="_blank" rel="noopener" href="https://www.electronforge.io/config/configuration">electron forge</a>.</p>
<p>Interpolation gets worse with higher resolution, that’s why I wouldn’t upscale first.</p>
<p>enhancr is built upon the following models:</p>
<h2 id="Interpolation"><a href="#Interpolation" class="headerlink" title="Interpolation"></a>Interpolation</h2><blockquote>
<p><strong>RIFE (NCNN)</strong> - <a target="_blank" rel="noopener" href="https://github.com/megvii-research">megvii-research</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/megvii-research/ECCV2022-RIFE">ECCV2022-RIFE</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/styler00dollar">styler00dollar</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/styler00dollar/VapourSynth-RIFE-NCNN-Vulkan">VapourSynth-RIFE-NCNN-Vulkan</a></strong></p>
</blockquote>
<blockquote>
<p><strong>RIFE (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/megvii-research">megvii-research</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/megvii-research/ECCV2022-RIFE">ECCV2022-RIFE</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong> &amp; <a target="_blank" rel="noopener" href="https://github.com/styler00dollar">styler00dollar</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/styler00dollar/VSGAN-tensorrt-docker">VSGAN-tensorrt-docker</a></strong></p>
</blockquote>
<blockquote>
<p><strong>GMFSS - Union (PyTorch&#x2F;TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/98mxr">98mxr</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/98mxr/GMFSS_union">GMFSS_Union</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/HolyWu">HolyWu</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/HolyWu/vs-gmfss_union">vs-gmfss_union</a></strong></p>
</blockquote>
<blockquote>
<p><strong>GMFSS - Fortuna (PyTorch&#x2F;TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/98mxr">98mxr</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/98mxr/GMFSS_Fortuna">GMFSS_Fortuna</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/HolyWu">HolyWu</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/HolyWu/vs-gmfss_fortuna">vs-gmfss_fortuna</a></strong></p>
</blockquote>
<blockquote>
<p><strong>CAIN (NCNN)</strong> - <a target="_blank" rel="noopener" href="https://github.com/myungsub">myungsub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/myungsub/CAIN">CAIN</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/mafiosnik777">mafiosnik</a>&#x2F;<strong>vsynth-cain-NCNN-vulkan</strong> (unreleased)</p>
</blockquote>
<blockquote>
<p><strong>CAIN (DirectML)</strong> - <a target="_blank" rel="noopener" href="https://github.com/myungsub">myungsub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/myungsub/CAIN">CAIN</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>CAIN (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/myungsub">myungsub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/myungsub/CAIN">CAIN</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/HubertSotnowski">HubertSotnowski</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/HubertSotnowski/cain-TensorRT">cain-TensorRT</a></strong></p>
</blockquote>
<h2 id="Upscaling"><a href="#Upscaling" class="headerlink" title="Upscaling"></a>Upscaling</h2><blockquote>
<p><strong>ShuffleCUGAN (NCNN)</strong> - <a target="_blank" rel="noopener" href="https://github.com/styler00dollar">styler00dollar</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/styler00dollar/VSGAN-tensorrt-docker">VSGAN-tensorrt-docker</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>ShuffleCUGAN (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/styler00dollar">styler00dollar</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/styler00dollar/VSGAN-tensorrt-docker">VSGAN-tensorrt-docker</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>RealESRGAN (NCNN)</strong> - <a target="_blank" rel="noopener" href="https://github.com/xinntao">xinntao</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/xinntao/Real-ESRGAN">Real-ESRGAN</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>RealESRGAN (DirectML)</strong> - <a target="_blank" rel="noopener" href="https://github.com/xinntao">xinntao</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/xinntao/Real-ESRGAN">Real-ESRGAN</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>RealESRGAN (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/xinntao">xinntao</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/xinntao/Real-ESRGAN">Real-ESRGAN</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>RealCUGAN (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/bilibili">bilibili</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/bilibili/ailab/tree/main/Real-CUGAN">ailab&#x2F;Real-CUGAN</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>SwinIR (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/JingyunLiang">JingyunLiang</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/JingyunLiang/SwinIR">SwinIR</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/mafiosnik777">mafiosnik777</a>&#x2F;<strong>SwinIR-TensorRT</strong> (unreleased)</p>
</blockquote>
<h2 id="Restoration"><a href="#Restoration" class="headerlink" title="Restoration"></a>Restoration</h2><blockquote>
<p><strong>DPIR (DirectML)</strong> - <a target="_blank" rel="noopener" href="https://github.com/cszn">cszn</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/cszn/DPIR">DPIR</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>DPIR (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/cszn">cszn</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/cszn/DPIR">DPIR</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/AmusementClub">AmusementClub</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/AmusementClub/vs-mlrt">vs-mlrt</a></strong></p>
</blockquote>
<blockquote>
<p><strong>SCUNet (TensorRT)</strong> - <a target="_blank" rel="noopener" href="https://github.com/cszn">cszn</a>&#x2F;<strong><a target="_blank" rel="noopener" href="https://github.com/cszn/SCUNet">SCUNet</a></strong> - powered by <a target="_blank" rel="noopener" href="https://github.com/mafiosnik777">mafiosnik777</a>&#x2F;<strong>SCUNet-TensorRT</strong> (unreleased)</p>
</blockquote>
<hr>
<p>Kdenlive has many video editing features, like automatic scene split, video stabilzation.</p>
<hr>
<p>To extract existing hard-coded subtitles in videos, use <a target="_blank" rel="noopener" href="https://sourceforge.net/projects/videosubfinder/">videosubfinder</a>, which is used in Cradle, an Red Dead Redemption II agent.</p>
<hr>
<p>To check if audio is recorded, we can view amplitude instead of hearing.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ffprobe -f lavfi -i <span class="string">&quot;amovie=&lt;audio_or_video_filepath&gt;,astats=metadata=1:reset=1&quot;</span> -show_entries frame=pkt_pts_time:frame_tags=lavfi.astats.Overall.RMS_level -of default=noprint_wrappers=1:nokey=1 -sexagesimal -v error</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/OceanNg529/allAI">AI toolbox</a>: a comprehensive content creation toolbox with links to related projects</p>
<hr>
<p>Use <code>streamlit</code> to write interactive interfaces for video labeling, editing and registration, tracking viewer counts.</p>
<p>Grided image can be used for image selection prompting and image condensation, putting multiple images together to save processing power during tasks like video rating.</p>
<p>When you play video games on low end devices, you can tune down the resolution and image quality, to ensure 30 FPS.</p>
<p>If you change screen resolution during screen recording, you might lose your view.</p>
<p>Train a video grading system with recent and relevant video grades, and when evaluating put grading context into the prompt, thus generalize the system.</p>
<p>Get system predicted labels of video content to train a label predictor out of it, providing necessary context of test video for improving the grading system accuracy.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/moymix/TaskMatrix">Taskmatrix</a> is a multimodal agent framework suitable for multiple types of image editing, using diffusion models.</p>
<p>You can learn what the viewers are craving about via recommendation engines, dynamic posts and latest bangumi releases.</p>
<p>Post the same content across multiple platforms to increase view counts.</p>

	
	</div>
  <a type="button" href="/blog/2024/03/10/593f71cb-ce66-4236-85f1-4256bf2b9f0a/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-12-08 </div>
			<div class="article-title"><a href="/blog/2022/12/08/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/" title="Text-to-video projects like make-a-video, Maria, OFA, GEN-2, CogVideo, Nuwa, MoCoGAN, tgan-pytorch, Redditube, and Ningyov employ multimodal techniques with distinctive features, leveraging deep learning for diverse video generation tasks.">Make-A-Video And Its Related Text To Video Projects</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>saying “video2video” is much simpler than “text2video”, I also want to add basic editing and semantic alignment is also simpler than this.</p>
<h2 id="similar-models-since-video-generating-models-are-usually-multimodal"><a href="#similar-models-since-video-generating-models-are-usually-multimodal" class="headerlink" title="similar models, since video generating models are usually multimodal"></a>similar models, since video generating models are usually multimodal</h2><p><a target="_blank" rel="noopener" href="https://github.com/jokieleung/Maria">maria</a>, A Visual Experience Powered Conversational Agent, suggested by incident</p>
<p><a target="_blank" rel="noopener" href="https://github.com/OFA-Sys/OFA">OFA</a> Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework</p>
<p><a target="_blank" rel="noopener" href="https://research.runwayml.com/gen2">GEN-2</a> by runway research with <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.03011">paper</a></p>
<h2 id="according-to-its-paper-it’s-been-compared-to-a-range-of-models"><a href="#according-to-its-paper-it’s-been-compared-to-a-range-of-models" class="headerlink" title="according to its paper, it’s been compared to a range of models"></a>according to its paper, it’s been compared to a range of models</h2><p><a target="_blank" rel="noopener" href="https://github.com/THUDM/CogVideo">cogvideo</a> able to process chinese and english input</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/make-a-video-pytorch">make a video in pytorch</a> text to video generation</p>
<p><a target="_blank" rel="noopener" href="https://github.com/soran-ghaderi/make-a-video">make a video in tensorflow</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/nuwa-pytorch">nuwa</a> text to video generation</p>
<p><a target="_blank" rel="noopener" href="https://github.com/sergeytulyakov/mocogan">mocogan</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/snap-research/MoCoGAN-HD#:~:text=/-,MoCoGAN%2DHD,-Public">mocogan-hd</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/proceduralia/tgan-pytorch">tgan-pytorch</a></p>
<h2 id="there-are-also-some-projects-being-a-video-generator-but-not-so-much-deeplearning-involved"><a href="#there-are-also-some-projects-being-a-video-generator-but-not-so-much-deeplearning-involved" class="headerlink" title="there are also some projects being a video generator but not so much deeplearning involved"></a>there are also some projects being a video generator but not so much deeplearning involved</h2><p><a target="_blank" rel="noopener" href="https://github.com/charlypoirier/redditube">redditube</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/HA6Bots/Automatic-Youtube-Reddit-Text-To-Speech-Video-Generator-and-Uploade">Automatic-Youtube-Reddit-Text-To-Speech-Video-Generator-and-Uploader</a></p>
<h2 id="tools-for-slideshow-video-effects-presentations"><a href="#tools-for-slideshow-video-effects-presentations" class="headerlink" title="tools for slideshow, video effects, presentations"></a>tools for slideshow, video effects, presentations</h2><p><a target="_blank" rel="noopener" href="https://github.com/react-phenomenon/phenomenon">phenomenon</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/oknoorap/vidshow">vidshow</a> Simple CLI to generate slideshow video with native FFMPEG</p>
<p><a target="_blank" rel="noopener" href="https://github.com/BayoDev/Twitch-Best-Of">Twitch-Best-Of</a> create best-of videos on twitch without token</p>
<p><a target="_blank" rel="noopener" href="https://github.com/613-forever/Ningyov">Ningyov</a> galgame effects</p>

	
	</div>
  <a type="button" href="/blog/2022/12/08/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-11-09 </div>
			<div class="article-title"><a href="/blog/2022/11/09/1210e7f0-68eb-4dbc-9012-9f7bbdb4b730/" title="In this article, you will learn how to generate noise videos and images using the ffmpeg software. The commands demonstrated will teach you how to create a 5-second TV noise video by employing different methods.">Generate Noise Image, Noise Video, Noise Audio With Ffmpeg For Test</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/15792105/simulating-tv-noise">simulating tv noise</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -f lavfi -i nullsrc=s=1280x720 -filter_complex \</span><br><span class="line"><span class="string">&quot;geq=random(1)*255:128:128;aevalsrc=-2+random(0)&quot;</span> \</span><br><span class="line">-t 5 output.mkv</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -f rawvideo -video_size 1280x720 -pixel_format yuv420p -framerate 25 \</span><br><span class="line">-i /dev/urandom -ar 48000 -ac 2 -f s16le -i /dev/urandom -codec:a copy \</span><br><span class="line">-t 5 output.mkv</span><br><span class="line"></span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/blog/2022/11/09/1210e7f0-68eb-4dbc-9012-9f7bbdb4b730/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-10-09 </div>
			<div class="article-title"><a href="/blog/2022/10/09/11c866f1-45df-4f41-a299-0c90e5e52d3f/" title="This article explores cutting-edge video generation models, such as OpenAI&#39;s Sora and Text2Video-Zero by Damo Academy. It also provides useful resources and recommendations for creating high-quality videos, including selecting the right content, utilizing smooth transitions, and incorporating subtitles.">Video Generation/Modification (Vfx) From Text</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>Sora is the new SOTA video generation model from OpenAI.</p>
<p>Following up projects:</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/hpcaitech/Open-Sora">Open-Sora</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/lichao-sun/SoraReview">SoraReview</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/hku/opensora">opensora</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/PKU-YuanGroup/Open-Sora-Plan">Open-Sora-Plan</a></p>
</li>
</ul>
<hr>
<p>达摩院放出了<a target="_blank" rel="noopener" href="https://modelscope.cn/models/damo/text-to-video-synthesis/summary">文本生成视频模型</a>，支持英文输入</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis">huggingface space</a></p>
<p>model weights:</p>
<table>
<thead>
<tr>
<th>weight path</th>
<th>weight size</th>
<th>model name</th>
<th>author</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/text-to-video-ms-1.7b">text-to-video-ms-1.7b</a></td>
<td>unknown</td>
<td>unknown</td>
<td>damo-vilab</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis">modelscope-damo-text-to-video-synthesis</a></td>
<td>unknown</td>
<td>unknown</td>
<td>damo-vilab</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/text-to-video-ms-1.7b-legacy">text-to-video-ms-1.7b-legacy</a></td>
<td>unknown</td>
<td>unknown</td>
<td>damo-vilab</td>
</tr>
</tbody></table>
<p>can also use from modelscope:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> modelscope.utils.constant <span class="keyword">import</span> Tasks</span><br><span class="line">p = pipeline(<span class="string">&#x27;text-to-video-synthesis&#x27;</span>, <span class="string">&#x27;damo/text-to-video-synthesis&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/PAIR">PAIR</a> now releases <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/PAIR/Text2Video-Zero">Text2Video-Zero</a> which leverages existing stable diffusion models to generate video. also released a bunch of controlnet dreambooth weights.</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains">lucidrains</a> is a workaholic on transformer implementations. we should scrape all the repos and index them. there are <a target="_blank" rel="noopener" href="https://github.com/lucidrains/memory-efficient-attention-pytorch">faster language models</a> to train.</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/phenaki-pytorch">Phenaki Video</a>, which uses Mask GIT to produce text guided videos of up to 2 minutes in length, in Pytorch</p>
<p><a target="_blank" rel="noopener" href="https://dreamix-video-editing.github.io/">dreamix</a> (not open-source)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/timothybrooks/instruct-pix2pix">instruct-pix2pix</a> requires 16GB+ VRAM</p>
<p><a target="_blank" rel="noopener" href="https://github.com/omerbt/Text2LIVE">text2live</a> modify video by text prompt (such as add fire in mouth)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/recurrent-interface-network-pytorch">recurrent-interface-network-pytorch</a> using diffusion to generate images and video</p>
<p>high quality! <a target="_blank" rel="noopener" href="https://github.com/lucidrains/imagen-pytorch/blob/main/imagen_pytorch/imagen_video.py">imagegen-video code</a> with <a target="_blank" rel="noopener" href="https://imagen.research.google/video/">demo</a> and <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.02303.pdf">paper</a></p>
<p>抄视频 视频的时间要讲究 看看是抄一年前的好还是抄刚刚发布的好</p>
<p>在发布的一个视频当中 最多抄某个作者的两三个符合要求的片段</p>
<p>use editly smooth&#x2F;slick transitions and subtitles to beat the copy-detection algorithm, also consider color change in ffmpeg</p>
<p>动态 专栏也可以抄</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/make-a-video-pytorch">make-a-video</a></p>
<p>谷歌AI歌手震撼来袭！AudioLM简单听几秒，便能谱曲写歌 <a target="_blank" rel="noopener" href="https://www.kuxai.com/article/398">https://www.kuxai.com/article/398</a></p>

	
	</div>
  <a type="button" href="/blog/2022/10/09/11c866f1-45df-4f41-a299-0c90e5e52d3f/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-31 </div>
			<div class="article-title"><a href="/blog/2022/05/31/27207c26-0f95-4d13-b6fe-b8d7f01f30fb/" title="Researchers have developed a Text-to-Video/Music-to-Video generator GAN that creates dance animations based on music genres. This novel approach utilizes a choreography-oriented embedding framework and cross-modal transformers to build a 3D dance dataset, allowing for the generation of unique dance animations synchronized with specific musical styles.">Music To Video Generator Gan</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="Text-to-Video-Music-to-video-generator-GAN"><a href="#Text-to-Video-Music-to-video-generator-GAN" class="headerlink" title="Text to Video&#x2F;Music to video generator GAN"></a>Text to Video&#x2F;Music to video generator GAN</h1><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=V8MlYa_yhF0">https://www.youtube.com/watch?v=V8MlYa_yhF0</a></p>
<p><a target="_blank" rel="noopener" href="https://netease-gameai.github.io/ChoreoMaster/Paper.pdf">https://netease-gameai.github.io/ChoreoMaster/Paper.pdf</a></p>
<p>该系统可依据音乐风格生成爵士、二次元、街舞等不同类型的舞蹈动画。给定一段音乐，舞蹈演员可以自动生成高质量的舞蹈动作序列以伴随输入音乐的风格、节奏和结构。为了实现这一目标，我们引入了一种新的面向编舞的编舞音乐嵌入框架，它成功地构建了一个统一的舞蹈音乐嵌入空间音乐和舞蹈短语之间的风格和节奏关系。</p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=VrVsAcgFK_4">https://www.youtube.com/watch?v=VrVsAcgFK_4</a></p>
<p>该方法提出了一个基于cross-modal transformer的架构模型和一个新的3D舞蹈数据集，该数据集包含了根据真实舞者重建的3D运动</p>
<p>项目地址: <a target="_blank" rel="noopener" href="https://google.github.io/aichoreographer">https://google.github.io/aichoreographer</a></p>
<p>数据集地址: <a target="_blank" rel="noopener" href="https://google.github.io/aistplusplus_dataset/">https://google.github.io/aistplusplus_dataset/</a></p>
<p>欢迎点赞、评论、分享、收藏！</p>
<p>video generation using music based on bigGAN:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Remideza/MichelAI/">https://github.com/Remideza/MichelAI/</a></p>
<p>bigGAN Large Scale GAN Training for High Fidelity Natural Image Synthesis:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ajbrock/BigGAN-PyTorch">https://github.com/ajbrock/BigGAN-PyTorch</a></p>
<p>dance video generation self-supervised:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/xrenaa/Music-Dance-Video-Synthesis">https://github.com/xrenaa/Music-Dance-Video-Synthesis</a></p>
<p>show me what and tell me how based on openai clip by snap research with pretrained models, able to generate arbitrary video based on text description:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/snap-research/MMVID">https://github.com/snap-research/MMVID</a></p>
<p>text to video generator based on vqgan and clip with primitive colab notebooks by kapwing the online video editor:</p>
<p><a target="_blank" rel="noopener" href="https://www.kapwing.com/ai-video-generator">https://www.kapwing.com/ai-video-generator</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/31/27207c26-0f95-4d13-b6fe-b8d7f01f30fb/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-28 </div>
			<div class="article-title"><a href="/blog/2022/05/28/ca55270b-02a3-4943-92b2-b4d595e3e9d7/" title="This article explores the utilization of AI techniques, specifically PaddleGAN, for colorizing images and videos. Additionally, it highlights other tools and GitHub repositories available for image colorization.">Ai上色</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="AI上色-ffmpeg去特定颜色-调色"><a href="#AI上色-ffmpeg去特定颜色-调色" class="headerlink" title="AI上色 ffmpeg去特定颜色 调色"></a>AI上色 ffmpeg去特定颜色 调色</h1><p><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1161285?channelType=0&channel=0">可能和GAN有关</a></p>
<p>use paddlegan for coloring</p>
<p>可以去掉血腥色情 暴力可能不行 需要剪辑</p>
<p>FFmpeg remove color:</p>
<p><a target="_blank" rel="noopener" href="https://video.stackexchange.com/questions/33588/using-ffmpeg-can-i-remove-the-color-from-an-area-of-the-video">https://video.stackexchange.com/questions/33588/using-ffmpeg-can-i-remove-the-color-from-an-area-of-the-video</a></p>
<p><a target="_blank" rel="noopener" href="http://johnriselvato.com/ffmpeg-how-to-remove-all-colors-except-one-from-a-video/">http://johnriselvato.com/ffmpeg-how-to-remove-all-colors-except-one-from-a-video/</a></p>
<p>face coloring:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Xu-Justin/Grayscale-Face-Coloring">https://github.com/Xu-Justin/Grayscale-Face-Coloring</a></p>
<p>nvidia coloring:</p>
<p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/easily-colorize-black-and-white-photos-with-ai/">https://developer.nvidia.com/blog/easily-colorize-black-and-white-photos-with-ai/</a></p>
<p>github topic on image colorization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/topics/image-colorization">https://github.com/topics/image-colorization</a></p>
<p>github repos on image colorization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image">https://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/aDouladiris/Grayscale-Image-Colorization">https://github.com/aDouladiris/Grayscale-Image-Colorization</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/aakaashjois/Colorizing-Grayscale-Images">https://github.com/aakaashjois/Colorizing-Grayscale-Images</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/emilwallner/Coloring-greyscale-images">https://github.com/emilwallner/Coloring-greyscale-images</a></p>
<p>curated list on image colorization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/oskar-j/awesome-image-coloring">https://github.com/oskar-j/awesome-image-coloring</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/28/ca55270b-02a3-4943-92b2-b4d595e3e9d7/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://yubingtao.netlify.app/" title="Yubingtao's Blog" target="_blank"]);">Yubingtao&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2024 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>