<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">Python</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-18 </div>
			<div class="article-title"><a href="/blog/2023/12/18/8a6267a2-bda4-4d09-a577-49dbf47fb6d3/" title="This text provides guidance on utilizing the Python utility &#39;pylint&#39; to identify unspecified exceptions in a Python file and proposes constructing microservices and tracking failures for enhanced error management.">Exception Phobia in Python</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pylint --<span class="built_in">enable</span>=unspecified-exception your_python_file.py</span><br></pre></td></tr></table></figure>
<p>However it is recommend to build microservices and log failures</p>

	
	</div>
  <a type="button" href="/blog/2023/12/18/8a6267a2-bda4-4d09-a577-49dbf47fb6d3/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-07-14 </div>
			<div class="article-title"><a href="/blog/2023/07/14/fc32ea43-c71f-4460-9806-b1dd4c9569a1/" title="This article provides an overview of several Python-based domain-specific language (DSL) tools, such as TextX with syntax highlighting and LSP support, Ply offering lex-yacc functionality, DhParser, and Lark Parser. These tools are designed to help developers create and analyze DSLs efficiently within the Python ecosystem.">Python DSL</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://github.com/textX/textX">textX</a> with syntax highlighter and LSP support, just like Xtext<br><a target="_blank" rel="noopener" href="https://ply.readthedocs.io/en/latest/ply.html">ply</a>: python lex-yacc<br><a target="_blank" rel="noopener" href="https://pypi.org/project/dhparser/">dhparser</a><br><a target="_blank" rel="noopener" href="https://github.com/lark-parser/lark">lark</a></p>

	
	</div>
  <a type="button" href="/blog/2023/07/14/fc32ea43-c71f-4460-9806-b1dd4c9569a1/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-05-04 </div>
			<div class="article-title"><a href="/blog/2023/05/04/f57039ce-6fc8-4be5-92ed-14f55b265fc8/" title="This article discusses various techniques such as optimizing AI models, utilizing different methods for creating bootable operating systems, working with tokenizers and embeddings, controlling OBS through Python programming, recording audio on macOS and Linux platforms, exploring complex neural network libraries, performing file operations using webdav-cli, capturing videos using Python and ffmpeg, forcing Ubuntu to utilize Xorg, and resizing virtual machine disks in UTM.">AGI that controls computer</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h2 id="make-specialized-in-RPA-tokenizer-and-embedding-for-this-new-model-add-new-words-to-the-tokenizer"><a href="#make-specialized-in-RPA-tokenizer-and-embedding-for-this-new-model-add-new-words-to-the-tokenizer" class="headerlink" title="make specialized (in RPA) tokenizer and embedding for this new model. add new words to the tokenizer."></a>make specialized (in RPA) tokenizer and embedding for this new model. add new words to the tokenizer.</h2><h2 id="you-can-just-boot-ubuntu-kali-parrot-iso-without-installing-but-that-would-make-us-embarrasing-we-need-to-check-for-the-option"><a href="#you-can-just-boot-ubuntu-kali-parrot-iso-without-installing-but-that-would-make-us-embarrasing-we-need-to-check-for-the-option" class="headerlink" title="you can just boot ubuntu&#x2F;kali&#x2F;parrot iso without installing.but that would make us embarrasing. we need to check for the option."></a>you can just boot ubuntu&#x2F;kali&#x2F;parrot iso without installing.<br>but that would make us embarrasing. we need to check for the option.</h2><h2 id="use-ChatGPT-derived-projects-for-localized-propaganda-on-CyberGod-and-The-Frozen-Forest-obs-remote-controlusing-obs-websocket-you-can-use-python-to-do-real-scripting-but-first-spin-up-obs-first-with-websocket-related-commandline-arguments-you-can-also-write-and-load-scripts-for-obs-run-on-custom-intervals-and-conditions-audio-recordingyour-OS-may-go-slient-if-you-want-to-record-audio-from-“speakers”"><a href="#use-ChatGPT-derived-projects-for-localized-propaganda-on-CyberGod-and-The-Frozen-Forest-obs-remote-controlusing-obs-websocket-you-can-use-python-to-do-real-scripting-but-first-spin-up-obs-first-with-websocket-related-commandline-arguments-you-can-also-write-and-load-scripts-for-obs-run-on-custom-intervals-and-conditions-audio-recordingyour-OS-may-go-slient-if-you-want-to-record-audio-from-“speakers”" class="headerlink" title="use ChatGPT-derived projects for localized propaganda on CyberGod and The Frozen Forest.## obs remote controlusing obs-websocket you can use python to do real scripting. but first spin up obs first (with websocket related commandline arguments)you can also write and load scripts for obs, run on custom intervals and conditions.## audio recordingyour OS may go slient if you want to record audio from “speakers”"></a>use ChatGPT-derived projects for localized propaganda on CyberGod and The Frozen Forest.<br>## obs remote control<br>using <a target="_blank" rel="noopener" href="https://github.com/obsproject/obs-websocket">obs-websocket</a> you can use python to do real scripting. but first spin up obs first (with websocket related commandline arguments)<br>you can also write and load scripts for obs, run on custom intervals and conditions.<br>## audio recording<br>your OS may go slient if you want to record audio from “speakers”</h2><h2 id="using-pyaudio-on-macos-you-need-blackhole-for-sending-all-audio-to-oblivion-thus-able-to-be-recorded-on-Linux-you-need-audio-loopback-device-run-sudo-modprobe-snd-aloopyou-use-hw-1-0-or-“Analog-Device-Output”-for-slient-output-speaker-and-use-hw-1-1-or-“Analog-Device-Input”-for-recording-benchmarksit-is-always-a-mystery-for-us-to-develop-the-right-ML-model-however-we-can-setup-guidelines-of-good-performance-over-specific-task-automate-the-benchmark-setup-metrics-there-could-be-more-room-for-trials-and-imagination-encodinguse-hfft-rfft-to-transform-multipart-inputs-special-bits-different-part-of-mouse-coords-x-y-dx-dy-if-you-want-to-use-complex-number-as-RNN-input-you-may-need-to-swap-ViT-for-ComplexConv2D-but-maybe-you-just-need-a-few"><a href="#using-pyaudio-on-macos-you-need-blackhole-for-sending-all-audio-to-oblivion-thus-able-to-be-recorded-on-Linux-you-need-audio-loopback-device-run-sudo-modprobe-snd-aloopyou-use-hw-1-0-or-“Analog-Device-Output”-for-slient-output-speaker-and-use-hw-1-1-or-“Analog-Device-Input”-for-recording-benchmarksit-is-always-a-mystery-for-us-to-develop-the-right-ML-model-however-we-can-setup-guidelines-of-good-performance-over-specific-task-automate-the-benchmark-setup-metrics-there-could-be-more-room-for-trials-and-imagination-encodinguse-hfft-rfft-to-transform-multipart-inputs-special-bits-different-part-of-mouse-coords-x-y-dx-dy-if-you-want-to-use-complex-number-as-RNN-input-you-may-need-to-swap-ViT-for-ComplexConv2D-but-maybe-you-just-need-a-few" class="headerlink" title="using pyaudio, on macos, you need blackhole for sending all audio to oblivion, thus able to be recorded.on Linux, you need audio loopback device.run: sudo modprobe snd-aloopyou use hw:1:0 or “Analog Device Output” for slient output&#x2F;speaker, and use hw:1:1 or “Analog Device Input” for recording.## benchmarksit is always a mystery for us to develop the right ML model. however, we can setup guidelines of good performance over specific task.automate the benchmark, setup metrics. there could be more room for trials and imagination.## encodinguse hfft&#x2F;rfft to transform multipart inputs (special bits, different part of mouse coords (x, y, dx, dy))if you want to use complex number as RNN input, you may need to swap ViT for ComplexConv2D, but maybe you just need a few."></a>using pyaudio, on macos, you need blackhole for sending all audio to oblivion, thus able to be recorded.<br>on Linux, you need audio loopback device.<br>run: <code>sudo modprobe snd-aloop</code><br>you use <code>hw:1:0</code> or “Analog Device Output” for slient output&#x2F;speaker, and use <code>hw:1:1</code> or “Analog Device Input” for recording.<br>## benchmarks<br>it is always a mystery for us to develop the right ML model. however, we can setup guidelines of good performance over specific task.<br>automate the benchmark, setup metrics. there could be more room for trials and imagination.<br>## encoding<br>use hfft&#x2F;rfft to transform multipart inputs (special bits, different part of mouse coords (x, y, dx, dy))<br>if you want to use complex number as RNN input, you may need to swap ViT for ComplexConv2D, but maybe you just need a few.</h2><h2 id="libraries-that-handle-complex-neural-networks-complexPyTorchpytorch-complex-multimodaldo-our-model-have-to-output-multimodal-data-if-you-combine-some-“special”-bits-along-with-token-embeding-by-ihfft-you-may-have-to-retrain-the-entire-damn-network-also-in-order-to-make-way-for-special-bits-you-may-have-to-introduce-extra-linear-layer"><a href="#libraries-that-handle-complex-neural-networks-complexPyTorchpytorch-complex-multimodaldo-our-model-have-to-output-multimodal-data-if-you-combine-some-“special”-bits-along-with-token-embeding-by-ihfft-you-may-have-to-retrain-the-entire-damn-network-also-in-order-to-make-way-for-special-bits-you-may-have-to-introduce-extra-linear-layer" class="headerlink" title="libraries that handle complex neural networks:complexPyTorchpytorch-complex## multimodaldo our model have to output multimodal data?if you combine some “special” bits along with token embeding by ihfft, you may have to retrain the entire damn network. also in order to make way for special bits, you may have to introduce extra linear layer."></a>libraries that handle complex neural networks:<br><a target="_blank" rel="noopener" href="https://github.com/wavefrontshaping/complexPyTorch">complexPyTorch</a><br><a target="_blank" rel="noopener" href="https://github.com/soumickmj/pytorch-complex">pytorch-complex</a><br>## multimodal<br>do our model have to output multimodal data?<br>if you combine some “special” bits along with token embeding by ihfft, you may have to retrain the entire damn network. also in order to make way for special bits, you may have to introduce extra linear layer.</h2><h2 id="some-may-prefer-“LoRA”-by-only-introducing-few-tunable-params-and-changing-the-overall-output"><a href="#some-may-prefer-“LoRA”-by-only-introducing-few-tunable-params-and-changing-the-overall-output" class="headerlink" title="some may prefer “LoRA”? by only introducing few tunable params and changing the overall output?"></a>some may prefer “LoRA”? by only introducing few tunable params and changing the overall output?</h2><h2 id="we-may-not-annotate-anything-in-our-dataset-in-contrast-we-will-set-goals-and-make-multiple-interfaces-for-our-model-to-explore"><a href="#we-may-not-annotate-anything-in-our-dataset-in-contrast-we-will-set-goals-and-make-multiple-interfaces-for-our-model-to-explore" class="headerlink" title="we may not annotate anything in our dataset. in contrast, we will set goals and make multiple interfaces for our model to explore."></a>we may not annotate anything in our dataset. in contrast, we will set goals and make multiple interfaces for our model to explore.</h2><h2 id="you-can-add-special-task-specific-embedding-before-passing-to-main-model-then-minus-that-task-specific-embedding-after-passing-to-classification-model-file-sharing-and-communicationmake-sure-you-don’t-share-important-files-as-read-write-on-VM"><a href="#you-can-add-special-task-specific-embedding-before-passing-to-main-model-then-minus-that-task-specific-embedding-after-passing-to-classification-model-file-sharing-and-communicationmake-sure-you-don’t-share-important-files-as-read-write-on-VM" class="headerlink" title="you can add special task specific embedding before passing to main model, then minus that task specific embedding after passing to classification model.## file sharing and communicationmake sure you don’t share important files as read&#x2F;write on VM."></a>you can add special task specific embedding before passing to main model, then minus that task specific embedding after passing to classification model.<br>## file sharing and communication<br>make sure you don’t share important files as read&#x2F;write on VM.</h2><h2 id="you-may-host-some-“execution-server”-on-UTM-VMs-you-may-expose-your-very-large-hard-disk-using-WebDAV-server-i-think-x11vnc-and-other-vnc-server-may-suffice-for-linux-but-we-always-want-to-listen-to-the-real-operational-data-including-human-operation-intervention-not-just-those-in-VNC-protocols"><a href="#you-may-host-some-“execution-server”-on-UTM-VMs-you-may-expose-your-very-large-hard-disk-using-WebDAV-server-i-think-x11vnc-and-other-vnc-server-may-suffice-for-linux-but-we-always-want-to-listen-to-the-real-operational-data-including-human-operation-intervention-not-just-those-in-VNC-protocols" class="headerlink" title="you may host some “execution server” on UTM VMs. you may expose your very large hard disk using WebDAV server. i think x11vnc and other vnc server may suffice for linux, but we always want to listen to the real operational data, including human operation&#x2F;intervention, not just those in VNC protocols."></a>you may host some “execution server” on UTM VMs. you may expose your very large hard disk using WebDAV server. i think x11vnc and other vnc server may suffice for linux, but we always want to listen to the real operational data, including human operation&#x2F;intervention, not just those in VNC protocols.</h2><h2 id="WebDAV-servers-wsgidav-python-webdav-cli-（nodejs-video-recordingfor-Ubuntu-ARM-VM-mss-failed-on-wayland-but-pyautogui-works-in-both-cases-write-one-python-script-to-pipe-raw-images-to-ffmpeg-for-better-compression-ratio-by-shell-the-final-video-is-not-“time-accurate”-it-is-frame-by-frame-matched-with-timestamps"><a href="#WebDAV-servers-wsgidav-python-webdav-cli-（nodejs-video-recordingfor-Ubuntu-ARM-VM-mss-failed-on-wayland-but-pyautogui-works-in-both-cases-write-one-python-script-to-pipe-raw-images-to-ffmpeg-for-better-compression-ratio-by-shell-the-final-video-is-not-“time-accurate”-it-is-frame-by-frame-matched-with-timestamps" class="headerlink" title="WebDAV servers:wsgidav (python)webdav-cli （nodejs)## video recordingfor Ubuntu ARM VM, mss failed on wayland but pyautogui works in both cases. write one python script to pipe raw images to ffmpeg for better compression ratio by shell. the final video is not “time-accurate”. it is frame by frame, matched with timestamps."></a>WebDAV servers:<br><a target="_blank" rel="noopener" href="https://github.com/mar10/wsgidav">wsgidav</a> (python)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsgidav --host=192.168.64.1 --port=8081 --root=<span class="string">&quot;/Volumes/Toshiba XG3/works/agi_computer_control&quot;</span>  --auth=anonymous</span><br></pre></td></tr></table></figure><br><a target="_blank" rel="noopener" href="https://github.com/svtslv/webdav-cli">webdav-cli</a> （nodejs)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">webdav-cli --host=192.168.64.1 --port=8081 --username=root --password=root --path=<span class="string">&quot;/Volumes/Toshiba XG3/works/agi_computer_control&quot;</span></span><br></pre></td></tr></table></figure><br>## video recording<br>for Ubuntu ARM VM, <code>mss</code> failed on wayland but <code>pyautogui</code> works in both cases. write one python script to pipe raw images to ffmpeg for better compression ratio by shell. the final video is not “time-accurate”. it is frame by frame, matched with timestamps.</h2><p>forcing ubuntu to use xorg by: <code>sudo vim /etc/gdm3/custom.conf</code></p>
<h2 id="resize-UTM-VM-disks"><a href="#resize-UTM-VM-disks" class="headerlink" title="resize UTM VM disks"></a>resize UTM VM disks</h2><p>you need to first resize the virtio disk in utm setting, then resize partition by using gparted, then <a target="_blank" rel="noopener" href="https://www.albertyw.com/note/resizing-ubuntu-utm#:~:text=For%20an%20Ubuntu%20guest%20OS%20running%20a%20default,be%20corrected%20by%20w%20%28rite%29%20warning%20More%20items">update the device mapper</a></p>

	
	</div>
  <a type="button" href="/blog/2023/05/04/f57039ce-6fc8-4be5-92ed-14f55b265fc8/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-04 </div>
			<div class="article-title"><a href="/blog/2023/04/04/cd70237b-ef04-47b8-a0dc-9ceadd42386c/" title="This article explores the advancements in Python performance, specifically mentioning Pypy&#39;s remarkable speed and how Codon leverages Python syntax to generate static executables.">faster python</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>latest python has better performance.<br>pypy is fast.<br><a target="_blank" rel="noopener" href="https://docs.exaloop.io/codon/">codon</a> is using python syntax to compile python into static executable.</p>

	
	</div>
  <a type="button" href="/blog/2023/04/04/cd70237b-ef04-47b8-a0dc-9ceadd42386c/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-02-08 </div>
			<div class="article-title"><a href="/blog/2023/02/08/9105af56-d2c8-48c8-9b2d-a9693bf8429a/" title="This article explores different Python libraries for creating diagrams and flowcharts, including pyflowchart, diagrams, and pydiagrams. It also includes installation instructions for dependencies like Graphviz on Debian-based systems.">python diagram/flowchart generator and markdown to word converter</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://github.com/cdfmlr/pyflowchart">pyflowchart</a><br><a target="_blank" rel="noopener" href="https://libraries.io/pypi/diagrams">diagrams</a> needs graphviz installed (on debian it is <code>apt install graphviz</code>). <a target="_blank" rel="noopener" href="https://diagrams.mingrammer.com/docs/">doc</a><br><a target="_blank" rel="noopener" href="https://libraries.io/pypi/pydiagrams">pydiagrams</a></p>

	
	</div>
  <a type="button" href="/blog/2023/02/08/9105af56-d2c8-48c8-9b2d-a9693bf8429a/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-12-13 </div>
			<div class="article-title"><a href="/blog/2022/12/13/e270170a-1520-4c18-af65-f9c4cc62a93e/" title="This article compares Dubbo and Python&#39;s XML-RPC as remote procedure call technologies, discussing their capabilities in handling native structures like numpy arrays. It also provides tutorial links for detecting if Dubbo services are functioning normally, along with warnings against ads when opening specific URLs.">dubbo and python xmlrpc</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>they are both remote procedure calls.<br>you can ship things across internet, but remember it can’t be some “native” structure like numpy array.<br>python <a target="_blank" rel="noopener" href="https://wiki.python.org/moin/XmlRpc">xmlrpc</a> tutorial and <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/xmlrpc.server.html">xmlrpc.server</a> mentions <a target="_blank" rel="noopener" href="http://c2.com/cgi/wiki?XmlRpc">c2 wiki</a> which you have scraped before. where is it, along with all other things you have scraped? believe it is in that AGI directory since you are such an archivist at that time.<br>tutorials on how to detect if dubbo services are working normally:<br>basically they use native java methods or telnet protocol with python<br><a target="_blank" rel="noopener" href="http://www.shouhuola.com/q-23671.html">http://www.shouhuola.com/q-23671.html</a><br><a target="_blank" rel="noopener" href="https://www.yisu.com/zixun/576879.html">https://www.yisu.com/zixun/576879.html</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/leozhanggg/p/14176752.html">https://www.cnblogs.com/leozhanggg/p/14176752.html</a><br><a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv13670275/">https://www.bilibili.com/read/cv13670275/</a><br><a target="_blank" rel="noopener" href="http://www.zztongyun.com/article/article-1-1.html">http://www.zztongyun.com/article/article-1-1.html</a> (open with <code>elinks</code> to prevent ads)</p>

	
	</div>
  <a type="button" href="/blog/2022/12/13/e270170a-1520-4c18-af65-f9c4cc62a93e/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-12-08 </div>
			<div class="article-title"><a href="/blog/2022/12/08/a60440bd-9482-44c5-9844-d747da208f69/" title="This article delves into AI techniques for text generation and paraphrasing, specifically exploring language models like LSA and LDA in Python. Comment A dives into word matrix decomposition to create attention-grabbing titles, while Comment B discusses the capabilities and drawbacks of Latent Semantic Analysis (LSA) in paraphrasing.">talk to openai chatgpt to learn a few on paraphrasing, title generation</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>it’s like a huge search engine which can talk.<br><a target="_blank" rel="noopener" href="https://github.com/topics/paraphrase">github topic on paraphrase</a><br><a target="_blank" rel="noopener" href="http://www.xiaofamaoai.com/">小发猫</a><br><a target="_blank" rel="noopener" href="http://www.wzwyc.com/">文章伪原创工具</a> and <a target="_blank" rel="noopener" href="http://ai.guiyigs.com/">backup</a> 有提到用扫描仪来扫描原创文章的方法<br>online <a target="_blank" rel="noopener" href="https://paraphrasetool.com/">paraphrase tool</a>  translation based, can process chinese<br>chatgpt says creativity matters, such as hackers, video producers and your evil sex shit.</p>
<h2 id="you-said-LDA-and-LSA-are-helpful-for-paraphrasing"><a href="#you-said-LDA-and-LSA-are-helpful-for-paraphrasing" class="headerlink" title="you said LDA and LSA are helpful for paraphrasing"></a>you said LDA and LSA are helpful for paraphrasing</h2><p>Yes, LDA and LSA are two methods that can be used to generate paraphrases of a given text. LDA (Latent Dirichlet Allocation) is a probabilistic model that can be used to identify topics in a text and then generate new sentences that express the same topics in a different way. LSA (Latent Semantic Analysis) is a method that uses singular value decomposition to identify the underlying meaning of words in a text and then generate paraphrases by replacing words with their closest semantic equivalents. Both LDA and LSA can be helpful for generating paraphrases, but they each have their own strengths and limitations.</p>
<h2 id="can-you-demonstrate-how-to-use-LSA-for-paraphrasing-in-python"><a href="#can-you-demonstrate-how-to-use-LSA-for-paraphrasing-in-python" class="headerlink" title="can you demonstrate how to use LSA for paraphrasing in python"></a>can you demonstrate how to use LSA for paraphrasing in python</h2><p>I’m sorry, but I am not currently able to browse the internet or access any external resources. As a large language model trained by OpenAI, my knowledge is based solely on the text that I have been trained on, and I don’t have the ability to run code or demonstrate specific examples. However, I can provide a general overview of how LSA could be used for paraphrasing in Python.<br>To use LSA for paraphrasing in Python, you would first need to create a matrix of word vectors for the words in the text you want to paraphrase. This matrix would represent the semantic relationships between the words in the text, and would be used to identify the underlying meaning of each word.<br>Next, you would use singular value decomposition (SVD) to decompose the matrix into three matrices, which represent the different factors that contribute to the meaning of the words in the text.<br>Once you have the three matrices, you can then use them to identify the most closely related words for each word in the text, and generate paraphrases by replacing words with their closest semantic equivalents.<br>This is just a brief overview of how LSA could be used for paraphrasing in Python. There are many different ways to implement LSA, and the exact details of the implementation would depend on the specific requirements of your project.</p>
<h2 id="continue"><a href="#continue" class="headerlink" title="continue"></a>continue</h2><p>I’m sorry, but I’m not sure what you would like me to continue with. If you have a specific question or topic you would like to discuss, I would be happy to help. Otherwise, I can provide more information about LSA and how it can be used for paraphrasing if that would be helpful. Let me know what you would like to know.</p>
<h2 id="how-to-use-LDA-for-paraphrasing"><a href="#how-to-use-LDA-for-paraphrasing" class="headerlink" title="how to use LDA for paraphrasing"></a>how to use LDA for paraphrasing</h2><p>To use LDA for paraphrasing, you would first need to train a LDA model on a large corpus of text. This would involve using a machine learning algorithm to identify the topics that are present in the corpus, and then generating a set of “topic vectors” that represent the distribution of those topics across the text.<br>Once you have trained the LDA model, you can then use it to generate paraphrases of a given text by identifying the topics present in the text and then replacing words with synonyms or related words that express the same topics in a different way. This process can be repeated multiple times to generate multiple paraphrases of the same text.<br>Here is a brief example of how LDA could be used for paraphrasing in Python:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora, models</span><br><span class="line"><span class="comment"># Load the text you want to paraphrase</span></span><br><span class="line">text = <span class="string">&quot;The quick brown fox jumps over the lazy dog.&quot;</span></span><br><span class="line"><span class="comment"># Tokenize the text and create a dictionary of words</span></span><br><span class="line">tokens = text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">dictionary = corpora.Dictionary([tokens])</span><br><span class="line"><span class="comment"># Train a LDA model on the text</span></span><br><span class="line">lda_model = models.LdaModel([dictionary.doc2bow(tokens)], num_topics=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Generate paraphrases of the text</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">paraphrase = lda_model.show_topics(num_topics=<span class="number">1</span>, num_words=<span class="built_in">len</span>(tokens), formatted=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join([word[<span class="number">0</span>] <span class="keyword">for</span> word <span class="keyword">in</span> paraphrase[<span class="number">0</span>][<span class="number">1</span>]]))</span><br></pre></td></tr></table></figure>
<p>This example trains a simple LDA model on a single sentence and then generates three paraphrases of the sentence by replacing words with their closest semantic equivalents. Of course, this is just a simple example to illustrate the basic concept of using LDA for paraphrasing. In practice, you would need to use a much larger corpus of text to train the LDA model and generate more accurate paraphrases.</p>
<h2 id="demonstrate-using-LSA-to-paraphrase-in-python-using-gensim-if-needed"><a href="#demonstrate-using-LSA-to-paraphrase-in-python-using-gensim-if-needed" class="headerlink" title="demonstrate using LSA to paraphrase in python, using gensim if needed"></a>demonstrate using LSA to paraphrase in python, using gensim if needed</h2><p>As I mentioned earlier, I am not currently able to browse the internet or access external resources, so I cannot demonstrate using LSA to paraphrase in Python using gensim or any other specific libraries. However, I can provide a general overview of how LSA could be used for paraphrasing in Python.<br>To use LSA for paraphrasing in Python, you would first need to create a matrix of word vectors for the words in the text you want to paraphrase. This matrix would represent the semantic relationships between the words in the text, and would be used to identify the underlying meaning of each word.<br>Once you have the matrix of word vectors, you can use singular value decomposition (SVD) to decompose the matrix into three matrices, which represent the different factors that contribute to the meaning of the words in the text. The gensim library includes a implementation of SVD that you can use for this purpose.<br>Once you have the three matrices, you can then use them to identify the most closely related words for each word in the text, and generate paraphrases by replacing words with their closest semantic equivalents. Here is an example of how this could be done in Python:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora, models, matutils</span><br><span class="line"><span class="comment"># Load the text you want to paraphrase</span></span><br><span class="line">text = <span class="string">&quot;The quick brown fox jumps over the lazy dog.&quot;</span></span><br><span class="line"><span class="comment"># Tokenize the text and create a dictionary of words</span></span><br><span class="line">tokens = text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">dictionary = corpora.Dictionary([tokens])</span><br><span class="line"><span class="comment"># Create a matrix of word vectors using the dictionary</span></span><br><span class="line">word_vectors = [dictionary.doc2bow(tokens)]</span><br><span class="line"><span class="comment"># Use SVD to decompose the matrix of word vectors</span></span><br><span class="line">U, S, VT = matutils.svd(word_vectors, k=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># Generate paraphrases of the text</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">paraphrase = []</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> tokens:</span><br><span class="line"><span class="comment"># Identify the closest semantic equivalents for each word</span></span><br><span class="line">closest_words = VT.dot(VT[dictionary.token2id[word]])</span><br><span class="line">closest_words = <span class="built_in">sorted</span>(<span class="built_in">enumerate</span>(closest_words), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">closest_word = closest_words[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="comment"># Replace the word with its closest semantic equivalent</span></span><br><span class="line">paraphrase.append(dictionary[closest_word])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>.join(paraphrase))</span><br></pre></td></tr></table></figure>
<p>This example trains an LSA model on a single sentence and then generates three paraphrases of the sentence by replacing words with their closest semantic equivalents. Again, this is just a simple example to illustrate the basic concept of using LSA for paraphrasing. In practice, you would need to use a much larger corpus of text to train the LSA model and generate more accurate paraphrases.</p>
<h2 id="how-to-use-transformer-for-paraphrasing"><a href="#how-to-use-transformer-for-paraphrasing" class="headerlink" title="how to use transformer for paraphrasing"></a>how to use transformer for paraphrasing</h2><p>The transformer is a type of neural network architecture that has been used for a wide range of natural language processing tasks, including paraphrasing. To use a transformer for paraphrasing, you would need to train the transformer on a large corpus of text using a machine learning algorithm.<br>During training, the transformer would learn to identify the underlying meaning of words and phrases in the text and then generate paraphrases by replacing words with synonyms or related words that express the same meaning in a different way.<br>Here is a brief example of how a transformer could be used for paraphrasing in Python:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM</span><br><span class="line"><span class="comment"># Load the text you want to paraphrase</span></span><br><span class="line">text = <span class="string">&quot;The quick brown fox jumps over the lazy dog.&quot;</span></span><br><span class="line"><span class="comment"># Tokenize the text using a pre-trained transformer model</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;distilbert-base-cased&quot;</span>)</span><br><span class="line">tokens = tokenizer.encode(text)</span><br><span class="line"><span class="comment"># Load a pre-trained transformer model</span></span><br><span class="line">transformer = AutoModelForSeq2SeqLM.from_pretrained(<span class="string">&quot;distilbert-base-cased&quot;</span>)</span><br><span class="line"><span class="comment"># Generate paraphrases of the text</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">paraphrase = transformer.generate(tokens)</span><br><span class="line">paraphrase = tokenizer.decode(paraphrase[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(paraphrase)</span><br></pre></td></tr></table></figure>
<p>This example uses a pre-trained transformer model to generate three paraphrases of a single sentence. Of course, in practice you would need to train the transformer on a much larger corpus of text to generate more accurate paraphrases. The exact details of the implementation would depend on the specific requirements of your project.</p>
<h2 id="how-to-generate-catchy-title-from-keywords-using-language-model"><a href="#how-to-generate-catchy-title-from-keywords-using-language-model" class="headerlink" title="how to generate catchy title from keywords using language model"></a>how to generate catchy title from keywords using language model</h2><p>To generate a catchy title from a set of keywords using a language model, you would need to train the language model on a large corpus of text that includes a variety of titles. During training, the language model would learn to identify the underlying meaning of words and phrases and the characteristics of catchy titles.<br>Once the language model has been trained, you can then use it to generate a catchy title from a set of keywords by providing the keywords as input to the model and then selecting the generated title that is the most catchy and relevant to the keywords.<br>Here is a brief example of how this could be done in Python:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"><span class="comment"># Load the keywords you want to use to generate the title</span></span><br><span class="line">keywords = [<span class="string">&quot;quick&quot;</span>, <span class="string">&quot;brown&quot;</span>, <span class="string">&quot;fox&quot;</span>]</span><br><span class="line"><span class="comment"># Tokenize the keywords using a pre-trained language model</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line">tokens = tokenizer.encode(keywords)</span><br><span class="line"><span class="comment"># Load a pre-trained language model</span></span><br><span class="line">language_model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line"><span class="comment"># Generate candidate titles from the keywords</span></span><br><span class="line">candidate_titles = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">title = language_model.generate(tokens, max_length=<span class="number">8</span>)</span><br><span class="line">title = tokenizer.decode(title[<span class="number">0</span>])</span><br><span class="line">candidate_titles.append(title)</span><br><span class="line"><span class="comment"># Select the most catchy and relevant title</span></span><br><span class="line">selected_title = candidate_titles[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> candidate_titles:</span><br><span class="line"><span class="keyword">if</span> is_catchy(title) <span class="keyword">and</span> is_relevant(title, keywords):</span><br><span class="line">selected_title = title</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(selected_title)</span><br></pre></td></tr></table></figure>
<p>This example generates three candidate titles from a set of keywords using a pre-trained language model, and then selects the most catchy and relevant title as the final title. Of course, this is just a simple example to illustrate the basic concept of using a language model to generate a catchy title from keywords. In practice, you would need to use a much larger corpus of text to train the language model and generate more accurate and diverse titles.</p>

	
	</div>
  <a type="button" href="/blog/2022/12/08/a60440bd-9482-44c5-9844-d747da208f69/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-12-07 </div>
			<div class="article-title"><a href="/blog/2022/12/07/c500a693-b2ba-4f2c-a898-c751b801b650/" title="The DARPA competition utilizes machine learning to generate software exploits in assembly and Python using Neural Machine Translation for natural language descriptions. This includes modifying Java bytecode and filtering HTML requests.">Cyber Grand Challenge DARPA machine automated cyber attack</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://ctf-wiki.org/introduction/cgc/">ctfwiki’s intro on CGC</a><br>analyze source code first, then plan attack or fix code<br><a target="_blank" rel="noopener" href="https://github.com/CyberGrandChallenge">cgc’s github repo</a> and <a target="_blank" rel="noopener" href="http://cybergrandchallenge.com/">website</a><br>search for <code>darpa cgc</code> on github<br><a target="_blank" rel="noopener" href="https://github.com/jamespic/cyber-challenge">cyber-challenge</a> Some toy examples, to demonstrate ideas that could be used in DARPA’s Cyber Grand Challenge including modifying java bytecode and filter out html requests on the fly<br><a target="_blank" rel="noopener" href="https://github.com/dessertlab/EVIL">EVIL</a> (Exploiting software VIa natural Language) is an approach to automatically generate software exploits in assembly&#x2F;Python language from descriptions in natural language. The approach leverages Neural Machine Translation (NMT) techniques and a dataset that we developed for this work.<br>Topics<br>linux exploit encoder assembly decoder dataset seq2seq shellcode nmt software-exploitation codebert<br>Resources<br>Readme<br>License<br>GPL-3.0 license<br>Stars<br>13 stars<br>Watchers<br>3 watching<br>Forks<br>1 fork<br>Releases<br>No releases published<br>Packages<br>No packages published<br>Contributors 2<br>@piliguori<br>piliguori Pietro Liguori<br>@taisazero<br>taisazero Erfan Al-Hossami<br>Languages<br>Python<br>97.6%<br>Shell<br>2.0%<br>Other<br>0.4%</p>

	
	</div>
  <a type="button" href="/blog/2022/12/07/c500a693-b2ba-4f2c-a898-c751b801b650/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-12-02 </div>
			<div class="article-title"><a href="/blog/2022/12/02/cc1e47b5-db3d-41e0-a6b3-a489fb104747/" title="This article provides an overview of several Python libraries and resources available for working with the Nmap network scanning tool. It covers python3-nmap, nmapthon, and python-nmap, along with their respective documentation, allowing readers to choose the best option for their needs.">Exploring Python Libraries and Resources for Nmap Network Scanning</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="nmap-python-scripting"><a href="#nmap-python-scripting" class="headerlink" title="nmap python scripting"></a>nmap python scripting</h1><p><a target="_blank" rel="noopener" href="https://pypi.org/project/python3-nmap/">python3-nmap</a> and <a target="_blank" rel="noopener" href="https://nmap.readthedocs.io/en/latest/nmap.html">doc</a><br><a target="_blank" rel="noopener" href="https://nmapthon.readthedocs.io/en/latest/simple_information.html">doc of nmapthon</a> python scriptable nse<br><a target="_blank" rel="noopener" href="https://pypi.org/project/python-nmap/">python-nmap</a></p>

	
	</div>
  <a type="button" href="/blog/2022/12/02/cc1e47b5-db3d-41e0-a6b3-a489fb104747/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-11-11 </div>
			<div class="article-title"><a href="/blog/2022/11/11/fc18f6ac-1fc3-4573-b435-c59310b8ecd3/" title="This article explores the integration between Python and Clojure using the libpython-clj library. The author explains how to call Python functions from Clojure or embed Clojure code within Python, making it easier to leverage the strengths of both languages in a single project.">Call python in clojure, clojure-python bridge</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://github.com/clj-python/libpython-clj">libpython-clj</a> deep python integration in clojure<br><a target="_blank" rel="noopener" href="https://clj-python.github.io/libpython-clj/embedded.html">embed clojure in python</a> call clojure in python</p>

	
	</div>
  <a type="button" href="/blog/2022/11/11/fc18f6ac-1fc3-4573-b435-c59310b8ecd3/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
		
          <li class="prev disabled"><a><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
        

        <li><a href="/blog/"><i class="fa fa-home"></i>Home</a></li>

		
		   <li class="next"> <a href="/blog/tags/Python/page/2/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a> </li>
        
	
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2023 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>