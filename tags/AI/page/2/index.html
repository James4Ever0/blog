<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Page 2 | AI | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">AI</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-11-28 </div>
			<div class="article-title"><a href="/blog/2022/11/28/b7f08b1f-e6c0-4c0a-b740-b9d4b7fed842/" title="This article highlights popular AI libraries and tools for different tasks, such as recommendation systems (Surprise, LightFM), time series forecasting (Prophet), subword embeddings (Bpemb), and more including XGBoost, Chakin, H2O AutoML, Awesome H2O, Numenta&#39;s Nupic doc, DESlib, and TFlearn. Each library is explained in detail to help readers understand their features and capabilities.">Exploring Popular AI Libraries and Tools for Various Tasks</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="popular-AI-libraries"><a href="#popular-AI-libraries" class="headerlink" title="popular AI libraries"></a>popular AI libraries</h1><p>thers’s something missing in the agi field.</p>
<p><a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/stable/get_started.html">xgboost binary classification</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Hironsan/awesome-embedding-models">awesome embedding models</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/chakki-works/chakin">chakin: simple downloader for embedding models</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/bheinzerling/bpemb">bpemb: pretrained subword embeddings for many languages</a></p>
<p><a target="_blank" rel="noopener" href="https://facebook.github.io/prophet/docs/quick_start.html#python-api">prophet python tutorial time series forcast</a></p>
<p><a target="_blank" rel="noopener" href="http://tflearn.org/">tflearn: high level wrappers for tensorflow</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html">h2o automl docs</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/h2oai/awesome-h2o">awesome h2o</a> for h2o beginners</p>
<p><a target="_blank" rel="noopener" href="http://nupic.docs.numenta.org/stable/index.html">numenta nupic doc</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Menelau/DESlib">deslib</a> dynamic classifier and ensemble library</p>
<h2 id="recommendation-system"><a href="#recommendation-system" class="headerlink" title="recommendation system"></a>recommendation system</h2><p><a target="_blank" rel="noopener" href="https://github.com/muricoca/crab">crab</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/NicolasHug/Surprise">surprise</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/ocelma/python-recsys">python recsys</a> recommendation system</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lyst/lightfm">lightfm</a> recsys</p>

	
	</div>
  <a type="button" href="/blog/2022/11/28/b7f08b1f-e6c0-4c0a-b740-b9d4b7fed842/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-10-09 </div>
			<div class="article-title"><a href="/blog/2022/10/09/93902e98-2508-4d74-80af-9afb6ecff3ae/" title="AI video generation tools such as Text2Video-Zero, Phenaki Video, Imagen-PyTorch, and Make-a-Video-PyTorch are revolutionizing the video production process. These platforms enable users to generate videos using source material quality, editing capabilities, subtitles, color changes, and even music composition through Google&#39;s AudioLM. Access to these tools is available on ModelScope, Hugging Face, and GitHub.">video generation/modification (vfx) from text</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>达摩院放出了<a target="_blank" rel="noopener" href="https://modelscope.cn/models/damo/text-to-video-synthesis/summary">文本生成视频模型</a>，支持英文输入</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis">huggingface space</a></p>
<p>model weights:</p>
<table>
<thead>
<tr>
<th>weight path</th>
<th>weight size</th>
<th>model name</th>
<th>author</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/text-to-video-ms-1.7b">text-to-video-ms-1.7b</a></td>
<td>unknown</td>
<td>unknown</td>
<td>damo-vilab</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/modelscope-damo-text-to-video-synthesis">modelscope-damo-text-to-video-synthesis</a></td>
<td>unknown</td>
<td>unknown</td>
<td>damo-vilab</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://huggingface.co/damo-vilab/text-to-video-ms-1.7b-legacy">text-to-video-ms-1.7b-legacy</a></td>
<td>unknown</td>
<td>unknown</td>
<td>damo-vilab</td>
</tr>
</tbody></table>
<p>can also use from modelscope:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> modelscope.utils.constant <span class="keyword">import</span> Tasks</span><br><span class="line">p = pipeline(<span class="string">&#x27;text-to-video-synthesis&#x27;</span>, <span class="string">&#x27;damo/text-to-video-synthesis&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/PAIR">PAIR</a> now releases <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/PAIR/Text2Video-Zero">Text2Video-Zero</a> which leverages existing stable diffusion models to generate video. also released a bunch of controlnet dreambooth weights.</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains">lucidrains</a> is a workaholic on transformer implementations. we should scrape all the repos and index them. there are <a target="_blank" rel="noopener" href="https://github.com/lucidrains/memory-efficient-attention-pytorch">faster language models</a> to train.</p>
<hr>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/phenaki-pytorch">Phenaki Video</a>, which uses Mask GIT to produce text guided videos of up to 2 minutes in length, in Pytorch</p>
<p><a target="_blank" rel="noopener" href="https://dreamix-video-editing.github.io/">dreamix</a> (not open-source)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/timothybrooks/instruct-pix2pix">instruct-pix2pix</a> requires 16GB+ VRAM</p>
<p><a target="_blank" rel="noopener" href="https://github.com/omerbt/Text2LIVE">text2live</a> modify video by text prompt (such as add fire in mouth)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/recurrent-interface-network-pytorch">recurrent-interface-network-pytorch</a> using diffusion to generate images and video</p>
<p>high quality! <a target="_blank" rel="noopener" href="https://github.com/lucidrains/imagen-pytorch/blob/main/imagen_pytorch/imagen_video.py">imagegen-video code</a> with <a target="_blank" rel="noopener" href="https://imagen.research.google/video/">demo</a> and <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.02303.pdf">paper</a></p>
<p>抄视频 视频的时间要讲究 看看是抄一年前的好还是抄刚刚发布的好</p>
<p>在发布的一个视频当中 最多抄某个作者的两三个符合要求的片段</p>
<p>use editly smooth&#x2F;slick transitions and subtitles to beat the copy-detection algorithm, also consider color change in ffmpeg</p>
<p>动态 专栏也可以抄</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/make-a-video-pytorch">make-a-video</a></p>
<p>谷歌AI歌手震撼来袭！AudioLM简单听几秒，便能谱曲写歌 <a target="_blank" rel="noopener" href="https://www.kuxai.com/article/398">https://www.kuxai.com/article/398</a></p>

	
	</div>
  <a type="button" href="/blog/2022/10/09/93902e98-2508-4d74-80af-9afb6ecff3ae/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-09-17 </div>
			<div class="article-title"><a href="/blog/2022/09/17/4ab0471b-4672-43d3-9407-72131934ae43/" title="This article explores various AI projects, including AGI, deep reinforcement learning, cognitive science, and sensor-based learning. Additionally, it provides resources such as GitHub repositories and papers to assist those interested in further understanding these cutting-edge technologies.">AGI (Artificial General Intelligence) related projects</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>said by <a target="_blank" rel="noopener" href="https://github.com/numenta/nupic.torch">HTM</a>, AGI knows what it did to the world (self-awareness), also signals from sensors.</p>
<h2 id="google-research"><a href="#google-research" class="headerlink" title="google research"></a><a target="_blank" rel="noopener" href="https://github.com/google-research/google-research">google research</a></h2><p>gwern wrote a <a target="_blank" rel="noopener" href="https://www.gwern.net/fiction/Clippy">fiction</a>. he thinks agi starts from <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research/tree/master/automl_zero">automl-zero</a> which is similar to <a target="_blank" rel="noopener" href="https://github.com/James4Ever0/lazero">lazero</a> and <a target="_blank" rel="noopener" href="https://gitee.com/x00e0d991e368/metalazero">metalazero</a> by name and perspective.</p>
<p>by design lazero can be deeply aligned, inspecting and studying user’s actions. it also has its own exploration space. however, these expectations can never be fully satisfied at the same time. if you want more power, you have to let go.</p>
<h2 id="lucidrains-repositories"><a href="#lucidrains-repositories" class="headerlink" title="lucidrains repositories"></a><a target="_blank" rel="noopener" href="https://github.com/lucidrains?tab=repositories">lucidrains</a> repositories</h2><p>this one got lots of state-of-the-art implementations for close-sourced papers and also repos for AGI. stunning.</p>
<h3 id="AGI-related"><a href="#AGI-related" class="headerlink" title="AGI related"></a>AGI related</h3><p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/JEPA-pytorch">JEPA-pytorch</a> (WIP) yann lecun’s version how agi will be built</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/PaLM-pytorch">PaLM</a> scaling language model with pathways</p>
<h3 id="side-projects"><a href="#side-projects" class="headerlink" title="side projects"></a>side projects</h3><p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/make-a-video-pytorch">make a video</a> text to video generation</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/nuwa-pytorch">nuwa</a> text to video generation</p>
<h2 id="opencog"><a href="#opencog" class="headerlink" title="opencog"></a><a target="_blank" rel="noopener" href="https://wiki.opencog.org/">opencog</a></h2><p><a target="_blank" rel="noopener" href="https://wiki.opencog.org/w/Meta-Optimizing_Semantic_Evolutionary_Search">moses</a> (supervised) for evolutionary program synthesis</p>
<h2 id="repos-on-github"><a href="#repos-on-github" class="headerlink" title="repos on github"></a><a target="_blank" rel="noopener" href="https://github.com/topics/artificial-general-intelligence">repos on github</a></h2><p><a target="_blank" rel="noopener" href="https://github.com/jiaxiaogang/he4o">he4o</a></p>
<p><a target="_blank" rel="noopener" href="https://www.aslanides.io/aixijs/">aixijs</a> general reinforcement learning in browser <a target="_blank" rel="noopener" href="https://github.com/aslanides/aixijs">repo</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/opennars/opennars">opennars</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/FutureAIGuru/BrainSimII">brain simulator 2</a> on windows platform</p>
<h2 id="materials-and-links"><a href="#materials-and-links" class="headerlink" title="materials and links"></a>materials and links</h2><p><a target="_blank" rel="noopener" href="https://github.com/tigerneil/awesome-deep-rl/blob/master/DQfD.md">DQfD: Learning from Demonstrations for Real World Reinforcement Learning</a> (<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1704.03732.pdf">paper</a>)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/pursh2002/MIT-6.S099-Artificial-General-Intelligence-">mit class on AGI</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/jiaxiaogang/HELIX_THEORY">jiaxiaogang’s god-knows-what theory and training logs</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tigerneil/awesome-deep-rl">awesome deep reinforcement learning (deep-rl)</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/YuzheSHI/awesome-agi-cocosci">awesome agicocosci</a> exhausitive list of papers and repos for cognitive science and AGI</p>
<p><a target="_blank" rel="noopener" href="https://github.com/guardians-of-life/awesome-artificial-general-intelligence">introduction and links on AGI</a></p>

	
	</div>
  <a type="button" href="/blog/2022/09/17/4ab0471b-4672-43d3-9407-72131934ae43/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-08-26 </div>
			<div class="article-title"><a href="/blog/2022/08/26/4da1c86b-86b6-49c6-a581-6289c6635ec7/" title="The article discusses AI-assisted live streaming, its capabilities in audience data utilization for content classification, and how it handles miscommunication and apologetic interactions between users.">Unlocking the Potential of AI-Assisted Live Streaming and Audience Data</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="关于直播的思路"><a href="#关于直播的思路" class="headerlink" title="关于直播的思路"></a>关于直播的思路</h1><p>可以用长音频 长视频替代直播源</p>
<p>Yukio 23:00:49</p>
<p>这个我还在研究这玩意</p>
<p>卑劣的写作者 23:01:13</p>
<p>[图片]</p>
<p>Yukio 23:01:19</p>
<p>尤其是怎么把别人的皮套拿来当成自己的</p>
<p>Yukio 23:01:44</p>
<p>追踪虚拟Vtuber的动作然后放到我的皮套上</p>
<p>Yukio 23:02:50</p>
<p>搞媒体不都靠抄么</p>
<p>Yukio 23:03:38</p>
<p>你们要是能把别人一个月之前的直播弄下来 视频音频分别杂交处理一下 弄的人看不出来是抄的</p>
<p>卑劣的写作者 23:03:48</p>
<p>那不是塞里斯特色媒体吗</p>
<p>Yukio 23:03:50</p>
<p>你就躺赚啊</p>
<p>gjz010 23:03:52</p>
<p>你偷大物皮套感觉会被版权炸弹</p>
<p>gjz010 23:04:13</p>
<p>你看即使是怪盗也不敢把自己的皮套偷过来用</p>
<p>gjz010 23:04:48</p>
<p>那你还不如用阿b的公用皮套</p>
<p>Yukio 23:04:49</p>
<p>你随便弄个b站提供的免费皮套</p>
<p>Yukio 23:05:00</p>
<p>或者原神的</p>
<p>Yukio 23:05:32</p>
<p>一天换一个啊 肯定有人看的</p>
<p>gjz010 23:05:44</p>
<p>也不一定</p>
<p>gjz010 23:05:58</p>
<p>皮套有商标的意味</p>
<p>Yukio 23:06:03</p>
<p>把别人的皮套动作追踪之后 绑定到免费皮套上面</p>
<p>gjz010 23:06:14</p>
<p>啥 皮套动作不都是跟着你走的吗</p>
<p>gjz010 23:06:20</p>
<p>偷别人的动作有啥用</p>
<p>Yukio 23:06:20</p>
<p>把别人的中文语音截取下来 随机播放</p>
<p>gjz010 23:06:30</p>
<p>你还不如找个ai念</p>
<p>Yukio 23:06:39</p>
<p>我为什么要绑我的动作</p>
<p>gjz010 23:06:54</p>
<p>就是不追踪瞎摇的</p>
<p>gjz010 23:07:01</p>
<p>动捕坏了的时候用</p>
<p>Yukio 23:07:08</p>
<p>我这个不是瞎摇晃</p>
<p>Yukio 23:07:18</p>
<p>我这个是重播</p>
<p>Yukio 23:07:36</p>
<p>把别人的动作再播送一遍</p>
<p>Yukio 23:07:49</p>
<p>所以只要你记忆力没有一个月</p>
<p>Yukio 23:07:59</p>
<p>没法把全网的直播都看一遍</p>
<p>Yukio 23:08:14</p>
<p>你不可能知道我究竟这期节目抄的谁</p>
<p>Yukio 23:08:41</p>
<p>我不仅动作和语音不是一个人 画面也是另外一个人</p>
<p>卑劣的写作者 23:08:58</p>
<p>？</p>
<p>Yukio 23:09:12</p>
<p>我还会把所有和原作者有关的东西自动清除</p>
<p>Yukio 23:09:24</p>
<p>比如任何QQ号码 任何联系方式</p>
<p>卑劣的写作者 23:09:26</p>
<p>这人不能处</p>
<p>Yukio 23:09:37</p>
<p>任何作者署名</p>
<p>Yukio 23:10:32</p>
<p>我会把语音变声处理</p>
<p>Yukio 23:11:51</p>
<p>只要有机会 我直接下载外网twitch直播 把国内的语音放上来 都是同类游戏</p>
<p>Yukio 23:14:06</p>
<p>我用谷歌翻译流行的游戏名字 拿到外网去搜索</p>
<p>Yukio 23:16:17</p>
<p>同时我还有一个自动读评论的插件</p>
<p>Yukio 23:16:36</p>
<p>每隔几分钟读一次 让你们以为这是个真人</p>
<p>Yukio 23:17:03</p>
<p>我通过图片截图搜索 得到游戏名字</p>
<p>Yukio 23:17:45</p>
<p>通过相似图片得到关键词 生成标题 主题 标签 分区</p>
<p>Yukio 23:20:47</p>
<p>皮套人的动作有自动过渡系统</p>
<p>Yukio 23:20:57</p>
<p>不会出现跳变</p>
<p>Yukio 23:22:47</p>
<p>利用智能匹配 选取最适合的主题 动作 语音 自动生成连续的内容</p>
<p>小晴清风揽月 23:24:01</p>
<p>见到皮套人就恶心</p>
<p>Yukio 23:24:19</p>
<p>皮套人是资本收割机</p>
<p>Yukio 23:24:38</p>
<p>可以把处男的jy转化为软妹币</p>
<p>Yukio 23:24:58</p>
<p>非常的节能环保 非常高效</p>
<p>重庆人快融化啦 23:26:20</p>
<p>[图片]</p>
<p>Yukio 23:26:40</p>
<p>如果我算力充足 完全可以跳出这个抄别人的逻辑 进行完全的所谓原创直播</p>
<p>Yukio 23:27:10</p>
<p>但是就一台笔记本 抄直播是最为经济有效的</p>
<p>Yukio 23:28:01</p>
<p>也为之后定制更高端的原创模型打好基础</p>
<p>Yukio 23:30:30</p>
<p>我可以用观众的弹幕数据作为搜索分类的数据 可以拿来衡量情绪激烈程度</p>
<p>Yukio 23:30:56</p>
<p>语音数据也是如此</p>
<p>小晴清风揽月 23:30:56</p>
<p>你语言混乱，先去看看医生</p>
<p>Yukio 23:31:06</p>
<p>不需要</p>
<p>Yukio 23:31:28</p>
<p>觉得我混乱的 你压根还不懂</p>
<p>Yukio 23:31:42</p>
<p>也就是没想清楚</p>
<p>小晴清风揽月 23:32:01</p>
<p>我开玩笑的</p>
<p>小晴清风揽月 23:32:08</p>
<p>对不起</p>
<p>小晴清风揽月 23:32:16</p>
<p>我只是在学仰山杨爱民说话</p>

	
	</div>
  <a type="button" href="/blog/2022/08/26/4da1c86b-86b6-49c6-a581-6289c6635ec7/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-08-09 </div>
			<div class="article-title"><a href="/blog/2022/08/09/7b4c3b5b-427d-45d2-9daf-caf2dea62597/" title="This article introduces several open-source tools for image and video data labeling, such as OpenLabeler, Anno-Mage, CATMAID, and makesense.ai. Additionally, it covers 2D/3D tools that can be applied to various applications, including neural morphology and LIDAR datasets.">awesome-data-labeling</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>A curated list of awesome data labeling tools</p>
<h4 id="Images"><a href="#Images" class="headerlink" title="Images"></a>Images</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/tzutalin/labelImg">labelImg</a> - LabelImg is a graphical image annotation tool and label object bounding boxes in images</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/opencv/cvat">CVAT</a> - Powerful and efficient Computer Vision Annotion Tool</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/wkentaro/labelme">labelme</a> - Image Polygonal Annotation with Python</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/microsoft/VoTT">VoTT</a> - An open source annotation and labeling tool for image and video assets</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/NaturalIntelligence/imglab">imglab</a> - A web based tool to label images for objects that can be used to train dlib or other object detectors</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/Yolo_mark">Yolo_mark</a> - GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/abreheret/PixelAnnotationTool">PixelAnnotationTool</a> - Software that allows you to manually and quickly annotate images in directories</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/Cartucho/OpenLabeling">OpenLabeling</a> - Label images and video for Computer Vision applications</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/bit-bots/imagetagger">imagetagger</a> - An open source online platform for collaborative image labeling</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/AlturosDestinations/Alturos.ImageAnnotation">Alturos.ImageAnnotation</a> - A collaborative tool for labeling image data</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/jveitchmichaelis/deeplabel">deeplabel</a> - A cross-platform image annotation tool for machine learning</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/medtagger/MedTagger">MedTagger</a> - A collaborative framework for annotating medical datasets using crowdsourcing.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/Labelbox/Labelbox">Labelbox</a> - Labelbox is the fastest way to annotate data to build and ship computer vision applications</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/jaxony/turktool">turktool</a> - A modern React app for scalable bounding box annotation of images</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/buni-rock/Pixie">Pixie</a> - Pixie is a GUI annotation tool which provides the bounding box, polygon, free drawing and semantic segmentation object labelling</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/kinhong/OpenLabeler">OpenLabeler</a> - OpenLabeler is an open source desktop application for annotating objects for AI appplications</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/virajmavani/semi-auto-image-annotation-tool">Anno-Mage</a> - A Semi Automatic Image Annotation Tool which helps you in annotating images by suggesting you annotations for 80 object classes using a pre-trained model</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/catmaid/CATMAID">CATMAID</a> - Collaborative Annotation Toolkit for Massive Amounts of Image Data</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/SkalskiP/make-sense">make-sense</a> - makesense.ai is a free to use online tool for labelling photos</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/l3p-cv/lost">LOST</a> - Design your own smart Image Annotation process in a web-based environment</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/recogito/annotorious">Annotorious</a> - A JavaScript library for image annotation.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/cvhciKIT/sloth">Sloth</a> - Tool for labeling image and video data for computer vision research.</p>
</li>
</ul>
<h4 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/jiesutd/YEDDA">YEDDA</a> - A Lightweight Collaborative Text Span Annotation Tool (Chunking, NER, etc.). ACL best demo nomination.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/planbrothers/ml-annotate">ML-Annotate</a> - Label text data for machine learning purposes. ML-Annotate supports binary, multi-label and multi-class labeling.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/d5555/TagEditor">TagEditor</a> - Annotation tool for spaCy</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/RTIInternational/SMART">SMART</a> - Smarter Manual Annotation for Resource-constrained collection of Training data</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/etalab/piaf">PIAF</a> - A Question-Answering annotation tool</p>
</li>
</ul>
<h4 id="Audio"><a href="#Audio" class="headerlink" title="Audio"></a>Audio</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/ritazh/EchoML">EchoML</a> - Play, visualize, and annotate your audio files</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/CrowdCurio/audio-annotator">audio-annotator</a> - A JavaScript interface for annotating and labeling audio files.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/hipstas/audio-labeler">audio-labeler</a> - An in-browser app for labeling audio clips at random, using Docker and Flask.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/katspaugh/wavesurfer.js">wavesurfer.js</a> - Simple annotations tool, check the example.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/bbc/peaks.js">peak.js</a> - Browser-based audio waveform visualisation and UI component for interacting with audio waveforms, developed by BBC UK.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/praat/praat">Praat</a> - Doing Phonetics By Computer</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://aubio.org/">Aubio</a> - Tool designed for the extraction of annotations from audio signals.</p>
</li>
</ul>
<h4 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/alexandre01/UltimateLabeling">UltimateLabeling</a> - A multi-purpose Video Labeling GUI in Python with integrated SOTA detector and tracker</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/cvondrick/vatic">VATIC</a> - VATIC is an online video annotation tool for computer vision research that crowdsources work to Amazon’s Mechanical Turk.</p>
</li>
</ul>
<h4 id="Time-Series"><a href="#Time-Series" class="headerlink" title="Time Series"></a>Time Series</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/baidu/Curve">Curve</a> - Curve is an open-source tool to help label anomalies on time-series data</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/Microsoft/TagAnomaly">TagAnomaly</a> - Anomaly detection analysis and labeling tool, specifically for multiple time series (one time series per category)</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/CrowdCurio/time-series-annotator">time-series-annotator</a> - The CrowdCurio Time Series Annotation Library implements classification tasks for time series.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/avenix/WDK">WDK</a> - The Wearables Development Toolkit (WDK) is a set of tools to facilitate the development of activity recognition applications with wearable devices.</p>
</li>
</ul>
<h4 id="3D"><a href="#3D" class="headerlink" title="3D"></a>3D</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/scalableminds/webknossos">webKnossos</a> - webKnossos is an open-source web-based tool for visualizing, annotating, and sharing large 3D image datasets. It features fast 3D data browsing, skeleton (line-segment) annotations, segmentation and proof-reading tools, mesh visualization, and collaboration features. The public instance <a target="_blank" rel="noopener" href="https://webknossos.org/">webknossos.org</a> hosts a collection of published datasets and can be used without a local setup.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/knossos-project/knossos">KNOSSOS</a> - KNOSSOS is a software tool for the visualization and annotation of 3D image data and was developed for the rapid reconstruction of neural morphology and connectivity.</p>
</li>
</ul>
<h4 id="Lidar"><a href="#Lidar" class="headerlink" title="Lidar"></a>Lidar</h4><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor">semantic-segmentation-editor</a> - Web labelling tool for camera and LIDAR data</li>
</ul>
<h4 id="MultiDomain"><a href="#MultiDomain" class="headerlink" title="MultiDomain"></a>MultiDomain</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/heartexlabs/label-studio">Label Studio</a> - Label Studio is a configurable data annotation tool that works with different data types</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://dataturks.com/">Dataturks</a> - Dataturks support E2E tagging of data items like video, images (classification, segmentation and labelling) and text (full length document annotations for PDF, Doc, Text etc) for ML projects.</p>
</li>
</ul>

	
	</div>
  <a type="button" href="/blog/2022/08/09/7b4c3b5b-427d-45d2-9daf-caf2dea62597/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-06-01 </div>
			<div class="article-title"><a href="/blog/2022/06/01/c49f910b-28d0-4837-9d99-581fb70b9e88/" title="This article delves into time series analysis and introduces three projects: Bosun, a tool for time series alerting; deep-learning-time-series, an implementation of deep learning techniques for forecasting; and LSTM-Neural-Network-for-Time-Series-Prediction, a project focusing on using LSTM neural networks to predict stock market trends.">Time Series Analysis</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>Time Series Alerting:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/bosun-monitor/bosun">https://github.com/bosun-monitor/bosun</a></p>
<p>Deep learning time series:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Alro10/deep-learning-time-series">https://github.com/Alro10/deep-learning-time-series</a></p>
<p>LSTM Time series forecast stock market:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction">https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction</a></p>

	
	</div>
  <a type="button" href="/blog/2022/06/01/c49f910b-28d0-4837-9d99-581fb70b9e88/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-31 </div>
			<div class="article-title"><a href="/blog/2022/05/31/560699e6-a134-4857-8cd6-c5832a5b1c16/" title="Sketch-based applications leverage AI technology to transform and bring life to sketches through completion and animation, exemplified by Magenta Studio and Inbetweening.">Sketch based applications</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>magenta studio sketch completion</p>
<p>awesome sketch based applications paper and code sketch syntheses inbetweening:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/MarkMoHR/Awesome-Sketch-Based-Applications#17-sketch-animationinbetweening">https://github.com/MarkMoHR/Awesome-Sketch-Based-Applications#17-sketch-animationinbetweening</a></p>
<p>deep sketch based cartoon inbetweening:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/xiaoyu258/Inbetweening">https://github.com/xiaoyu258/Inbetweening</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/31/560699e6-a134-4857-8cd6-c5832a5b1c16/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-29 </div>
			<div class="article-title"><a href="/blog/2022/05/29/8319a62a-3336-4a1a-a3d5-33c9971c96df/" title="Jina is a neural search engine that enables users to efficiently search for images, videos, and audios. It leverages popular libraries like openclip, haystack, towhee, and Milvus to provide pre-trained models and workflows through Jina Hub. Additionally, VCED offers tutorials in machine learning topics.">Jina: Neural Search Engine for Images, Videos, Audios</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://github.com/mlfoundations/open_clip">openclip</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/deepset-ai/haystack">haystack</a></p>
<p>tutorial: <a target="_blank" rel="noopener" href="https://haystack.deepset.ai/tutorials/03_basic_qa_pipeline_without_elasticsearch">build QA pipeline with no dependencies with haystack</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/towhee-io/towhee">towhee</a></p>
<p><a target="_blank" rel="noopener" href="https://milvus.io/docs/v2.1.x/install_standalone-docker.md">milvus</a></p>
<p>visit <a target="_blank" rel="noopener" href="https://docs.jina.ai/fundamentals/executor/hub/">jina hub</a> to get multiple embedding models and workflows</p>
<p><a target="_blank" rel="noopener" href="https://github.com/datawhalechina/vced/blob/44480a869a57be0d7e3a6f163d499286f65ad86c/docs/source/user_guide/jina.md">jina import video&#x2F;image&#x2F;text</a></p>
<p><a target="_blank" rel="noopener" href="https://finetuner.jina.ai/tasks/text-to-image/">finetuner: text to image search via clip</a></p>
<p>datawhale provides tutorials on machine learning, also provide book materials, topics are: numpy, matplotlib, pandas,</p>
<p><a target="_blank" rel="noopener" href="https://github.com/datawhalechina/vced/tree/44480a869a57be0d7e3a6f163d499286f65ad86c">vced: holy gift from datawhale</a> able to edit video by text, video auto editor, cutter</p>
<p>VCED 可以通过你的文字描述来自动识别视频中相符合的片段进行视频剪辑。该项目基于跨模态搜索与向量检索技术搭建，通过前后端分离的模式，帮助你快速的接触新一代搜索技术。</p>
<p>jina:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jina-ai/jina/">https://github.com/jina-ai/jina/</a></p>
<p>documentation:</p>
<p><a target="_blank" rel="noopener" href="https://docs.jina.ai/">https://docs.jina.ai</a></p>
<p>quick demos:</p>
<p>dress Fashion image search: jina hello fashion</p>
<p>robot QA chatbot: pip install “jina[demo]” &amp;&amp; jina hello chatbot</p>
<p>newspaper Multimodal search: pip install “jina[demo]” &amp;&amp; jina hello multimodal</p>
<p>fork_and_knife Fork the source of a demo to your folder: jina hello fork fashion ..&#x2F;my-proj&#x2F;</p>
<p>Create a new Jina project: jina new hello-jina</p>
<p>ai video metadata generation:</p>

	
	</div>
  <a type="button" href="/blog/2022/05/29/8319a62a-3336-4a1a-a3d5-33c9971c96df/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-29 </div>
			<div class="article-title"><a href="/blog/2022/05/29/5143f988-6ee1-41d3-b04b-1261934000e9/" title="This article highlights several open-source projects that enable image generation from text using models similar to DALL-E. Mentioned projects include DALLE-pytorch, dalle_mini, dalle-flow by Jina AI (a human-in-the-loop multi-prompt tool), and a playground for experimentation called dalle-playground.">DALL_E Text to Image</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>open sourced text to image:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/DALLE-pytorch">https://github.com/lucidrains/DALLE-pytorch</a></p>
<p>dalle_mini:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/borisdayma/dalle-mini">https://github.com/borisdayma/dalle-mini</a></p>
<p>jina ai human in the loop multi prompt text to image dalle-flow:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jina-ai/dalle-flow">https://github.com/jina-ai/dalle-flow</a></p>
<p>dalle playground:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/saharmor/dalle-playground">https://github.com/saharmor/dalle-playground</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/29/5143f988-6ee1-41d3-b04b-1261934000e9/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-24 </div>
			<div class="article-title"><a href="/blog/2022/05/24/fda36896-d174-4011-ae7c-f5e913ea4f74/" title="This article explores different data annotation tools such as Doccano, CVAT with Docker, LabelImg, and label-studio that can be used for text, video/image, images, audio, video, and transcription respectively. Installation is available through pip or GitHub.">AI训练集标注工具</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h2 id="text-annotation-tool"><a href="#text-annotation-tool" class="headerlink" title="text annotation tool:"></a>text annotation tool:</h2><p><a target="_blank" rel="noopener" href="https://github.com/doccano/doccano">https://github.com/doccano/doccano</a></p>
<p>sqlite 3 backend:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip3 install doccano</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="video-image-annotation-tool-needs-docker-with-online-demo"><a href="#video-image-annotation-tool-needs-docker-with-online-demo" class="headerlink" title="video&#x2F;image annotation tool, needs docker, with online demo:"></a>video&#x2F;image annotation tool, needs docker, with <a target="_blank" rel="noopener" href="https://cvat.org/">online demo</a>:</h2><p><a target="_blank" rel="noopener" href="https://github.com/openvinotoolkit/cvat">https://github.com/openvinotoolkit/cvat</a></p>
<h2 id="image-labeling"><a href="#image-labeling" class="headerlink" title="image labeling:"></a>image labeling:</h2><p><a target="_blank" rel="noopener" href="https://github.com/heartexlabs/labelImg">https://github.com/heartexlabs/labelImg</a></p>
<h2 id="with-audio-video-support"><a href="#with-audio-video-support" class="headerlink" title="with audio video support"></a>with audio video support</h2><p><a target="_blank" rel="noopener" href="https://github.com/heartexlabs/label-studio">https://github.com/heartexlabs/label-studio</a></p>
<h2 id="with-audio-transcription-support"><a href="#with-audio-transcription-support" class="headerlink" title="with audio transcription support"></a>with audio transcription support</h2><p><a target="_blank" rel="noopener" href="https://github.com/UniversalDataTool/universal-data-tool">https://github.com/UniversalDataTool/universal-data-tool</a></p>
<h2 id="image-and-audio"><a href="#image-and-audio" class="headerlink" title="image and audio"></a>image and audio</h2><p><a target="_blank" rel="noopener" href="https://github.com/Cartucho/OpenLabeling">https://github.com/Cartucho/OpenLabeling</a></p>
<h2 id="specialized-for-yolo-bounding-boxes"><a href="#specialized-for-yolo-bounding-boxes" class="headerlink" title="specialized for yolo bounding boxes"></a>specialized for yolo bounding boxes</h2><p><a target="_blank" rel="noopener" href="https://github.com/developer0hye/Yolo_Label">https://github.com/developer0hye/Yolo_Label</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/24/fda36896-d174-4011-ae7c-f5e913ea4f74/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
		
		<li class="prev"><a href="/blog/tags/AI/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i> Prev</a></li>
  		

        <li><a href="/blog/"><i class="fa fa-home"></i>Home</a></li>

		
		   <li class="next"> <a href="/blog/tags/AI/page/3/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a> </li>
        
	
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2023 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>