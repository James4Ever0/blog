<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Beta-Binomial likelihoods | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">Beta-Binomial likelihoods</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-12-18 </div>
			<div class="article-title"><a href="/blog/2022/12/18/ca3e1b76-cbfa-4656-b026-6e684d808de4/" title="Pyro and PyMC3 are programming languages designed for probabilistic programming. PyMC3, in particular, utilizes Beta-Binomial likelihoods, Markov Chain Monte Carlo (MCMC) techniques, and Gamma priors for creating models, sampling data, and calculating statistics.">Pyro And Pymc3 Basics</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://github.com/paraschopra/bayesian-neural-network-mnist">using pyro for mnist classification</a> and <a target="_blank" rel="noopener" href="https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch-b1c24e6ab8cd">tutorial</a> (benefits: knowing if it doesn’t know what’s in front)</p>
<h2 id="demonstrate-basic-usage-of-pyro"><a href="#demonstrate-basic-usage-of-pyro" class="headerlink" title="demonstrate basic usage of pyro"></a>demonstrate basic usage of <a target="_blank" rel="noopener" href="http://pyro.ai/examples/intro_long.html">pyro</a></h2><p>Pyro is a probabilistic programming language developed by Uber that allows users to define complex probabilistic models and perform Bayesian inference on them. Here is a simple example of how Pyro can be used to define and sample from a simple probabilistic model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyro</span><br><span class="line"><span class="keyword">import</span> pyro.distributions <span class="keyword">as</span> dist</span><br><span class="line"><span class="comment"># Define a simple probabilistic model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model</span>():</span><br><span class="line"><span class="comment"># Sample a value from a normal distribution</span></span><br><span class="line">x = pyro.sample(<span class="string">&quot;x&quot;</span>, dist.Normal(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># Condition the model on a Bernoulli distribution</span></span><br><span class="line">pyro.sample(<span class="string">&quot;y&quot;</span>, dist.Bernoulli(logits=x), obs=x &gt; <span class="number">0</span>)</span><br><span class="line"><span class="comment"># Clear the Pyro cache and run the model</span></span><br><span class="line">pyro.clear_param_store()</span><br><span class="line">svi = pyro.infer.SVI(model, pyro.infer.JitTraceEnum_ELBO(), pyro.optim.Adam(&#123;<span class="string">&quot;lr&quot;</span>: <span class="number">0.01</span>&#125;))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">svi.step()</span><br><span class="line"><span class="comment"># Sample from the posterior distribution</span></span><br><span class="line">posterior = pyro.infer.Posterior(model)</span><br><span class="line">samples = posterior.sample((<span class="number">1000</span>,))</span><br><span class="line"><span class="comment"># Print the mean and standard deviation of the samples</span></span><br><span class="line"><span class="built_in">print</span>(samples.mean())</span><br><span class="line"><span class="built_in">print</span>(samples.std())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>In this example, we define a simple model that samples a value from a normal distribution and conditions it on a Bernoulli distribution. We then use the SVI (stochastic variational inference) algorithm to perform approximate Bayesian inference on the model. Finally, we sample from the posterior distribution and print the mean and standard deviation of the samples.</p>
<p>This is just a simple example of what you can do with Pyro. There are many more advanced features and techniques available in the library, including support for discrete and continuous latent variables, transformations, and more. You can find more information about Pyro in the documentation and examples available on the Pyro website.</p>
<h2 id="compare-pyro-to-pymc3"><a href="#compare-pyro-to-pymc3" class="headerlink" title="compare pyro to pymc3"></a>compare pyro to pymc3</h2><p>Pyro and PyMC3 are both probabilistic programming languages that allow users to define complex probabilistic models and perform Bayesian inference on them. Both Pyro and PyMC3 are built on top of PyTorch, a popular machine learning library, and they share many features and capabilities. However, there are also some key differences between the two languages.</p>
<p>One of the main differences between Pyro and PyMC3 is the way they represent probabilistic models. Pyro uses a language called “PyroScript” to define models, which is a variant of Python that includes special statements for defining random variables and specifying probabilistic dependencies. PyMC3, on the other hand, uses a more traditional approach where models are defined using objects and functions.</p>
<p>Another difference between the two languages is the type of inference algorithms they support. Pyro includes a variety of inference algorithms, including both variational inference and Monte Carlo methods, while PyMC3 is primarily focused on Markov chain Monte Carlo (MCMC) techniques.</p>
<p>Overall, both Pyro and PyMC3 are powerful probabilistic programming languages that can be used to define and analyze complex probabilistic models. Which one is the best fit for your needs will depend on your specific requirements and preferences.</p>
<h2 id="demonstrate-usage-of-pymc3"><a href="#demonstrate-usage-of-pymc3" class="headerlink" title="demonstrate usage of pymc3"></a>demonstrate usage of pymc3</h2><p>Here is an example of how PyMC3 can be used to define and analyze a simple probabilistic model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymc3 <span class="keyword">as</span> pm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># Define a simple model</span></span><br><span class="line"><span class="keyword">with</span> pm.Model() <span class="keyword">as</span> model:</span><br><span class="line"><span class="comment"># Sample a value from a normal distribution</span></span><br><span class="line">x = pm.Normal(<span class="string">&quot;x&quot;</span>, mu=<span class="number">0</span>, sigma=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Condition the model on a Bernoulli distribution</span></span><br><span class="line">y = pm.Bernoulli(<span class="string">&quot;y&quot;</span>, p=pm.math.sigmoid(x), observed=x &gt; <span class="number">0</span>)</span><br><span class="line"><span class="comment"># Sample from the posterior distribution using the NUTS algorithm</span></span><br><span class="line"><span class="keyword">with</span> model:</span><br><span class="line">trace = pm.sample(<span class="number">1000</span>, tune=<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># Extract the samples and calculate the mean and standard deviation</span></span><br><span class="line">samples = trace[<span class="string">&quot;x&quot;</span>]</span><br><span class="line">mean = np.mean(samples)</span><br><span class="line">std = np.std(samples)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean: <span class="subst">&#123;mean:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Standard deviation: <span class="subst">&#123;std:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>In this example, we define a simple model that samples a value from a normal distribution and conditions it on a Bernoulli distribution. We then use the NUTS (No-U-Turn Sampler) algorithm to sample from the posterior distribution. Finally, we extract the samples and calculate the mean and standard deviation of the distribution.</p>
<p>This is just a simple example of what you can do with PyMC3. There are many more advanced features and techniques available in the library, including support for discrete and continuous latent variables, transformations, and more. You can find more information about PyMC3 in the documentation and examples available on the PyMC3 website.</p>
<h2 id="show-me-the-model-written-in-pymc3-and-how-to-train-it-with-code-assume-data-is-obtained"><a href="#show-me-the-model-written-in-pymc3-and-how-to-train-it-with-code-assume-data-is-obtained" class="headerlink" title="show me the model written in pymc3 and how to train it with code, assume data is obtained"></a>show me the model written in pymc3 and how to train it with code, assume data is obtained</h2><p>Here is an example of a simple natural language generator model written in PyMC3:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymc3 <span class="keyword">as</span> pm</span><br><span class="line"><span class="comment"># Define the model</span></span><br><span class="line"><span class="keyword">with</span> pm.Model() <span class="keyword">as</span> model:</span><br><span class="line"><span class="comment"># Define the priors for the model parameters</span></span><br><span class="line">alpha = pm.Gamma(<span class="string">&#x27;alpha&#x27;</span>, alpha=<span class="number">1</span>, beta=<span class="number">1</span>)</span><br><span class="line">beta = pm.Gamma(<span class="string">&#x27;beta&#x27;</span>, alpha=<span class="number">1</span>, beta=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Define the likelihood function</span></span><br><span class="line">likelihood = pm.BetaBinomial(<span class="string">&#x27;likelihood&#x27;</span>, alpha=alpha, beta=beta, observed=data)</span><br><span class="line"><span class="comment"># Fit the model to the data using MCMC</span></span><br><span class="line"><span class="keyword">with</span> model:</span><br><span class="line">trace = pm.sample(draws=<span class="number">1000</span>, tune=<span class="number">1000</span>, chains=<span class="number">4</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>This model defines a Beta-Binomial distribution as the likelihood function, with alpha and beta as the model parameters. The alpha and beta parameters are given Gamma priors, which are a type of continuous probability distribution.</p>
<p>To train the model, we can use the sample function from PyMC3 to fit the model to the data using Markov chain Monte Carlo (MCMC) techniques. The draws argument specifies the number of samples to draw from the posterior distribution, the tune argument specifies the number of tuning samples to use, and the chains argument specifies the number of chains to run.</p>
<p>It is important to note that this is just a simple example of a natural language generator model written in PyMC3. In practice, the model architecture and training process will depend on the specific requirements and goals of your application, as well as the characteristics of the training data.</p>

	
	</div>
  <a type="button" href="/blog/2022/12/18/ca3e1b76-cbfa-4656-b026-6e684d808de4/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://yubingtao.netlify.app/" title="Yubingtao's Blog" target="_blank"]);">Yubingtao&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2024 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>