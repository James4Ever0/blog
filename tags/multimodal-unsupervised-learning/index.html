<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>multimodal unsupervised learning | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">multimodal unsupervised learning</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2024-02-28 </div>
			<div class="article-title"><a href="/blog/2024/02/28/a6499fb6-03ac-4ee9-92ce-be530c73efb6/" title="The article delves into various topics including multimodal unsupervised learning, Kaggle login security, token encoding with GPT2 and LLaMA, ViT adaptation, Genie architecture, prompt-based image/video editing, and cautions against NTFS usage in Linux. It also offers detailed instructions on PyTorch GPU installation, environment variable settings, manual token encoding, custom embedding, and exploring multimodal learning applications.">Multimodal Autoregressive Unsupervised Learning</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>It is so good that I can login to Kaggle on smartphone.</p>
<hr>
<p>Instruction following image editing via prompt engineering like <a target="_blank" rel="noopener" href="https://minidalle3.github.io/">Mini DALLE3</a> or multimodal model like <a target="_blank" rel="noopener" href="https://github.com/THUDM/CogCoM">CogCoM</a></p>
<hr>
<p>Recently search engine &amp; browser augmented generation has become popular. A great tool for creating video scripts.</p>
<hr>
<p>Google has released a new architecure called Genie, which can generate latent action space only using video unsupervised training.</p>
<hr>
<p>Do not ever use NTFS in Linux. If you unfortunatedly face disk inaccessible problem when accessing NTFS disks, in the first case run chkdsk &#x2F;f onthen reboot into Windows twice. The usage of the &#x2F;f parameter iimportant!</p>
<p>After fixing, copy all files to another place, format the disk into ext4 or xfs, then recover the files.</p>
<hr>
<p>GPT2 models from huggingface accept <code>inputs_embeds</code> as parameter of instance call and method “generate”.</p>
<p>Typically to adapt ViT into LLM you need <code>LayerNorm</code> and a linear projection layer.</p>
<p>You cannot put custom embedding into text generaton pipeline.</p>
<hr>
<p>To encode token manually in GPT2:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inputs_embeds = model.transformer.wte(input_ids)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>In LLaMA:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">embed_tokens</span>(<span class="params">self，token_ids</span>):</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">hasattr</span>(self.llama_model.base_model, <span class="string">&quot;model&quot;</span>): <span class="comment"># with lora</span></span><br><span class="line">embeds = self.llama_model.base_model.model.model.embed_tokens(token_ids)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">self.llama_model.base_model.embed_tokens(token_ids)</span><br><span class="line"><span class="keyword">return</span> embeds</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<p>Install pytorch gpu with conda:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<p>Set <code>HF_HUB_OFFLINE=1</code> while loading local models, to prevent accessing network.</p>
<hr>
<p>Set <code>Environment=&quot;OLLAMA_MODELS=&lt;model_storage_path&gt;&quot;</code> in ollama systemd service file. Remember to change username and usergroup too, and set appropriate permission to model storage path.</p>
<p>In Windows, set it in system environment variables, or create a directory symlink by:</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mklink /D C:\Users\&lt;User&gt;\.ollama\models E:\AI\Ollama\Models</span><br><span class="line"></span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/blog/2024/02/28/a6499fb6-03ac-4ee9-92ce-be530c73efb6/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://yubingtao.netlify.app/" title="Yubingtao's Blog" target="_blank"]);">Yubingtao&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2024 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>