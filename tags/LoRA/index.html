<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>LoRA | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">LoRA</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-05-04 </div>
			<div class="article-title"><a href="/blog/2023/05/04/d361bf81-d50c-4031-af5e-cf0d860f5bff/" title="This article provides detailed information on a wide range of topics, including creating tokenizers and embeddings using ChatGPT-derived projects, remotely controlling OBS, handling complex neural networks, generating multimodal data output, utilizing LoRA for AI model performance improvement, annotating datasets, developing task-specific embeddings in classification models, working with various libraries for managing neural networks, considering VNC server factors, using `webdav-cli`, recording video on Ubuntu ARM VM, adjusting display settings in UTM VMs, and resizing UTM VM disks via virtio disk resizing and Gparted.">Agi That Controls Computer</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>make specialized (in RPA) tokenizer and embedding for this new model. add new words to the tokenizer.</p>
<hr>
<p>you can just boot ubuntu&#x2F;kali&#x2F;parrot iso without installing.</p>
<p>but that would make us embarrasing. we need to check for the option.</p>
<hr>
<p>use ChatGPT-derived projects for localized propaganda on CyberGod and The Frozen Forest.</p>
<h2 id="obs-remote-control"><a href="#obs-remote-control" class="headerlink" title="obs remote control"></a>obs remote control</h2><p>using <a target="_blank" rel="noopener" href="https://github.com/obsproject/obs-websocket">obs-websocket</a> you can use python to do real scripting. but first spin up obs first (with websocket related commandline arguments)</p>
<p>launch obs in minimized way <code>obs --minimize-to-tray</code> or just using xvfb.</p>
<p>you can also write and load scripts for obs, run on custom intervals and conditions.</p>
<h2 id="audio-recording"><a href="#audio-recording" class="headerlink" title="audio recording"></a>audio recording</h2><p>your OS may go slient if you want to record audio from “speakers”</p>
<hr>
<p>using pyaudio, on macos, you need blackhole for sending all audio to oblivion, thus able to be recorded.</p>
<p>on Linux, you need audio loopback device.</p>
<p>run: <code>sudo modprobe snd-aloop</code></p>
<p>you use <code>hw:1:0</code> or “Analog Device Output” for slient output&#x2F;speaker, and use <code>hw:1:1</code> or “Analog Device Input” for recording.</p>
<h2 id="benchmarks"><a href="#benchmarks" class="headerlink" title="benchmarks"></a>benchmarks</h2><p>it is always a mystery for us to develop the right ML model. however, we can setup guidelines of good performance over specific task.</p>
<p>automate the benchmark, setup metrics. there could be more room for trials and imagination.</p>
<h2 id="encoding"><a href="#encoding" class="headerlink" title="encoding"></a>encoding</h2><p>use hfft&#x2F;rfft to transform multipart inputs (special bits, different part of mouse coords (x, y, dx, dy))</p>
<p>if you want to use complex number as RNN input, you may need to swap ViT for ComplexConv2D, but maybe you just need a few.</p>
<hr>
<p>libraries that handle complex neural networks:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/wavefrontshaping/complexPyTorch">complexPyTorch</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/soumickmj/pytorch-complex">pytorch-complex</a></p>
<h2 id="multimodal"><a href="#multimodal" class="headerlink" title="multimodal"></a>multimodal</h2><p>do our model have to output multimodal data?</p>
<p>if you combine some “special” bits along with token embeding by ihfft, you may have to retrain the entire damn network. also in order to make way for special bits, you may have to introduce extra linear layer.</p>
<hr>
<p>some may prefer “LoRA”? by only introducing few tunable params and changing the overall output?</p>
<hr>
<p>we may not annotate anything in our dataset. in contrast, we will set goals and make multiple interfaces for our model to explore.</p>
<hr>
<p>you can add special task specific embedding before passing to main model, then minus that task specific embedding after passing to classification model.</p>
<h2 id="file-sharing-and-communication"><a href="#file-sharing-and-communication" class="headerlink" title="file sharing and communication"></a>file sharing and communication</h2><p>make sure you don’t share important files as read&#x2F;write on VM.</p>
<hr>
<p>you may host some “execution server” on UTM VMs. you may expose your very large hard disk using WebDAV server. i think x11vnc and other vnc server may suffice for linux, but we always want to listen to the real operational data, including human operation&#x2F;intervention, not just those in VNC protocols.</p>
<hr>
<p>WebDAV servers:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mar10/wsgidav">wsgidav</a> (python)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wsgidav --host=192.168.64.1 --port=8081 --root=<span class="string">&quot;/Volumes/Toshiba XG3/works/agi_computer_control&quot;</span>  --auth=anonymous</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://github.com/svtslv/webdav-cli">webdav-cli</a> （nodejs)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">webdav-cli --host=192.168.64.1 --port=8081 --username=root --password=root --path=<span class="string">&quot;/Volumes/Toshiba XG3/works/agi_computer_control&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="video-recording"><a href="#video-recording" class="headerlink" title="video recording"></a>video recording</h2><p>for Ubuntu ARM VM, <code>mss</code> failed on wayland but <code>pyautogui</code> works in both cases. write one python script to pipe raw images to ffmpeg for better compression ratio by shell. the final video is not “time-accurate”. it is frame by frame, matched with timestamps.</p>
<hr>
<p>forcing ubuntu to use xorg by: <code>sudo vim /etc/gdm3/custom.conf</code></p>
<h2 id="resize-UTM-VM-disks"><a href="#resize-UTM-VM-disks" class="headerlink" title="resize UTM VM disks"></a>resize UTM VM disks</h2><p>you need to first resize the virtio disk in utm setting, then resize partition by using gparted, then <a target="_blank" rel="noopener" href="https://www.albertyw.com/note/resizing-ubuntu-utm#:~:text=For%20an%20Ubuntu%20guest%20OS%20running%20a%20default,be%20corrected%20by%20w%20%28rite%29%20warning%20More%20items">update the device mapper</a></p>

	
	</div>
  <a type="button" href="/blog/2023/05/04/d361bf81-d50c-4031-af5e-cf0d860f5bff/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-04-02 </div>
			<div class="article-title"><a href="/blog/2023/04/02/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/" title="This article highlights the use of GGML, LoRA, and LangChain to improve LLM inference on standard hardware by overcoming storage and computation limitations. Quantization techniques are employed, and an API is implemented to retrieve tokens from a server for matching behavior. The provided reference projects focus on conversational LLMs.">Chatgpt Local Version</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>Run some community contributed ChatGPT-like models on commondity PCs.</p>
<h2 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h2><p>Below are some models we are about to use:</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/BlinkDL/ChatRWKV">ChatRWKV</a>, or <a target="_blank" rel="noopener" href="https://github.com/BlinkDL/RWKV-LM">RWKV</a>-based models, some are <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Hazzzardous/RWKV-Instruct">fine-tuned on alpaca dataset</a>.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">ChatGLM-6B</a>, open-sourced by Tsinghua KEG, with <a target="_blank" rel="noopener" href="https://huggingface.co/silver/chatglm-6b-int4-slim">INT4 quantized version</a>.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://huggingface.co/OpenAssistant">OpenAssistant</a> by LAION-AI, trained on their own <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/laion/OIG">OIG dataset</a>. There are also <a target="_blank" rel="noopener" href="https://huggingface.co/Rallio67">few models</a> contributed by their <a target="_blank" rel="noopener" href="https://ykilcher.com/open-assistant-discord">discord community</a>.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/tatsu-lab/standford_alpaca">Alpaca</a>, trained on alpaca dataset (synthetic, generated by ChatGPT) by Standford University. Model weights are <a target="_blank" rel="noopener" href="https://github.com/antimatter15/alpaca.cpp">community provided</a>.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://huggingface.co/ClueAI/ChatYuan-large-v1">ChatYuan</a> by ClueAI.</p>
</li>
</ul>
<p>There are quite a few more models to be listed. You can check <a target="_blank" rel="noopener" href="https://github.com/nichtdax/awesome-totally-open-chatgpt">this curated open-sourced ChatGPT-like model list</a> for updates. But for now, these models shall be sufficient.</p>
<h2 id="Quantization-and-Optimization"><a href="#Quantization-and-Optimization" class="headerlink" title="Quantization and Optimization"></a>Quantization and Optimization</h2><p>Floating-point values in model weights are stored as 32bit. Quantization can reduce storage space and computation by switching to 16bit, 8bit or 4bit values. However, most quantized models cannot be trained or fine-tuned, some 16bit models can only be trained on certain architecture of GPUs, such as Ada and Turing.</p>
<p>To make LLM (Large Language Model) inference feasible on common hardware, GPU is usually mandatory. However, most commondity GPUs have smaller VRAM compared to RAM, limiting the size of LLM to be run, thus the capability of the LLM. Most computer have 12GB of VRAM, 32GB of RAM. <a target="_blank" rel="noopener" href="https://github.com/ggerganov/ggml">GGML</a> is a project aiming to make LLM inference on CPU as fast as GPU, utilizing larger RAM compared to VRAM to run larger LLMs. Currently some popular LLMs have been ported to GGML, like <a target="_blank" rel="noopener" href="https://github.com/ggerganov/llama.cpp">LLaMA</a> and <a target="_blank" rel="noopener" href="https://github.com/antimatter15/alpaca.cpp">Alpaca</a>.</p>
<h2 id="Training-and-Fine-tuning"><a href="#Training-and-Fine-tuning" class="headerlink" title="Training and Fine-tuning"></a>Training and Fine-tuning</h2><p>In deeplearning, people tend to tune all parameters during training, requiring much VRAM and time. To train GPT3.5 aka ChatGPT, OpenAI spends millions to rent interconnected A100 GPUs. This is impossible for an individual to afford such.</p>
<p>With technologies like <a target="_blank" rel="noopener" href="https://github.com/microsoft/LoRA">LoRA</a>, by freezing most part of the model and introducing a small fraction of tunable parameters, training requirements can be greatly reduced. One can easily tune <a target="_blank" rel="noopener" href="https://github.com/tolen/alpaca-lora">7B LLaMA</a> or <a target="_blank" rel="noopener" href="https://github.com/Blealtan/RWKV-LM-LoRA">14B RWKV</a> using LoRA on a PC (usually rented on the cloud, such as <a href="www.autodl.com/home">AutoDL</a>) with a single 80GB A100 card and 200GB of RAM.</p>
<h2 id="Prompting-and-Chaining"><a href="#Prompting-and-Chaining" class="headerlink" title="Prompting and Chaining"></a>Prompting and Chaining</h2><p>LLMs are general problem solvers given enough external storage and access to search engines. Text is the only way to language models (not for multimodal LLMs, like <a target="_blank" rel="noopener" href="https://openai.com/research/gpt-4">GPT4</a>, <a target="_blank" rel="noopener" href="https://github.com/OFA-Sys/OFA">OFA</a> or <a target="_blank" rel="noopener" href="https://github.com/microsoft/unilm">UniLM</a>).</p>
<p>To enhance the capability of LLMs, you have to <a target="_blank" rel="noopener" href="https://langchain.readthedocs.io/en/latest/modules/memory/getting_started.html">maintain its memory</a>, <a target="_blank" rel="noopener" href="https://langchain.readthedocs.io/en/latest/modules/agents.html">define action keywords and trigger external actions</a> during the conversation, connect it to <a target="_blank" rel="noopener" href="https://github.com/deepset-ai/haystack">semantic search engines</a> powered by other AI models like <a target="_blank" rel="noopener" href="https://www.sbert.net/">sentence transformers</a>.</p>
<p>One such library is <a target="_blank" rel="noopener" href="https://langchain.readthedocs.io/en/latest/index.html">LangChain</a>.</p>
<h2 id="Serving-as-API"><a href="#Serving-as-API" class="headerlink" title="Serving as API"></a>Serving as API</h2><p>The process of generation for LLMs is sequential. Server needs to maintain a streaming API to match this behavior. Tokens are fetched one by one from the server with a constant speed, revealed in the frontend.</p>
<p>One can check third-party frontend-only or self-hosted projects for conversational LLMs for reference.</p>

	
	</div>
  <a type="button" href="/blog/2023/04/02/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://yubingtao.netlify.app/" title="Yubingtao's Blog" target="_blank"]);">Yubingtao&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2024 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>