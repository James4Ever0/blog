<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>talking head | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">talking head</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-08-13 </div>
			<div class="article-title"><a href="/blog/2022/08/13/a8d57d12-8153-4cfb-a58f-f7ceb2612412/" title="This article delves into the development of anime-style avatars, emphasizing the significance of 3D models, Linux compatibility, and face tracking tools. It explores various techniques such as moeflow, AniSeg, NextHuman Beta0.9, FaceRig, Style GAN, Python, and facial landmark detection for creating digital people and animating them. Furthermore, it discusses applications like Animoji, VTuber talking heads, and live streaming in the context of this avatar development.">哔哩哔哩 直播姬 2D模型 3D模型</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h2 id="3d-pose-tracker"><a href="#3d-pose-tracker" class="headerlink" title="3d pose tracker"></a><a target="_blank" rel="noopener" href="https://github.com/digital-standard/ThreeDPoseTracker">3d pose tracker</a></h2><p>rendered on unity. needs GPU.</p>
<h2 id="Sysmocap"><a href="#Sysmocap" class="headerlink" title="Sysmocap"></a><a target="_blank" rel="noopener" href="https://github.com/xianfei/SysMocap">Sysmocap</a></h2><p><strong>WHAT I WANT FOR</strong> (or nearly) requires real 3d models, written in javascript</p>
<p>cannot output video?</p>
<p>A cross-platform real-time video-driven motion capture and 3D virtual character rendering system for VTuber&#x2F;Live&#x2F;AR&#x2F;VR.</p>
<p>Does not require a discrete graphics card and runs smoothly even on eight-year-old computers</p>
<h2 id="Vtuber-python-unity"><a href="#Vtuber-python-unity" class="headerlink" title="Vtuber python unity"></a><a target="_blank" rel="noopener" href="https://github.com/mmmmmm44/VTuber-Python-Unity">Vtuber python unity</a></h2><p>search for “vtuber” along with “motion capture” you will get many head-only trackers and renderers for windows but not linux, also some “broadcast templates&#x2F;frameworks”. many support one single image (anime head + remove background) as input instead of 2d&#x2F;3d models</p>
<p>face tracking only, showing face, mouth and eyes, head directions, bind to live2d models</p>
<h2 id="虚拟数字人-metahuman"><a href="#虚拟数字人-metahuman" class="headerlink" title="虚拟数字人 metahuman"></a>虚拟数字人 metahuman</h2><p>NextHuman Beta0.9上线公测，5分钟高品质讲解，带你进入数字人“零门槛”创作新时代，体验直通车 -&gt; <a target="_blank" rel="noopener" href="https://nexthuman.cn/">https://nexthuman.cn</a> 免费版是Windows上面跑的 需要高端1070显卡</p>
<h2 id="anime-character-segmentation"><a href="#anime-character-segmentation" class="headerlink" title="anime character segmentation"></a>anime character segmentation</h2><p>to remove false positives, make sure we have anime face in view, otherwise mark it as a false positive.</p>
<p>you can use anime character recognition like <a target="_blank" rel="noopener" href="https://github.com/freedomofkeima/MoeFlow">moeflow</a> or <a target="_blank" rel="noopener" href="https://github.com/nagadomi/lbpcascade_animeface">opencv anime face detector</a> <strong>along with</strong> some <a target="_blank" rel="noopener" href="http://phash.org/">phash</a> or perceptual hash library to group similar characters, compare perceptual image similarity and line them up in a series.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jerryli27/AniSeg">aniseg, able to segment anime character and head, using mask-rcnn</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/zymk9/Yet-Another-Anime-Segmenter">yet another anime character segmentation model using solov2 and condinst</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Neihtq/waifu-segmentation">waifu segmentation</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/SkyTNT/anime-segmentation">high accuracy anime character segmentation</a></p>
<p>自动画漫画 画几笔就成某个人像 动漫头像</p>
<p><a target="_blank" rel="noopener" href="https://menyifang.github.io/projects/DCTNet/DCTNet.html">https://menyifang.github.io/projects/DCTNet/DCTNet.html</a></p>
<p>自动捏脸 gan给人脸戴口罩</p>
<p><a target="_blank" rel="noopener" href="https://github.com/futscdav/Chunkmogrify">https://github.com/futscdav/Chunkmogrify</a></p>
<h2 id="selfie-to-anime-picture-to-anime-photos"><a href="#selfie-to-anime-picture-to-anime-photos" class="headerlink" title="selfie to anime, picture to anime photos"></a>selfie to anime, picture to anime photos</h2><p><a target="_blank" rel="noopener" href="https://github.com/XingruiWang/Animefy">selfie2anime with trained models</a></p>
<p>##原神mmd下载模型</p>
<p>模之屋（需要注册）：</p>
<p><a target="_blank" rel="noopener" href="https://www.aplaybox.com/u/680828836">https://www.aplaybox.com/u/680828836</a></p>
<p>夕蓝资源网（可直接下载） 也有其他的3d模型可以下载：</p>
<p><a target="_blank" rel="noopener" href="https://www.seoliye.com/tags/53.html">https://www.seoliye.com/tags/53.html</a></p>
<h2 id="use-voice-to-power-up-static-images"><a href="#use-voice-to-power-up-static-images" class="headerlink" title="use voice to power up static images"></a>use voice to power up static images</h2><p><a target="_blank" rel="noopener" href="https://github.com/AnimatePortrait/AnimatePortrait">voice powered animated cartoon figure</a></p>
<h2 id="jeeliz-some-web-deep-learning-runtime-like-tensorflow-js-powered"><a href="#jeeliz-some-web-deep-learning-runtime-like-tensorflow-js-powered" class="headerlink" title="jeeliz (some web deep learning runtime, like tensorflow.js) powered"></a>jeeliz (some web deep learning runtime, like tensorflow.js) powered</h2><p><a target="_blank" rel="noopener" href="https://github.com/jeeliz/jeelizWeboji">weboji, highly similar to animoji, with three.js and cute fox avatar</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/jeeliz/jeelizFaceFilter">face filter, alter the face like putting glass, minor changes to avoid privacy&#x2F;copyright concerns?</a></p>
<h2 id="openface"><a href="#openface" class="headerlink" title="openface"></a>openface</h2><p><a target="_blank" rel="noopener" href="https://github.com/TadasBaltrusaitis/OpenFace">facial features extraction</a></p>
<h2 id="facerig"><a href="#facerig" class="headerlink" title="facerig"></a>facerig</h2><p>facerig location: <code>/Software/Program Files (x86)/FaceRig</code></p>
<p>i’ve seen python code inside facerig.</p>
<p>facerig does not offer head-only rendering, but that could be changed i suppose?</p>
<h2 id="avatarify-python"><a href="#avatarify-python" class="headerlink" title="avatarify python"></a>avatarify python</h2><p><a target="_blank" rel="noopener" href="https://github.com/alievk/avatarify-python">infinite avatars by using style gan, first order motion model</a></p>
<p><a target="_blank" rel="noopener" href="https://pypi.org/project/python-avatars/">create static portrait avatar (svg?)</a></p>
<h2 id="animoji-from-apple"><a href="#animoji-from-apple" class="headerlink" title="animoji from apple"></a>animoji from apple</h2><p><a target="_blank" rel="noopener" href="https://github.com/thevarunsharma/Animoji-Animate">facial landmark detection in python, animoji-animate</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/efremidze/Animoji">animoji apple private framework</a> 实际上这个就是之前看到的会动的狗屎的视频来源</p>
<h2 id="2d模型-皮套-可动-虚拟Vtuber-talking-head"><a href="#2d模型-皮套-可动-虚拟Vtuber-talking-head" class="headerlink" title="2d模型 皮套 可动 虚拟Vtuber talking head"></a>2d模型 皮套 可动 虚拟Vtuber talking head</h2><p><a target="_blank" rel="noopener" href="https://github.com/yuyuyzl/EasyVtuber">https://github.com/yuyuyzl/EasyVtuber</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/pkhungurn/talking-head-anime-3-demo">https://github.com/pkhungurn/talking-head-anime-3-demo</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/GunwooHan/EasyVtuber">https://github.com/GunwooHan/EasyVtuber</a></p>
<h2 id="b站官方"><a href="#b站官方" class="headerlink" title="b站官方"></a>b站官方</h2><p>直播姬现在支持2d面部捕捉 3d模型动作捕捉</p>
<p>直播姬版本有windows macos(m1) Android版本</p>
<p>2d模型是live2d的模型</p>
<p>有待研究</p>

	
	</div>
  <a type="button" href="/blog/2022/08/13/a8d57d12-8153-4cfb-a58f-f7ceb2612412/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-13 </div>
			<div class="article-title"><a href="/blog/2022/05/13/7aa059cd-4abf-4b43-acf1-f35f5aa93d77/" title="The VToonify framework offers a method for creating high-quality artistic portrait videos with a cartoon style, using StyleGAN layers and features to preserve frame details. It is compatible with existing image cartoonization models.">The Singing Bot</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="the-still-image-to-singing-face-bot-lip-sync-video-generation"><a href="#the-still-image-to-singing-face-bot-lip-sync-video-generation" class="headerlink" title="the still image to singing face bot, lip-sync video generation"></a>the still image to singing face bot, lip-sync video generation</h1><p>sadtalker</p>
<p>wombo.ai, likely to be talking head or yanderifier</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mchong6/GANsNRoses/">https://github.com/mchong6/GANsNRoses/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/williamyang1991/VToonify">https://github.com/williamyang1991/VToonify</a></p>
<p>生成高质量的艺术人像视频是计算机图形学和视觉中一项重要且理想的任务。虽然已经提出了一系列基于强大的 StyleGAN 成功的人像图像卡通化模型，但这些面向图像的方法在应用于视频时存在明显的局限性，在这项工作中，我们通过引入一种新颖的 VToonify 框架来研究具有挑战性的可控高分辨率肖像视频风格迁移。具体来说，VToonify 利用StyleGAN 的中高分辨率层基于编码器提取的多尺度内容特征来渲染高质量的艺术肖像，以更好地保留帧细节。作为输入，有助于输出具有自然运动的完整面部区域。 amework 与现有的基于 StyleGAN 的图像卡通化模型兼容，以将其扩展到视频卡通化，并继承了这些模型的吸引人的特性，可灵活地控制颜色和强度。这项工作展示了基于 Toonify 和 DualStyleGAN 的 VToonify 的两个实例，用于基于集合广泛的实验结果证明了我们提出的 VToonify 框架在生成具有灵活风格控制的高质量和时间连贯的艺术肖像视频方面优于现有方法的有效性</p>
<p>all in one colab text to talking face generation, also consider paddlespeech example:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ChintanTrivedi/ask-fake-ai-karen">https://github.com/ChintanTrivedi/ask-fake-ai-karen</a></p>
<p>avaliable from paddlegan as an example used in paddlespeech, the artificial host.</p>
<p>lip-sync accurate wav2lip:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Rudrabha/Wav2Lip">https://github.com/Rudrabha/Wav2Lip</a></p>
<p>lipgan generate realistic lip-sync talking head animation(fully_pythonic branch or google colab notebook):</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Rudrabha/LipGAN">https://github.com/Rudrabha/LipGAN</a></p>
<p>google’s lipsync implementation, using tensorflow facemesh:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/google/lipsync">https://github.com/google/lipsync</a></p>
<p><a target="_blank" rel="noopener" href="https://lipsync.withyoutube.com/">https://lipsync.withyoutube.com/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tensorflow/tfjs-models/tree/master/facemesh">https://github.com/tensorflow/tfjs-models/tree/master/facemesh</a></p>
<p>network reverse engineering for wombo.ai:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/the-garlic-os/wombo-reverse-engineering">https://github.com/the-garlic-os/wombo-reverse-engineering</a></p>
<p>matamata using vosk models, recommend to use gentle lip-sync method:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/AI-Spawn/Auto-Lip-Sync">https://github.com/AI-Spawn/Auto-Lip-Sync</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Matamata-Animator/Matamata-Core">https://github.com/Matamata-Animator/Matamata-Core</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Yey007/Auto-Lip-Sync">https://github.com/Yey007/Auto-Lip-Sync</a></p>
<p>ai-based lip reading might be irrelevant to lip-sync video generation:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/eflood23/lipsync">https://github.com/eflood23/lipsync</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/13/7aa059cd-4abf-4b43-acf1-f35f5aa93d77/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://yubingtao.netlify.app/" title="Yubingtao's Blog" target="_blank"]);">Yubingtao&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2024 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>