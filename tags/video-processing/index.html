<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>video processing | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      

<!-- title -->
<div class="page-header page-header-inverse ">
  <h1 class="archive-title-tag title title-inverse ">video processing</h1>
</div>

<div class="row page">
  <!-- cols -->
  
  <div class="col-md-9">
	

	  <div id="top_search"></div>

      
         <!-- display as entry -->
	     <div class="mypage">
	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-09-11 </div>
			<div class="article-title"><a href="/blog/2022/09/11/2842d760-78aa-4a8b-8d28-aca75f0d4785/" title="This article delves into motion vector extraction, scene change detection, subtitle removal, and frame interpolation using PyAV with FFmpeg. Additionally, it covers FFmpeg&#39;s image resizing algorithms such as &#39;sinc&#39;, &#39;lanczos&#39;, and &#39;spline&#39;. The article also explores logging options, rounding methods, chroma interpolation, luma/chroma component handling, and the &#39;bitexact&#39; option for exact pixel handling.">Motion Vector Estimation, Motion Vector Export, Ffmpeg Advanced Usage</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="motion-verctor-estimation-motion-vector-export-ffmpeg-advanced-usage"><a href="#motion-verctor-estimation-motion-vector-export-ffmpeg-advanced-usage" class="headerlink" title="motion verctor estimation, motion vector export, ffmpeg advanced usage"></a>motion verctor estimation, motion vector export, ffmpeg advanced usage</h1><h2 id="use-cases"><a href="#use-cases" class="headerlink" title="use cases"></a>use cases</h2><p>to detect hard-coded subtitles, crop the region and detect sudden changes</p>
<p>can also use pyscenedetect to do the job</p>
<h2 id="pyav"><a href="#pyav" class="headerlink" title="pyav"></a>pyav</h2><p><a target="_blank" rel="noopener" href="https://pyav.org/docs/stable/">docs</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip3 install av</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="remove-detect-silence"><a href="#remove-detect-silence" class="headerlink" title="remove&#x2F;detect silence"></a>remove&#x2F;detect silence</h2><p>… silencedetect     A-&gt;A       Detect silence.</p>
<p>… silenceremove     A-&gt;A       Remove silence.</p>
<h2 id="frame-interpolate"><a href="#frame-interpolate" class="headerlink" title="frame interpolate"></a>frame interpolate</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -y -i <span class="string">&quot;/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif&quot;</span> \</span><br><span class="line">-vf <span class="string">&quot;minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d&quot;</span> \</span><br><span class="line">-r 60 ffmpeg_samoyed.mp4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="motion-estimation"><a href="#motion-estimation" class="headerlink" title="motion estimation"></a>motion estimation</h2><p>to get mosaic motion vectors and visualize:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -i <span class="string">&quot;/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif&quot;</span> \</span><br><span class="line">-vf <span class="string">&quot;mestimate=epzs:mb_size=16:search_param=7, codecview=mv=pf+bf+bb&quot;</span>  \</span><br><span class="line">mestimate_output.mp4 -y</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="get-help"><a href="#get-help" class="headerlink" title="get help"></a>get help</h2><h3 id="on-specific-filter"><a href="#on-specific-filter" class="headerlink" title="on specific filter:"></a>on specific filter:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -h filter=showspectrumpic</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="on-all-filters"><a href="#on-all-filters" class="headerlink" title="on all filters:"></a>on all filters:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -filters</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="crop-detection-picture-in-picture-PIP-detection"><a href="#crop-detection-picture-in-picture-PIP-detection" class="headerlink" title="crop detection, picture in picture (PIP) detection"></a>crop detection, picture in picture (PIP) detection</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -i <span class="string">&quot;/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4&quot;</span> \</span><br><span class="line">-vf <span class="string">&quot;mestimate,cropdetect=mode=mvedges,metadata=mode=print&quot;</span> \</span><br><span class="line">-f null -</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="scene-change-detection"><a href="#scene-change-detection" class="headerlink" title="scene change detection"></a><a target="_blank" rel="noopener" href="https://brontosaurusrex.github.io/2019/03/11/ffmpeg-scene-detection/">scene change detection</a></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -hide_banner -i <span class="string">&quot;<span class="variable">$file</span>&quot;</span> -an \</span><br><span class="line">-filter:v \</span><br><span class="line"><span class="string">&quot;select=&#x27;gt(scene,0.2)&#x27;,showinfo&quot;</span> \</span><br><span class="line">-f null \</span><br><span class="line">- 2&gt;&amp;1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="extract-motion-vectors"><a href="#extract-motion-vectors" class="headerlink" title="extract motion vectors"></a>extract motion vectors</h2><p>ffmpeg can produce motion vector estimation but it is not exportable, only for internal use.</p>
<p>mp4 format provides motion vector information thus maybe we need not to use GPU to get those ‘optical flow’ data.</p>
<h3 id="extract-by-using-ffmpeg-apis"><a href="#extract-by-using-ffmpeg-apis" class="headerlink" title="extract by using ffmpeg apis"></a>extract by using ffmpeg apis</h3><p><a target="_blank" rel="noopener" href="https://github.com/LukasBommes/mv-extractor">mv-extractor</a> Extract frames and motion vectors from H.264 and MPEG-4 encoded video.</p>
<h3 id="extract-from-mp4-file"><a href="#extract-from-mp4-file" class="headerlink" title="extract from mp4 file"></a>extract from mp4 file</h3><p><a target="_blank" rel="noopener" href="https://github.com/vadimkantorov/mpegflow">mpegflow</a> for easy extraction of motion vectors stored in video files</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jishnujayakumar/MV-Tractus">mv-tractus</a>: A simple tool to extract motion vectors from h264 encoded videos.</p>
<h2 id="take-screenshot-at-time"><a href="#take-screenshot-at-time" class="headerlink" title="take screenshot at time:"></a><a target="_blank" rel="noopener" href="https://write.corbpie.com/taking-screenshot-with-ffmpeg/#:~:text=To%20take%20a%20screenshot%20or%20save%20a%20frame,means%20the%20frame%20number%20at%20the%20time%20specified.">take screenshot at time:</a></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -ss 01:10:35 -i invideo.mp4 -vframes 1 -q:v 3 screenshot.jpg</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="video-denoise-filters"><a href="#video-denoise-filters" class="headerlink" title="video denoise filters:"></a>video denoise filters:</h2><p>dctdnoiz fftdnoiz hqdn3d nlmeans owdenoise removegrain vaguedenoiser nlmeans_opencl yaepblur</p>
<h2 id="super-resolution-resampling"><a href="#super-resolution-resampling" class="headerlink" title="super-resolution, resampling:"></a>super-resolution, resampling:</h2><h3 id="deeplearning-model-tensorflow"><a href="#deeplearning-model-tensorflow" class="headerlink" title="deeplearning model, tensorflow"></a>deeplearning model, tensorflow</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">env</span> LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:<span class="variable">$LD_LIBRARY_PATH</span> \</span><br><span class="line">ffmpeg -i <span class="string">&quot;/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4&quot;</span> \</span><br><span class="line">-y -vf \</span><br><span class="line"><span class="string">&quot;sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur&quot;</span> \</span><br><span class="line">supertest.mp4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="use-standard-scale-method"><a href="#use-standard-scale-method" class="headerlink" title="use standard scale method:"></a>use standard scale method:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -y -i <span class="string">&quot;/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif&quot;</span>\</span><br><span class="line">-vf <span class="string">&quot;minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d&quot;</span> \</span><br><span class="line">-r 60 ffmpeg_samoyed.mp4</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="options"><a href="#options" class="headerlink" title="options:"></a>options:</h3><p>‘fast_bilinear’</p>
<p>Select fast bilinear scaling algorithm.</p>
<p>‘bilinear’</p>
<p>Select bilinear scaling algorithm.</p>
<p>‘bicubic’</p>
<p>Select bicubic scaling algorithm.</p>
<p>‘experimental’</p>
<p>Select experimental scaling algorithm.</p>
<p>‘neighbor’</p>
<p>Select nearest neighbor rescaling algorithm.</p>
<p>‘area’</p>
<p>Select averaging area rescaling algorithm.</p>
<p>‘bicublin’</p>
<p>Select bicubic scaling algorithm for the luma component, bilinear for chroma components.</p>
<p>‘gauss’</p>
<p>Select Gaussian rescaling algorithm.</p>
<p>‘sinc’</p>
<p>Select sinc rescaling algorithm.</p>
<p>‘lanczos’</p>
<p>Select Lanczos rescaling algorithm. The default width (alpha) is 3 and can be changed by setting param0.</p>
<p>‘spline’</p>
<p>Select natural bicubic spline rescaling algorithm.</p>
<p>‘print_info’</p>
<p>Enable printing&#x2F;debug logging.</p>
<p>‘accurate_rnd’</p>
<p>Enable accurate rounding.</p>
<p>‘full_chroma_int’</p>
<p>Enable full chroma interpolation.</p>
<p>‘full_chroma_inp’</p>
<p>Select full chroma input.</p>
<p>‘bitexact’</p>
<p>Enable bitexact output.</p>

	
	</div>
  <a type="button" href="/blog/2022/09/11/2842d760-78aa-4a8b-8d28-aca75f0d4785/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-09-07 </div>
			<div class="article-title"><a href="/blog/2022/09/07/097a59b9-2109-4a81-8f9f-390bfe3714c5/" title="VapourSynth is a powerful video processing tool that utilizes optical flow algorithms, frame interpolation, and denoising. It seamlessly integrates with other tools like nazobase, DBmbk, and ffmpeg to enhance video quality. With support for Python scripting, users can customize the tool according to their specific requirements. VapourSynth also leverages techniques such as nazorip Bezier curve, gamma curve, convolution, and flowpy for advanced image processing capabilities.">Vapoursynth 光流算法 补帧 画面优化 Denoising</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p><a target="_blank" rel="noopener" href="https://github.com/GoodManWEN/nazobase">nazobase</a> NAZOrip basement, with cython dll <a target="_blank" rel="noopener" href="https://www.nazorip.site/archives/37/">docs</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/kewenyu/DBmbk">DBmbk</a> a debanding toolkit, for easier bezier curve generation</p>
<p><a target="_blank" rel="noopener" href="https://ffmpeg.org/ffmpeg-filters.html#sr">ffmpeg super resolution filter</a> could get faster if run on gpu with <a target="_blank" rel="noopener" href="https://www.tensorflow.org/install/lang_c">libtensorflow</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/HighVoltageRocknRoll/sr">VESPCN: real-time super resolution</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/stax76/mpv.net">mpv</a> is a media player with VapourSynth built-in, and that’s probably how vapoursynth gets in my mac via brew dependency manager</p>
<p><a target="_blank" rel="noopener" href="https://github.com/UniversalAl/view">view.py</a> is Python module for vapoursynth scripts that previews clips</p>
<p><a target="_blank" rel="noopener" href="https://github.com/WolframRhodium/muvsfunc/wiki/OpenCV-Python-for-VapourSynth">to use opencv functions with vapoursynth</a></p>
<p>svp is <a target="_blank" rel="noopener" href="https://www.svp-team.com/zh/get/#">free on linux</a>, offering <a target="_blank" rel="noopener" href="https://www.svp-team.com/wiki/SVP:VLC#Using_SVP_in_VLC">plugin for vlc</a> while vlc cannot be run as root</p>
<p>you might harvest some prebuilt binaries of vapoursynth plugins for linux</p>
<p>补帧算法可适用于我们的动态水印追踪系统 但是可能需要优化 才能做到比较快速的补帧 因为水印所在位置的区间实际上只是白色的 不需要过于复杂的网络 同时这种补出来的水印需要逐帧处理 或者两帧一处理 生成的区间数量会非常的多</p>
<p>it is much easier to do this on windows since we need quick evaluation. might run this on virtualbox?</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Bl4Cc4t/homebrew-vsplugins/tree/master/Formula">build scripts</a> on how to build plugins for macos, including how to configure the installation prefix.</p>
<p>brew compatible, macos compatible vapoursynth plugin build script provider: <a target="_blank" rel="noopener" href="https://github.com/Bl4Cc4t/homebrew-vsplugins">homebrew-vsplugins</a> does not provide build scripts for all plugins avaliable for windows, and it requires <a target="_blank" rel="noopener" href="https://github.com/Bl4Cc4t/homebrew-vsplugins/blob/master/linkvsp.sh">additional linking</a></p>
<p><a target="_blank" rel="noopener" href="https://forum.doom9.org/showthread.php?t=175522">tutorial</a> on how to configure it: (is it intel only?)</p>
<p>Alternative VapourSynth Install Method (Brew):</p>
<p>IMPORTANT: Brew users will need to create and set the autoload folder prior to installing VapourSynth! Simply run the following commands:</p>
<p>Code:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /usr/local/lib/vapoursynth</span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$HOME</span>/Library/Application Support/VapourSynth&quot;</span></span><br><span class="line"><span class="built_in">touch</span> <span class="string">&quot;<span class="variable">$HOME</span>/Library/Application Support/VapourSynth/vapoursynth.conf&quot;</span></span><br><span class="line"><span class="built_in">echo</span> UserPluginDir=/usr/local/lib/vapoursynth &gt;&gt; <span class="string">&quot;<span class="variable">$HOME</span>/Library/Application Support/VapourSynth/vapoursynth.conf&quot;</span></span><br><span class="line"><span class="built_in">echo</span> SystemPluginDir=/usr/local/lib/vapoursynth &gt;&gt; <span class="string">&quot;<span class="variable">$HOME</span>/Library/Application Support/VapourSynth/vapoursynth.conf&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>(Optional) Create desktop shortcuts for the plugins and scripts folders. Run the following commands in terminal:</p>
<p>Code:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> <span class="variable">$HOME</span>/Desktop/VapourSynth</span><br><span class="line"><span class="built_in">ln</span> -s /usr/local/lib/vapoursynth <span class="variable">$HOME</span>/Desktop/VapourSynth/Plugins</span><br><span class="line"><span class="built_in">ln</span> -s /usr/local/lib/python3.9/site-packages <span class="variable">$HOME</span>/Desktop/VapourSynth/Scripts</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Use brew command:</p>
<p>Code:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brew install vapoursynth</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://github.com/WolframRhodium/VapourSynth-BM3DCUDA">bm3d denoising using cuda</a></p>
<p><a target="_blank" rel="noopener" href="https://vsdb.top/plugins/fft3dfilter">fft3d denoising</a></p>
<p><a target="_blank" rel="noopener" href="https://learnopencv.com/optical-flow-in-opencv/">python opencv 光流算法详解</a> 分为sparse和dense两种 某种程度上都可以计算场景的变换激烈程度</p>
<p><a target="_blank" rel="noopener" href="https://github.com/vineeths96/Video-Interpolation-using-Deep-Optical-Flow">frame interpolation using deep optical flow</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmflow">openmmlab mmflow</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/google-research/frame-interpolation">google research: FILM (frame interpolation for large motion)</a></p>
<p><a target="_blank" rel="noopener" href="http://www.vapoursynth.com/doc/gettingstarted.html">vapoursynth get started (official doc)</a></p>
<p><a target="_blank" rel="noopener" href="http://vsdb.top/">vapoursynth plugin database</a> only provide prebuilt binaries for windows while the plugin source code might work with linux and macos (if it has the source code)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/vapoursynth/vsrepo">VSRepo plugin manager</a> installing vapoursynth plugin via commandline tool and vsrepo is only supported on windows, for other platforms we need to compile plugins manually.</p>
<p><a target="_blank" rel="noopener" href="https://www.nazorip.site/category/Tutorials/">nazorip vapoursynth blogs</a></p>
<p><a target="_blank" rel="noopener" href="https://nazorip.site/archives/32/">nazorip bezier curve</a></p>
<p><a target="_blank" rel="noopener" href="https://nazorip.site/archives/56/">nazorip gamma curve and convolution</a></p>
<p><a target="_blank" rel="noopener" href="https://nazorip.site/archives/56/">flowpy: tool for visualizing and processing image with optical flow</a></p>

	
	</div>
  <a type="button" href="/blog/2022/09/07/097a59b9-2109-4a81-8f9f-390bfe3714c5/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-31 </div>
			<div class="article-title"><a href="/blog/2022/05/31/8926a23b-7f8a-4942-9461-c762c8944427/" title="This article explores image restoration, upscaling, and inpainting techniques. It highlights LAMACleaner as a cutting-edge image inpainting tool, which requires manual labeling. Additionally, it covers Deep Image Prior, NAS Image Prior, and mmediting, an open-source toolbox for various image and video restoration, editing, and generation tasks.">Image Restoration Upscaling</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="Image-Restoration-Upscaling-Inpainting-图像修复-超分辨率"><a href="#Image-Restoration-Upscaling-Inpainting-图像修复-超分辨率" class="headerlink" title="Image Restoration Upscaling Inpainting 图像修复 超分辨率"></a>Image Restoration Upscaling Inpainting 图像修复 超分辨率</h1><p><a target="_blank" rel="noopener" href="https://github.com/Sanster/lama-cleaner">sota image inpainting: lama-cleaner</a> still needs manual labeling on inpainting area</p>
<p><a target="_blank" rel="noopener" href="https://github.com/DmitryUlyanov/deep-image-prior">https://github.com/DmitryUlyanov/deep-image-prior</a></p>
<p>nas image prior</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2008.11713">https://arxiv.org/abs/2008.11713</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmediting">mmediting</a>: OpenMMLab Image and Video Restoration, Editing and Generation Toolbox</p>

	
	</div>
  <a type="button" href="/blog/2022/05/31/8926a23b-7f8a-4942-9461-c762c8944427/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-29 </div>
			<div class="article-title"><a href="/blog/2022/05/29/0a0e6520-c166-4e30-819f-b9705c059350/" title="NeuralDiff is a Pytorch-based solution designed to differentiate between actors and objects in 3D videos captured from an egocentric viewpoint. This implementation leverages advanced neural network techniques to accurately identify and categorize the elements present within such videos.">Neuraldiff: Discriminate Actor And Objects In Video</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>Neuraldiff:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/dichotomies/NeuralDiff?ref=pythonawesome.com">https://github.com/dichotomies/NeuralDiff?ref=pythonawesome.com</a></p>
<p><a target="_blank" rel="noopener" href="https://pythonawesome.com/official-pytorch-implementation-of-neuraldiff-segmenting-3d-objects-that-move-in-egocentric-videos/">https://pythonawesome.com/official-pytorch-implementation-of-neuraldiff-segmenting-3d-objects-that-move-in-egocentric-videos/</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/29/0a0e6520-c166-4e30-819f-b9705c059350/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-28 </div>
			<div class="article-title"><a href="/blog/2022/05/28/ca55270b-02a3-4943-92b2-b4d595e3e9d7/" title="This article explores the utilization of AI techniques, specifically PaddleGAN, for colorizing images and videos. Additionally, it highlights other tools and GitHub repositories available for image colorization.">Ai上色</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="AI上色-ffmpeg去特定颜色-调色"><a href="#AI上色-ffmpeg去特定颜色-调色" class="headerlink" title="AI上色 ffmpeg去特定颜色 调色"></a>AI上色 ffmpeg去特定颜色 调色</h1><p><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1161285?channelType=0&channel=0">可能和GAN有关</a></p>
<p>use paddlegan for coloring</p>
<p>可以去掉血腥色情 暴力可能不行 需要剪辑</p>
<p>FFmpeg remove color:</p>
<p><a target="_blank" rel="noopener" href="https://video.stackexchange.com/questions/33588/using-ffmpeg-can-i-remove-the-color-from-an-area-of-the-video">https://video.stackexchange.com/questions/33588/using-ffmpeg-can-i-remove-the-color-from-an-area-of-the-video</a></p>
<p><a target="_blank" rel="noopener" href="http://johnriselvato.com/ffmpeg-how-to-remove-all-colors-except-one-from-a-video/">http://johnriselvato.com/ffmpeg-how-to-remove-all-colors-except-one-from-a-video/</a></p>
<p>face coloring:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Xu-Justin/Grayscale-Face-Coloring">https://github.com/Xu-Justin/Grayscale-Face-Coloring</a></p>
<p>nvidia coloring:</p>
<p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/easily-colorize-black-and-white-photos-with-ai/">https://developer.nvidia.com/blog/easily-colorize-black-and-white-photos-with-ai/</a></p>
<p>github topic on image colorization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/topics/image-colorization">https://github.com/topics/image-colorization</a></p>
<p>github repos on image colorization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image">https://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/aDouladiris/Grayscale-Image-Colorization">https://github.com/aDouladiris/Grayscale-Image-Colorization</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/aakaashjois/Colorizing-Grayscale-Images">https://github.com/aakaashjois/Colorizing-Grayscale-Images</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/emilwallner/Coloring-greyscale-images">https://github.com/emilwallner/Coloring-greyscale-images</a></p>
<p>curated list on image colorization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/oskar-j/awesome-image-coloring">https://github.com/oskar-j/awesome-image-coloring</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/28/ca55270b-02a3-4943-92b2-b4d595e3e9d7/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-24 </div>
			<div class="article-title"><a href="/blog/2022/05/24/b6f93dd7-a741-44ee-92bd-8021bea75c77/" title="This article focuses on video analysis using popular frameworks PyTorch and Keras. It offers a range of resources to perform tasks such as classification and summarization, along with access to a pretrained model zoo for further customization. Additionally, it provides a link to a helpful video feature extractor tool.">视频分析处理 剧本生成</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<h1 id="视频分析处理-视频摘要-剧本生成"><a href="#视频分析处理-视频摘要-剧本生成" class="headerlink" title="视频分析处理 视频摘要 剧本生成"></a>视频分析处理 视频摘要 剧本生成</h1><p>自动抠像 最新 2022 较小的性能消耗：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/hkchengrex/XMem">https://github.com/hkchengrex/XMem</a></p>
<p>我fork的项目：<a target="_blank" rel="noopener" href="https://github.com/ProphetHJK/XMem">https://github.com/ProphetHJK/XMem</a></p>
<p>我fork后添加了一些小工具，包括绿幕生成，蒙版视频生成，中文教程等</p>
<p>simple video captioning:</p>
<p><a target="_blank" rel="noopener" href="https://pythonawesome.com/a-simple-implementation-of-video-captioning/">https://pythonawesome.com/a-simple-implementation-of-video-captioning/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/232525/videocaptioning.pytorch?ref=pythonawesome.com">https://github.com/232525/videocaptioning.pytorch?ref=pythonawesome.com</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/xiadingZ/video-caption.pytorch">https://github.com/xiadingZ/video-caption.pytorch</a></p>
<p>3d cnn for video classification:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/kcct-fujimotolab/3DCNN">https://github.com/kcct-fujimotolab/3DCNN</a></p>
<p>end-to-end video image classification by facebook:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/ClassyVision">https://github.com/facebookresearch/ClassyVision</a></p>
<p>video understanding models and datasets:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/sujiongming/awesome-video-understanding">https://github.com/sujiongming/awesome-video-understanding</a></p>
<p>video classification dataset:</p>
<p>​video_type_dict​ ​&#x3D;​ {​’360VR’​: ​’VR’​, ​’4k’​: ​’4K’​, ​’Technology’​: ​’科技’​, ​’Sport’​: ​’运动’​, ​’Timelapse’​: ​’延时’​,</p>
<p>​’Aerial’​: ​’航拍’​, ​’Animals’​: ​’动物’​, ​’Sea’​: ​’大海’​, ​’Beach’​: ​’海滩’​, ​’space’​: ​’太空’​,</p>
<p>​’stars’​: ​’星空’​, ​’City’​: ​’城市’​, ​’Business’​: ​’商业’​, ​’Underwater’​: ​’水下摄影’​,</p>
<p>​’Wedding’​: ​’婚礼’​, ​’Archival’​: ​’档案’​, ​’Backgrounds’​: ​’背景’​, ​’Alpha Channel’​: ​’透明通道’​,</p>
<p>​’Intro’​: ​’开场’​, ​’Celebration’​: ​’庆典’​, ​’Clouds’​: ​’云彩’​, ​’Corporate’​: ​’企业’​,</p>
<p>​’Explosion’​: ​’爆炸’​, ​’Film’​: ​’电影镜头’​, ​’Green Screen’​: ​’绿幕’​, ​’Military’​: ​’军事’​,</p>
<p>​’Nature’​: ​’自然’​, ​’News’​: ​’新闻’​, ​’R3d’​: ​’R3d’​, ​’Romantic’​: ​’浪漫’​, ​’Abstract’​: ​’抽象’​}</p>
<p><a target="_blank" rel="noopener" href="https://github.com/yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model">https://github.com/yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model</a></p>
<p>rnn for human action recognization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input">https://github.com/stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input</a></p>
<p>video script introduction and generation:</p>
<p><a target="_blank" rel="noopener" href="https://sharetxt.live/blog/how-to-generate-a-youtube-video-script-with-ai#:~:text=%20How%20to%20use%20Chibi.ai%20to%20create%20a,scan%20through%20your%20text%20and%20generate...%20More%20">https://sharetxt.live/blog/how-to-generate-a-youtube-video-script-with-ai#:~:text=%20How%20to%20use%20Chibi.ai%20to%20create%20a,scan%20through%20your%20text%20and%20generate...%20More%20</a></p>
<p>fight detection using pose estimation and rnn:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/imsoo/fight_detection">https://github.com/imsoo/fight_detection</a></p>
<p>video summarizer to summarized video based on video feature:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Lalit-ai/Video-Summary-Generator">https://github.com/Lalit-ai/Video-Summary-Generator</a></p>
<p>awesome action recognition:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jinwchoi/awesome-action-recognition">https://github.com/jinwchoi/awesome-action-recognition</a></p>
<p>temporal model for video understanding:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/temporal-shift-module">https://github.com/mit-han-lab/temporal-shift-module</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/temporal-shift-module">https://github.com/mit-han-lab/temporal-shift-module</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/yjxiong/tsn-pytorch">https://github.com/yjxiong/tsn-pytorch</a></p>
<p>time space attention for video understanding(timesformer):</p>
<p><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/TimeSformer">https://github.com/facebookresearch/TimeSformer</a></p>
<p>video understanding by alibaba:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/alibaba-mmai-research/pytorch-video-understanding">https://github.com/alibaba-mmai-research/pytorch-video-understanding</a></p>
<p>video object segmentation:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/yoxu515/aot-benchmark?ref=pythonawesome.com">https://github.com/yoxu515/aot-benchmark?ref=pythonawesome.com</a></p>
<p>video scene segmentation:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/kakaobrain/bassl?ref=pythonawesome.com">https://github.com/kakaobrain/bassl?ref=pythonawesome.com</a></p>
<p>mmaction detect actions in video:</p>
<p><a target="_blank" rel="noopener" href="https://pythonawesome.com/an-open-source-toolbox-for-video-understanding-based-on-pytorch/">https://pythonawesome.com/an-open-source-toolbox-for-video-understanding-based-on-pytorch/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmaction2">https://github.com/open-mmlab/mmaction2</a></p>
<p>dense video captioning:</p>
<p><a target="_blank" rel="noopener" href="https://www.opensourceagenda.com/projects/dense-video-captioning-pytorch">https://www.opensourceagenda.com/projects/dense-video-captioning-pytorch</a></p>
<p><a target="_blank" rel="noopener" href="https://www.opensourceagenda.com/projects/dense-video-captioning-pytorch">https://www.opensourceagenda.com/projects/dense-video-captioning-pytorch</a></p>
<p>seq2seq video captioning:</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013010889/article/details/80087601">https://blog.csdn.net/u013010889/article/details/80087601</a></p>
<p>2d cnn with LSTM video classification:</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43493208/article/details/104387182">https://blog.csdn.net/qq_43493208/article/details/104387182</a></p>
<p>spp-net for image shape unification:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/peace195/sppnet">https://github.com/peace195/sppnet</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/yueruchen/sppnet-pytorch">https://github.com/yueruchen/sppnet-pytorch</a></p>
<p>running pretrained pytorchvideo video classification model from zoo:</p>
<p><a target="_blank" rel="noopener" href="https://pytorchvideo.org/docs/tutorial_torchhub_inference">https://pytorchvideo.org/docs/tutorial_torchhub_inference</a></p>
<p>pytorchvideo model zoo:</p>
<p><a target="_blank" rel="noopener" href="https://pytorchvideo.readthedocs.io/en/latest/model_zoo.html">https://pytorchvideo.readthedocs.io/en/latest/model_zoo.html</a></p>
<p>(arxiv) end to end generative pretraining multimodal video captioning mv-gpt:</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2201.08264v1">https://arxiv.org/abs/2201.08264v1</a></p>
<p>video captioning using encoder-decoder:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Shreyz-max/Video-Captioning">https://github.com/Shreyz-max/Video-Captioning</a></p>
<p>video captioning video2text keras implementation:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/alvinbhou/Video2Text">https://github.com/alvinbhou/Video2Text</a></p>
<p>video summarization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/shruti-jadon/Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming">https://github.com/shruti-jadon/Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming</a></p>
<p>pytorch_video video classification:</p>
<p><a target="_blank" rel="noopener" href="https://pytorchvideo.org/docs/tutorial_classification">https://pytorchvideo.org/docs/tutorial_classification</a></p>
<p>video feature extractor:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/hobincar/pytorch-video-feature-extractor">https://github.com/hobincar/pytorch-video-feature-extractor</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/24/b6f93dd7-a741-44ee-92bd-8021bea75c77/#more" class="btn btn-default more">Read More</a>
</div>

	       
		     
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-14 </div>
			<div class="article-title"><a href="/blog/2022/05/14/506afef5-ff55-44d1-b448-25f79c62b997/" title="This article discusses the process of creating a non-NSFW and anti-censorship anime video using music and open-source tools from GitHub. It highlights how these tools can be employed to combat content and video restrictions.">动漫剪辑过审</a></div>
		</h3>
	


		     
<div class="entry">

  <div class="row">
	
	
		<p>剪的时候不要超过4分钟 可以用spleeter切出语音 加入自己的背景音乐</p>
<p>这个属于anti nsfw anti censorship 反内容审查 反视频审查 对抗机制 可以在github上面搜索</p>
<p>二创某种意义也是反审查</p>
<p>审查的 nsfw 微信小程序 可以解包 然后调用别人的接口 可能不稳定</p>
<p><a target="_blank" rel="noopener" href="https://github.com/superdashu/frida_with_wechat_applet">https://github.com/superdashu/frida_with_wechat_applet</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/superdashu/pc_wxapkg_decrypt_python">https://github.com/superdashu/pc_wxapkg_decrypt_python</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/14/506afef5-ff55-44d1-b448-25f79c62b997/#more" class="btn btn-default more">Read More</a>
</div>

	       
	     </div>
	     <div>
	       <center>
	         <div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

	       </center>
	     </div>	
      

</div> <!-- col-md-9/col-md-12 -->


<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://yubingtao.netlify.app/" title="Yubingtao's Blog" target="_blank"]);">Yubingtao&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2024 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>