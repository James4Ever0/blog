<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Page 104 | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  
    <script src="/js/marked.js"></script>
    <script src="/js/comment.js"></script>
    <script src="/js/timeago.min.js"></script>
    <script src="/js/highlight.min.js"></script>
	<script src="/js/spin.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      <div class="page-header page-header-inverse ">
  <h1 class="title title-inverse ">Blog of James Brown</h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		
<div class="slogan">
      <i class="fa fa-heart"></i>
      Autonomous Machines &amp; Society.
</div>


		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
        <!-- render top articles firstly -->
        
        <!-- render other articles -->
        
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f7255fb1-aae0-4fba-a33f-7acbd6237677/" title="This text discusses the process of typing the backtick character using a splitable keyboard, with a suggestion to use the meta+esc combination. However, it mentions that this method may sometimes fail. Additionally, it provides an alternative universal method for typing a tilde &#39;~&#39; which is by using shift+esc.">typing backtick &#34;`&#34; with my current splitable keyboard</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="typing-backtick-“-”-with-my-current-splitable-keyboard"><a href="#typing-backtick-“-”-with-my-current-splitable-keyboard" class="headerlink" title="typing backtick “&#96;” with my current splitable keyboard"></a>typing backtick “&#96;” with my current splitable keyboard</h1><p>it used to work with meta+esc key, but it fails sometimes.</p>
<p>there’s a universal way: shift+alt+esc</p>
<p>type tlide “~”: shift+esc</p>

	
	</div>
  <a type="button" href="/2023/12/22/f7255fb1-aae0-4fba-a33f-7acbd6237677/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f737d025-f1ba-4d92-bd65-19aca850c42e/" title="This article explores various video search methods, including Yandex&#39;s reverse image search for videos, Python libraries for YouTube searches, and self-hosted AI engines like Jina. It also provides additional resources on search engines with video functionality.">Video Search Engines</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="Video-Search-Engines"><a href="#Video-Search-Engines" class="headerlink" title="Video Search Engines"></a>Video Search Engines</h1><p>Yandex好像可以根据视频截图搜索原视频来源</p>
<p><a target="_blank" rel="noopener" href="https://github.com/alexmercerind/youtube-search-python">youtube search python</a></p>
<p><a target="_blank" rel="noopener" href="https://codefather.tech/blog/youtube-search-python/">search youtube using urllib</a></p>
<p>AI VIDEO SEARCH ENGINE (self hosted):<br>Jina</p>
<p>search video by subtitle or generated subtitle:<br><a target="_blank" rel="noopener" href="https://github.com/antiboredom/videogrep">https://github.com/antiboredom/videogrep</a></p>
<p>From search Engine journal:<br><a target="_blank" rel="noopener" href="https://www.searchenginejournal.com/best-video-search-engines/360822/">https://www.searchenginejournal.com/best-video-search-engines/360822/</a></p>
<p>Google Youtube Bing<br>DailyMotion </p>
<p>DuckduckGo Yahoo </p>
<p>Metacafe<br>find fun unusual videos</p>
<p>Ask Yandex Swisscows</p>
<p><a target="_blank" rel="noopener" href="https://kinsta.com/blog/video-search-engine/">https://kinsta.com/blog/video-search-engine/</a></p>
<p>Facebook Dogpile</p>
<p> Veoh<br>video share platform, search by language of subtitles</p>
<p>berify<br>reverse video search by screenshot inside the video</p>
<p>vimeo</p>
<p>social searcher<br>search multiple social media platform at once</p>
<p>ecosia</p>
<p>shutterstock<br>need purchase? Royalty-free?</p>
<p>chinese local video platforms:<br>baidu sogou 360 tencent  zhihu …</p>

	
	</div>
  <a type="button" href="/2023/12/22/f737d025-f1ba-4d92-bd65-19aca850c42e/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f7c45c1f-982e-41ca-bf82-1d4f37499b71/" title="The &#39;pyjom producer&#39; is a process designed for analyzing audio and video separately. Audio can be processed in chunks or split tracks, allowing for more efficient analysis. However, to analyze the video, it needs to be iterated frame by frame.">pyjom producer</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="pyjom-producer"><a href="#pyjom-producer" class="headerlink" title="pyjom producer"></a>pyjom producer</h1><p>video and audio needs to be analysised separately.</p>
<p>audio can be processed by chunks, splited tracks, while video can be itered frame by frame.</p>

	
	</div>
  <a type="button" href="/2023/12/22/f7c45c1f-982e-41ca-bf82-1d4f37499b71/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f808aaf8-3fb6-4038-9eec-326b20433bd0/" title="This article explores the application of Large Language Models (LLMs) in generating various elements such as images, tags, categories, and embeddings for content. It also delves into the capabilities of these models to perform full-text and vector searches, generate query words and media, update relevance based on user preferences, and even generate new queries for content.">RAG in my mind</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="RAG-in-my-mind"><a href="#RAG-in-my-mind" class="headerlink" title="RAG in my mind"></a>RAG in my mind</h1><p>llm generate images for content<br>llm generate tags &amp; categories for content<br>llm generate embedding for content</p>
<p>llm generate query words<br>llm generate query image&#x2F;audio</p>
<p>system perform full text search<br>system perform vector search</p>
<p>llm generate relevance or preference<br>llm generate potential query for content<br>system update relevance based on llm preference</p>

	
	</div>
  <a type="button" href="/2023/12/22/f808aaf8-3fb6-4038-9eec-326b20433bd0/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f79db9b7-459c-4d4b-9922-b528ccee0c30/" title="Recent advancements in Transformers technology have enabled the creation of large language models such as GPT-NeoX and OPT, which have significantly improved conversational AI capabilities. BERT tools are now used for text generation, question answering, and language classification using open-source resources like Hugging Face&#39;s Transformers library and TensorFlow 2.0 for multi-lingual modeling.">Awesome Transformer &amp; Transfer Learning in NLP</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="Awesome-Transformer-Transfer-Learning-in-NLP"><a href="#Awesome-Transformer-Transfer-Learning-in-NLP" class="headerlink" title="Awesome Transformer &amp; Transfer Learning in NLP"></a>Awesome Transformer &amp; Transfer Learning in NLP</h1><p><a target="_blank" rel="noopener" href="https://github.com/mikeroyal/Machine-Learning-Guide">machine learning guide</a> lots of links, broad topics</p>
<p><a target="_blank" rel="noopener" href="https://github.com/cedrickchee/awesome-transformer-nlp/">This repository</a> contains a hand-curated of great machine (deep) learning resources for Natural Language Processing (NLP) with a focus on Bidirectional Encoder Representations from Transformers (BERT), attention mechanism, Transformer architectures&#x2F;networks, and transfer learning in NLP.</p>
<p><img src="https://user-images.githubusercontent.com/145605/206787465-bdfae6e0-c850-46fc-808d-a51c97644a9e.png#gh-dark-mode-only" alt="Transformer"><br><img src="https://user-images.githubusercontent.com/145605/79639176-9ca33d80-81bc-11ea-8cde-f7ff68ee2042.png#gh-light-mode-only" alt="Transformer"></p>
<p>Transformer (BERT) (<a target="_blank" rel="noopener" href="https://web.archive.org/web/20201217063603/https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/bert-encoder">Source</a>)</p>
<!-- <br />
<p align="center">
  <img src="https://user-images.githubusercontent.com/145605/79639176-9ca33d80-81bc-11ea-8cde-f7ff68ee2042.png" width="600" />
<h4 align="center">Transformer (BERT) (<a target="_blank" rel="noopener" href="https://web.archive.org/web/20201217063603/https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/bert-encoder">Source</a>)</h4>
</p>
<br /> -->

<h1 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents"></a>Table of Contents</h1><details>

<summary><b>Expand Table of Contents</b></summary>

<ul>
<li><a href="#papers">Papers</a></li>
<li><a href="#articles">Articles</a><ul>
<li><a href="#bert-and-transformer">BERT and Transformer</a></li>
<li><a href="#attention-concept">Attention Concept</a></li>
<li><a href="#transformer-architecture">Transformer Architecture</a></li>
<li><a href="#generative-pre-training-transformer-gpt">Generative Pre-Training Transformer (GPT)</a></li>
<li><a href="#large-language-model-llm">Large Language Model (LLM)</a></li>
<li><a href="#additional-reading">Additional Reading</a></li>
</ul>
</li>
<li><a href="#educational">Educational</a><ul>
<li><a href="#tutorials">Tutorials</a></li>
</ul>
</li>
<li><a href="#videos">Videos</a><ul>
<li><a href="#bertology">BERTology</a></li>
<li><a href="#attention-and-transformer-networks">Attention and Transformer Networks</a></li>
</ul>
</li>
<li><a href="#official-implementations">Official Implementations</a></li>
<li><a href="#other-implementations">Other Implementations</a><ul>
<li><a href="#pytorch-and-tensorflow">PyTorch and TensorFlow</a></li>
<li><a href="#pytorch">PyTorch</a></li>
<li><a href="#keras">Keras</a></li>
<li><a href="#tensorflow">TensorFlow</a></li>
<li><a href="#chainer">Chainer</a></li>
</ul>
</li>
<li><a href="#transfer-learning-in-nlp">Transfer Learning in NLP</a></li>
<li><a href="#books">Books</a></li>
<li><a href="#other-resources">Other Resources</a></li>
<li><a href="#tools">Tools</a></li>
<li><a href="#tasks">Tasks</a><ul>
<li><a href="#named-entity-recognition-ner">Named-Entity Recognition (NER)</a></li>
<li><a href="#classification">Classification</a></li>
<li><a href="#text-generation">Text Generation</a></li>
<li><a href="#question-answering-qa">Question Answering (QA)</a></li>
<li><a href="#knowledge-graph">Knowledge Graph</a></details></li>
</ul>
</li>
</ul>
<hr>
<h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><ol>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a> by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.02860">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a> by Zihang Dai, Zhilin Yang, Yiming Yang, William W. Cohen, Jaime Carbonell, Quoc V. Le and Ruslan Salakhutdinov.</li>
</ol>
<ul>
<li>Uses smart caching to improve the learning of long-term dependency in Transformer. Key results: state-of-art on 5 language modeling benchmarks, including ppl of 21.8 on One Billion Word (LM1B) and 0.99 on enwiki8. The authors claim that the method is more flexible, faster during evaluation (1874 times speedup), generalizes well on small datasets, and is effective at modeling short and long sequences.</li>
</ul>
<ol start="2">
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1812.06705">Conditional BERT Contextual Augmentation</a> by Xing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han and Songlin Hu.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.03593">SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering</a> by Chenguang Zhu, Michael Zeng and Xuedong Huang.</li>
<li><a target="_blank" rel="noopener" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a> by Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1901.11117">The Evolved Transformer</a> by David R. So, Chen Liang and Quoc V. Le.</li>
</ol>
<ul>
<li>They used architecture search to improve Transformer architecture. Key is to use evolution and seed initial population with Transformer itself. The architecture is better and more efficient, especially for small size models.</li>
</ul>
<ol start="6">
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1906.08237">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a> by Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.</li>
</ol>
<ul>
<li>A new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE).</li>
<li>“Transformer-XL is a shifted model (each hyper-column ends with next token) while XLNet is a direct model (each hyper-column ends with contextual representation of same token).” — <a target="_blank" rel="noopener" href="https://twitter.com/Thom_Wolf/status/1141803437719506944?s=20">Thomas Wolf</a>.</li>
<li><a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=20229145">Comments from HN</a>:<details>

<summary>A clever dual masking-and-caching algorithm.</summary>

<ul>
<li>This is NOT “just throwing more compute” at the problem.</li>
<li>The authors have devised a clever dual-masking-plus-caching mechanism to induce an attention-based model to learn to predict tokens from all possible permutations of the factorization order of all other tokens in the same input sequence.</li>
<li>In expectation, the model learns to gather information from all positions on both sides of each token in order to predict the token.<ul>
<li>For example, if the input sequence has four tokens, [“The”, “cat”, “is”, “furry”], in one training step the model will try to predict “is” after seeing “The”, then “cat”, then “furry”.</li>
<li>In another training step, the model might see “furry” first, then “The”, then “cat”.</li>
<li>Note that the original sequence order is always retained, e.g., the model always knows that “furry” is the fourth token.</li>
</ul>
</li>
<li>The masking-and-caching algorithm that accomplishes this does not seem trivial to me.</li>
<li>The improvements to SOTA performance in a range of tasks are significant – see tables 2, 3, 4, 5, and 6 in the paper.</details></li>
</ul>
</li>
</ul>
<ol start="7">
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.05858">CTRL: Conditional Transformer Language Model for Controllable Generation</a> by Nitish Shirish Keskar, Richard Socher et al. [<a target="_blank" rel="noopener" href="https://github.com/salesforce/ctrl">Code</a>].</li>
<li><a target="_blank" rel="noopener" href="https://github.com/thunlp/PLMpapers">PLMpapers</a> - BERT (Transformer, transfer learning) has catalyzed research in pretrained language models (PLMs) and has sparked many extensions. This repo contains a list of papers on PLMs.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a> by Google Brain.</li>
</ol>
<ul>
<li>The group perform a systematic study of transfer learning for NLP using a unified Text-to-Text Transfer Transformer (T5) model and push the limits to achieve SoTA on SuperGLUE (approaching human baseline), SQuAD, and CNN&#x2F;DM benchmark. [<a target="_blank" rel="noopener" href="https://git.io/Je0cZ">Code</a>].</li>
</ul>
<ol start="10">
<li><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=rkgNKkHtvB">Reformer: The Efficient Transformer</a> by Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya.</li>
</ol>
<ul>
<li>“They present techniques to reduce the time and memory complexity of Transformer, allowing batches of very long sequences (64K) to fit on one GPU. Should pave way for Transformer to be really impactful beyond NLP domain.” — @hardmaru</li>
</ul>
<ol start="11">
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.02950">Supervised Multimodal Bitransformers for Classifying Images and Text</a> (MMBT) by Facebook AI.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2002.12327">A Primer in BERTology: What we know about how BERT works</a> by Anna Rogers et al.</li>
</ol>
<ul>
<li>“Have you been drowning in BERT papers?”. The group survey over 40 papers on BERT’s linguistic knowledge, architecture tweaks, compression, multilinguality, and so on.</li>
</ul>
<ol start="12">
<li><a target="_blank" rel="noopener" href="https://github.com/tomohideshibata/BERT-related-papers">tomohideshibata&#x2F;BERT-related papers</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2101.03961">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</a> by Google Brain. <a target="_blank" rel="noopener" href="https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/moe.py">[Code]</a> | <a target="_blank" rel="noopener" href="https://syncedreview.com/2021/01/14/google-brains-switch-transformer-language-model-packs-1-6-trillion-parameters/">[Blog post (unofficial)]</a></li>
</ol>
<ul>
<li>Key idea: the architecture use a subset of parameters on every training step and on each example. Upside: model train much faster. Downside: super large model that won’t fit in a lot of environments.</li>
</ul>
<ol start="14">
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2105.14103">An Attention Free Transformer</a> by Apple.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.04554">A Survey of Transformers</a> by Tianyang Lin et al.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2107.03374">Evaluating Large Language Models Trained on Code</a> by OpenAI.</li>
</ol>
<ul>
<li>Codex, a GPT language model that powers GitHub Copilot.</li>
<li>They investigate their model limitations (and strengths).</li>
<li>They discuss the potential broader impacts of deploying powerful code generation techs, covering safety, security, and economics.</li>
</ul>
<ol start="17">
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.02155">Training language models to follow instructions with human feedback</a> by OpenAI. They call the resulting models <a target="_blank" rel="noopener" href="https://openai.com/blog/instruction-following/">InstructGPT</a>. <a target="_blank" rel="noopener" href="https://openai.com/blog/chatgpt/">ChatGPT</a> is a sibling model to InstructGPT.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2201.08239">LaMDA: Language Models for Dialog Applications</a> by Google.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.15556">Training Compute-Optimal Large Language Models</a> by Hoffmann et al. at DeepMind. TLDR: introduces a new 70B LM called “Chinchilla” that outperforms much bigger LMs (GPT-3, Gopher). DeepMind has found the secret to cheaply scale large language models — to be compute-optimal, model size and training data must be scaled equally. It shows that most LLMs are severely starved of data and under-trained. Given the <a target="_blank" rel="noopener" href="https://www.alignmentforum.org/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications">new scaling law</a>, even if you pump a quadrillion parameters into a model (GPT-4 urban myth), the gains will not compensate for 4x more training tokens.</li>
</ol>
<h2 id="Articles"><a href="#Articles" class="headerlink" title="Articles"></a>Articles</h2><h3 id="BERT-and-Transformer"><a href="#BERT-and-Transformer" class="headerlink" title="BERT and Transformer"></a>BERT and Transformer</h3><ol>
<li><a target="_blank" rel="noopener" href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing</a> from Google AI.</li>
<li><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a>.</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/dissecting-bert">Dissecting BERT</a> by Miguel Romero and Francisco Ingham - Understand BERT in depth with an intuitive, straightforward explanation of the relevant concepts.</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/dair-ai/a-light-introduction-to-transformer-xl-be5737feb13">A Light Introduction to Transformer-XL</a>.</li>
<li><a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html">Generalized Language Models</a> by Lilian Weng, Research Scientist at OpenAI.</li>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/what-is-xlnet-and-why-it-outperforms-bert-8d8fce710335">What is XLNet and why it outperforms BERT</a></li>
</ol>
<ul>
<li>Permutation Language Modeling objective is the core of XLNet.</li>
</ul>
<ol start="6">
<li><a target="_blank" rel="noopener" href="https://github.com/huggingface/pytorch-transformers/tree/master/examples/distillation">DistilBERT</a> (from HuggingFace), released together with the blog post <a target="_blank" rel="noopener" href="https://medium.com/huggingface/distilbert-8cf3380435b5">Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT</a>.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.11942v3">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations paper</a> from Google Research and Toyota Technological Institute. — Improvements for more efficient parameter usage: factorized embedding parameterization, cross-layer parameter sharing, and Sentence Order Prediction (SOP) loss to model inter-sentence coherence. [<a target="_blank" rel="noopener" href="https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html">Blog post</a> | <a target="_blank" rel="noopener" href="https://github.com/google-research/ALBERT">Code</a>]</li>
<li><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=r1xMH1BtvB">ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</a> by Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning - A BERT variant like ALBERT and cost less to train. They trained a model that outperforms GPT by using only one GPU; match the performance of RoBERTa by using 1&#x2F;4 computation. It uses a new pre-training approach, called replaced token detection (RTD), that trains a bidirectional model while learning from all input positions. [<a target="_blank" rel="noopener" href="https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html">Blog post</a> | <a target="_blank" rel="noopener" href="https://github.com/google-research/electra">Code</a>]</li>
<li><a target="_blank" rel="noopener" href="https://amitness.com/2020/02/albert-visual-summary/">Visual Paper Summary: ALBERT (A Lite BERT)</a></li>
</ol>
<h3 id="Attention-Concept"><a href="#Attention-Concept" class="headerlink" title="Attention Concept"></a>Attention Concept</h3><ol>
<li><a target="_blank" rel="noopener" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer by Harvard NLP Group</a> - Further reading to understand the “Attention is all you need” paper.</li>
<li><a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">Attention? Attention!</a> - Attention guide by Lilian Weng from OpenAI.</li>
<li><a target="_blank" rel="noopener" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a> by Jay Alammar, an Instructor from Udacity ML Engineer Nanodegree.</li>
<li><a target="_blank" rel="noopener" href="https://ai.facebook.com/blog/making-transformer-networks-simpler-and-more-efficient/">Making Transformer networks simpler and more efficient</a> - FAIR released an all-attention layer to simplify the Transformer model and an adaptive attention span method to make it more efficient (reduce computation time and memory footprint).</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1906.04341">What Does BERT Look At? An Analysis of BERT’s Attention paper</a> by Stanford NLP Group.</li>
</ol>
<h3 id="Transformer-Architecture"><a href="#Transformer-Architecture" class="headerlink" title="Transformer Architecture"></a>Transformer Architecture</h3><ol>
<li><a target="_blank" rel="noopener" href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">The Transformer blog post</a>.</li>
<li><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a> by Jay Alammar, an Instructor from Udacity ML Engineer Nanodegree.</li>
<li>Watch <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rBCqOTEfxvg">Łukasz Kaiser’s talk</a> walking through the model and its details.</li>
<li><a target="_blank" rel="noopener" href="https://ai.googleblog.com/2019/01/transformer-xl-unleashing-potential-of.html">Transformer-XL: Unleashing the Potential of Attention Models</a> by Google Brain.</li>
<li><a target="_blank" rel="noopener" href="https://openai.com/blog/sparse-transformer/">Generative Modeling with Sparse Transformers</a> by OpenAI - an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.06764">Stabilizing Transformers for Reinforcement Learning</a> paper by DeepMind and CMU - they propose architectural modifications to the original Transformer and XL variant by moving layer-norm and adding gating creates Gated Transformer-XL (GTrXL). It substantially improve the stability and learning speed (integrating experience through time) in RL.</li>
<li><a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html">The Transformer Family</a> by Lilian Weng - since the paper “Attention Is All You Need”, many new things have happened to improve the Transformer model. This post is about that.</li>
<li><a target="_blank" rel="noopener" href="https://ai.facebook.com/blog/end-to-end-object-detection-with-transformers/">DETR (<strong>DE</strong>tection <strong>TR</strong>ansformer): End-to-End Object Detection with Transformers</a> by FAIR - :fire: Computer vision has not yet been swept up by the Transformer revolution. DETR completely changes the architecture compared with previous object detection systems. (<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/detr">PyTorch Code and pretrained models</a>). “A solid swing at (non-autoregressive) end-to-end detection. Anchor boxes + Non-Max Suppression (NMS) is a mess. I was hoping detection would go end-to-end back in ~2013)” — Andrej Karpathy</li>
<li><a target="_blank" rel="noopener" href="https://blog.nelhage.com/post/transformers-for-software-engineers/">Transformers for software engineers</a> - This post will be helpful to software engineers who are interested in learning ML models, especially anyone interested in Transformer interpretability. The post walk through a (mostly) complete implementation of a GPT-style Transformer, but the goal will not be running code; instead, they use the language of software engineering and programming to explain how these models work and articulate some of the perspectives they bring to them when doing interpretability work.</li>
<li><a target="_blank" rel="noopener" href="https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html">Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance</a> - PaLM is a dense decoder-only Transformer model trained with the Pathways system, which enabled Google to efficiently train a single model across multiple TPU v4 Pods. The example explaining a joke is remarkable. This shows that it can generate explicit explanations for scenarios that require a complex combination of multi-step logical inference, world knowledge, and deep language understanding.</li>
</ol>
<h3 id="Generative-Pre-Training-Transformer-GPT"><a href="#Generative-Pre-Training-Transformer-GPT" class="headerlink" title="Generative Pre-Training Transformer (GPT)"></a>Generative Pre-Training Transformer (GPT)</h3><ol>
<li><a target="_blank" rel="noopener" href="https://openai.com/blog/better-language-models/">Better Language Models and Their Implications</a>.</li>
<li><a target="_blank" rel="noopener" href="https://blog.openai.com/language-unsupervised/">Improving Language Understanding with Unsupervised Learning</a> - this is an overview of the original OpenAI GPT model.</li>
<li><a target="_blank" rel="noopener" href="https://convai.huggingface.co/">🦄 How to build a State-of-the-Art Conversational AI with Transfer Learning</a> by Hugging Face.</li>
<li><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a> by Jay Alammar.</li>
<li><a target="_blank" rel="noopener" href="https://nv-adlr.github.io/MegatronLM">MegatronLM: Training Billion+ Parameter Language Models Using GPU Model Parallelism</a> by NVIDIA ADLR.</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc">OpenGPT-2: We Replicated GPT-2 Because You Can Too</a> - the authors trained a 1.5 billion parameter GPT-2 model on a similar sized text dataset and they reported results that can be compared with the original model.</li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=fZSFNUT6iY8">MSBuild demo of an OpenAI generative text model generating Python code</a> [video] - The model that was trained on GitHub OSS repos. The model uses English-language code comments or simply function signatures to generate entire Python functions. Cool!</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.14165">GPT-3: Language Models are Few-Shot Learners (paper)</a> by Tom B. Brown (OpenAI) et al. - “We train GPT-3, an autoregressive language model with 175 billion parameters :scream:, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.”</li>
<li><a target="_blank" rel="noopener" href="https://github.com/elyase/awesome-gpt3">elyase&#x2F;awesome-gpt3</a> - A collection of demos and articles about the OpenAI GPT-3 API.</li>
<li><a target="_blank" rel="noopener" href="https://jalammar.github.io/how-gpt3-works-visualizations-animations/">How GPT3 Works - Visualizations and Animations</a> by Jay Alammar.</li>
<li><a target="_blank" rel="noopener" href="https://www.eleuther.ai/projects/gpt-neo/">GPT-Neo</a> - Replicate a GPT-3 sized model and open source it for free. GPT-Neo is “an implementation of model parallel GPT2 &amp; GPT3-like models, with the ability to scale up to full GPT3 sizes (and possibly more!), using the mesh-tensorflow library.” [<a target="_blank" rel="noopener" href="https://github.com/EleutherAI/gpt-neo">Code</a>].</li>
<li><a target="_blank" rel="noopener" href="https://copilot.github.com/">GitHub Copilot</a>, powered by OpenAI Codex - Codex is a descendant of GPT-3. Codex translates natural language into code.</li>
<li><a target="_blank" rel="noopener" href="https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley">GPT-4 Rumors From Silicon Valley</a> - GPT-4 is almost ready. GPT-4 would be multimodal, accepting text, audio, image, and possibly video inputs. Release window: Dec - Feb. #hype</li>
<li><a target="_blank" rel="noopener" href="https://beta.openai.com/docs/models/davinci">New GPT-3 model: text-Davinci-003</a> - Improvements:</li>
</ol>
<ul>
<li>Handle more complex intents — you can get even more creative with how you make use of its capabilities now.</li>
<li>Higher quality writing — clearer, more engaging, and more compelling content.</li>
<li>Better at longer form content generation.</li>
</ul>
<ol start="15">
<li><a target="_blank" rel="noopener" href="https://openai.com/blog/chatgpt/">ChatGPT blog post</a> and link to the conversational interface.</li>
</ol>
<ul>
<li>ChatGPT is OpenAI’s newest language model fine-tuned from a model in the <a target="_blank" rel="noopener" href="https://beta.openai.com/docs/model-index-for-researchers">GPT-3.5 series</a> (which finished training in early 2022), optimized for dialogue. It is trained using Reinforcement Learning from Human Feedback; human AI trainers provide supervised fine-tuning by playing both sides of the conversation.</li>
<li>Is it evidently better than GPT-3 at following user instructions and context? <a target="_blank" rel="noopener" href="https://archive.ph/m6AOQ">People have noticed</a>, ChatGPT’s output quality seems to represent a notable improvement over previous GPT-3 models.</li>
</ul>
<h3 id="Large-Language-Model-LLM"><a href="#Large-Language-Model-LLM" class="headerlink" title="Large Language Model (LLM)"></a>Large Language Model (LLM)</h3><ol>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/cant-access-gpt-3-here-s-gpt-j-its-open-source-cousin-8af86a638b11">GPT-J-6B</a> - Can’t access GPT-3? Here’s GPT-J — its open-source cousin.</li>
<li><a target="_blank" rel="noopener" href="https://minimaxir.com/2021/06/gpt-j-6b/">Fun and Dystopia With AI-Based Code Generation Using GPT-J-6B</a> - Prior to GitHub Copilot tech preview launch, Max Woolf, a data scientist tested GPT-J-6B’s code “writing” abilities.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/CodedotAl/gpt-code-clippy">GPT-Code-Clippy (GPT-CC)</a> - An open source version of GitHub Copilot. The GPT-CC models are fine-tuned versions of GPT-2 and GPT-Neo.</li>
<li><a target="_blank" rel="noopener" href="https://blog.eleuther.ai/announcing-20b/">GPT-NeoX-20B</a> - A 20 billion parameter model trained using EleutherAI’s <a target="_blank" rel="noopener" href="https://github.com/EleutherAI/gpt-neox">GPT-NeoX</a> framework. They expect it to perform well on many tasks. You can try out the model on <a target="_blank" rel="noopener" href="https://goose.ai/">GooseAI</a> playground.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/metaseq">Metaseq</a> - A codebase for working with <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.01068">Open Pre-trained Transformers (OPT)</a>.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/yandex/YaLM-100B">YaLM 100B</a> by Yandex is a GPT-like pretrained language model with 100B parameters for generating and processing text. It can be used <strong>freely</strong> by developers and researchers from all over the world.</li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/bigscience/bloom">BigScience’s BLOOM-176B</a> from the Hugging Face repository [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.15424">paper</a>, <a target="_blank" rel="noopener" href="https://bigscience.huggingface.co/blog/bloom">blog post</a>] - BLOOM is a 175-billion parameter model for language processing, able to generate text much like GPT-3 and OPT-175B. It was developed to be multilingual, being deliberately trained on datasets containing 46 natural languages and 13 programming languages.</li>
<li><a target="_blank" rel="noopener" href="https://docs.google.com/document/d/1JxSo4lQgMDBdnd19VBEoaG-mMfQupQ3XvOrgmRAVtpU/edit">bitsandbytes-Int8 inference for Hugging Face models</a> - You can run BLOOM-176B&#x2F;OPT-175B easily on a single machine, without performance degradation. If true, this could be a game changer in enabling people outside of big tech companies being able to use these LLMs.</li>
</ol>
<h3 id="Additional-Reading"><a href="#Additional-Reading" class="headerlink" title="Additional Reading"></a>Additional Reading</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.reddit.com/r/MachineLearning/comments/bj0dsa/d_how_to_build_openais_gpt2_the_ai_thats_too/">How to Build OpenAI’s GPT-2: “The AI That’s Too Dangerous to Release”</a>.</li>
<li><a target="_blank" rel="noopener" href="https://www.skynettoday.com/briefs/gpt2">OpenAI’s GPT2 - Food to Media hype or Wake Up Call?</a></li>
<li><a target="_blank" rel="noopener" href="https://hackingsemantics.xyz/2019/leaderboards/">How the Transformers broke NLP leaderboards</a> by Anna Rogers. :fire::fire::fire:</li>
</ol>
<ul>
<li>A well put summary post on problems with large models that dominate NLP these days.</li>
<li>Larger models + more data &#x3D; progress in Machine Learning research :question:</li>
</ul>
<ol start="4">
<li><a target="_blank" rel="noopener" href="http://www.peterbloem.nl/blog/transformers">Transformers From Scratch</a> tutorial by Peter Bloem.</li>
<li><a target="_blank" rel="noopener" href="https://devblogs.nvidia.com/nlu-with-tensorrt-bert/">Real-time Natural Language Understanding with BERT using NVIDIA TensorRT</a> on Google Cloud T4 GPUs achieves 2.2 ms latency for inference. Optimizations are open source on GitHub.</li>
<li><a target="_blank" rel="noopener" href="https://thegradient.pub/nlps-clever-hans-moment-has-arrived/">NLP’s Clever Hans Moment has Arrived</a> by The Gradient.</li>
<li><a target="_blank" rel="noopener" href="https://pair-code.github.io/interpretability/bert-tree/">Language, trees, and geometry in neural networks</a> - a series of expository notes accompanying the paper, “Visualizing and Measuring the Geometry of BERT” by Google’s People + AI Research (PAIR) team.</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2">Benchmarking Transformers: PyTorch and TensorFlow</a> by Hugging Face - a comparison of inference time (on CPU and GPU) and memory usage for a wide range of transformer architectures.</li>
<li><a target="_blank" rel="noopener" href="https://lena-voita.github.io/posts/emnlp19_evolution.html">Evolution of representations in the Transformer</a> - An accessible article that presents the insights of their EMNLP 2019 paper. They look at how the representations of individual tokens in Transformers trained with different objectives change.</li>
<li><a target="_blank" rel="noopener" href="https://text-machine-lab.github.io/blog/2020/bert-secrets/">The dark secrets of BERT</a> - This post probes fine-tuned BERT models for linguistic knowledge. In particular, the authors analyse how many self-attention patterns with some linguistic interpretation are actually used to solve downstream tasks. TL;DR: They are unable to find evidence that linguistically interpretable self-attention maps are crucial for downstream performance.</li>
<li><a target="_blank" rel="noopener" href="https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/">A Visual Guide to Using BERT for the First Time</a> - Tutorial on using BERT in practice, such as for sentiment analysis on movie reviews by Jay Alammar.</li>
<li><a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/">Turing-NLG: A 17-billion-parameter language model</a> by Microsoft that outperforms the state of the art on many downstream NLP tasks. This work would not be possible without breakthroughs produced by the <a target="_blank" rel="noopener" href="https://github.com/microsoft/DeepSpeed">DeepSpeed library</a> (compatible with PyTorch) and <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.02054">ZeRO optimizer</a>, which can be explored more in this accompanying <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters">blog post</a>.</li>
<li><a target="_blank" rel="noopener" href="https://blog.google/products/search/introducing-mum/">MUM (Multitask Unified Model): A new AI milestone for understanding information</a> by Google.</li>
</ol>
<ul>
<li>Based on transformer architecture but more powerful.</li>
<li>Multitask means: supports text and images, knowledge transfer between 75 languages, understand context and go deeper in a topic, and generate content.</li>
</ul>
<ol start="14">
<li><a target="_blank" rel="noopener" href="https://lastweekin.ai/p/gpt-3-is-no-longer-the-only-game">GPT-3 is No Longer the Only Game in Town</a> - GPT-3 was by far the largest AI model of its kind last year (2020). Now? Not so much.</li>
<li><a target="_blank" rel="noopener" href="https://openai.com/blog/api-no-waitlist/">OpenAI’s API Now Available with No Waitlist</a> - GPT-3 access without the wait. However, apps must be approved before <a target="_blank" rel="noopener" href="https://beta.openai.com/docs/going-live">going live</a>. This release also allow them to review applications, monitor for misuse, and better understand the effects of this tech.</li>
<li><a target="_blank" rel="noopener" href="https://lastweekin.ai/p/the-inherent-limitations-of-gpt-3">The Inherent Limitations of GPT-3</a> - One thing missing from the article if you’ve read <a target="_blank" rel="noopener" href="https://www.gwern.net/GPT-3#repetitiondivergence-sampling">Gwern’s GPT-3 Creative Fiction article</a> before is the mystery known as “Repetition&#x2F;Divergence Sampling”:<blockquote>
<p>when you generate free-form completions, they have a tendency to eventually fall into repetitive loops of gibberish.</p>
</blockquote>
For those using Copilot, you should have experienced this wierdness where it generates the same line or block of code over and over again.</li>
<li><a target="_blank" rel="noopener" href="https://deepmind.com/blog/article/language-modelling-at-scale">Language Modelling at Scale: Gopher, Ethical considerations, and Retrieval</a> by DeepMind - The paper present an analysis of Transformer-based language model performance across a wide range of model scales — from models with tens of millions of parameters up to a 280 billion parameter model called Gopher.</li>
<li><a target="_blank" rel="noopener" href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode">Competitive programming with AlphaCode</a> by DeepMind - AlphaCode uses transformer-based language models to generate code that can create novel solutions to programming problems which require an understanding of algorithms.</li>
<li><a target="_blank" rel="noopener" href="https://andrewmayneblog.wordpress.com/2022/03/17/building-games-and-apps-entirely-through-natural-language-using-openais-davinci-code-model/">Building games and apps entirely through natural language using OpenAI’s code-davinci model</a> - The author built several small games and apps without touching a single line of code, simply by telling the model what they want.</li>
<li><a target="_blank" rel="noopener" href="https://statmodeling.stat.columbia.edu/2022/03/28/is-open-ai-cooking-the-books-on-gpt-3/">Open AI gets GPT-3 to work by hiring an army of humans to fix GPT’s bad answers</a></li>
<li><a target="_blank" rel="noopener" href="https://mayt.substack.com/p/gpt-3-can-run-code">GPT-3 can run code</a> - You provide an input text and a command and GPT-3 will transform them into an expected output. It works well for tasks like changing coding style, translating between programming languages, refactoring, and adding doc. For example, converts JSON into YAML, translates Python code to JavaScript, improve the runtime complexity of the function.</li>
<li><a target="_blank" rel="noopener" href="https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/">Using GPT-3 to explain how code works</a> by Simon Willison.</li>
<li><a target="_blank" rel="noopener" href="https://blog.character.ai/introducing-character/">Character AI announces they’re building a full stack AGI company</a> so you could create your own AI to help you with anything, using conversational AI research. The co-founders Noam Shazeer (co-invented Transformers, scaled them to supercomputers for the first time, and pioneered large-scale pretraining) and Daniel de Freitas (led the development of LaMDA), all of which are foundational to recent AI progress.</li>
<li><a target="_blank" rel="noopener" href="https://scale.com/blog/gpt-3-davinci-003-comparison">How Much Better is OpenAI’s Newest GPT-3 Model?</a> - In addition to ChatGPT, OpenAI releases text-davinci-003, a Reinforcement Learning-tuned model that performs better long-form writing. Example, it can explain code in the style of Eminem. 😀</li>
</ol>
<h2 id="Educational"><a href="#Educational" class="headerlink" title="Educational"></a>Educational</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/karpathy/minGPT">minGPT</a> by Andrej Karpathy - A PyTorch re-implementation of GPT, both training and inference. minGPT tries to be small, clean, interpretable and educational, as most of the currently available GPT model implementations can a bit sprawling. GPT is not a complicated model and this implementation is appropriately about 300 lines of code.</li>
</ul>
<h3 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h3><ol>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/blog/how-to-train">How to train a new language model from scratch using Transformers and Tokenizers</a> tutorial by Hugging Face. :fire:</li>
</ol>
<h2 id="Videos"><a href="#Videos" class="headerlink" title="Videos"></a>Videos</h2><h3 id="BERTology"><a href="#BERTology" class="headerlink" title="BERTology"></a><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/bertology.html">BERTology</a></h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=naOuE9gLbZo">XLNet Explained</a> by NLP Breakfasts.</li>
</ol>
<ul>
<li>Clear explanation. Also covers the two-stream self-attention idea.</li>
</ul>
<ol start="2">
<li><a target="_blank" rel="noopener" href="https://youtu.be/G5lmya6eKtc">The Future of NLP</a> by 🤗</li>
</ol>
<ul>
<li>Dense overview of what is going on in transfer learning in NLP currently, limits, and future directions.</li>
</ul>
<ol start="3">
<li><a target="_blank" rel="noopener" href="https://youtu.be/FWFA4DGuzSc">The Transformer neural network architecture explained</a> by AI Coffee Break with Letitia Parcalabescu.</li>
</ol>
<ul>
<li>High-level explanation, best suited when unfamiliar with Transformers.</li>
</ul>
<h3 id="Attention-and-Transformer-Networks"><a href="#Attention-and-Transformer-Networks" class="headerlink" title="Attention and Transformer Networks"></a>Attention and Transformer Networks</h3><ol>
<li><a target="_blank" rel="noopener" href="https://youtu.be/GTVgJhSlHEk">Sequence to Sequence Learning Animated (Inside Transformer Neural Networks and Attention Mechanisms)</a> by learningcurve.</li>
</ol>
<h2 id="Official-Implementations"><a href="#Official-Implementations" class="headerlink" title="Official Implementations"></a>Official Implementations</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/google-research/bert">google-research&#x2F;bert</a> - TensorFlow code and pre-trained models for BERT.</li>
</ol>
<h2 id="Other-Implementations"><a href="#Other-Implementations" class="headerlink" title="Other Implementations"></a>Other Implementations</h2><h3 id="PyTorch-and-TensorFlow"><a href="#PyTorch-and-TensorFlow" class="headerlink" title="PyTorch and TensorFlow"></a>PyTorch and TensorFlow</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers">🤗 Hugging Face Transformers</a> (formerly known as <a target="_blank" rel="noopener" href="https://github.com/huggingface/pytorch-transformers">pytorch-transformers</a> and <a target="_blank" rel="noopener" href="https://github.com/huggingface/pytorch-pretrained-BERT">pytorch-pretrained-bert</a>) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL…) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch. [<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.03771">Paper</a>]</li>
<li><a target="_blank" rel="noopener" href="https://github.com/explosion/spacy-transformers">spacy-transformers</a> - a library that wrap Hugging Face’s Transformers, in order to extract features to power NLP pipelines. It also calculates an alignment so the Transformer features can be related back to actual words instead of just wordpieces.</li>
</ol>
<h3 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/codertimo/BERT-pytorch">codertimo&#x2F;BERT-pytorch</a> - Google AI 2018 BERT pytorch implementation.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/innodatalabs/tbert">innodatalabs&#x2F;tbert</a> - PyTorch port of BERT ML model.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kimiyoung/transformer-xl">kimiyoung&#x2F;transformer-xl</a> - Code repository associated with the Transformer-XL paper.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/dreamgonfly/BERT-pytorch">dreamgonfly&#x2F;BERT-pytorch</a> - A PyTorch implementation of BERT in “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/dhlee347/pytorchic-bert">dhlee347&#x2F;pytorchic-bert</a> - A Pytorch implementation of Google BERT.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/pingpong-ai/xlnet-pytorch">pingpong-ai&#x2F;xlnet-pytorch</a> - A Pytorch implementation of Google Brain XLNet.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/pytorch/fairseq/blob/master/examples/roberta/README.md">facebook&#x2F;fairseq</a> - RoBERTa: A Robustly Optimized BERT Pretraining Approach by Facebook AI Research. SoTA results on GLUE, SQuAD and RACE.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/Megatron-LM">NVIDIA&#x2F;Megatron-LM</a> - Ongoing research training transformer language models at scale, including: BERT.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/deepset-ai/FARM">deepset-ai&#x2F;FARM</a> - Simple &amp; flexible transfer learning for the industry.</li>
<li><a target="_blank" rel="noopener" href="https://www.intel.ai/nlp-transformer-models/">NervanaSystems&#x2F;nlp-architect</a> - NLP Architect by Intel AI. Among other libraries, it provides a quantized version of Transformer models and efficient training method.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kaushaltrivedi/fast-bert">kaushaltrivedi&#x2F;fast-bert</a> - Super easy library for BERT based NLP models. Built based on 🤗 Transformers and is inspired by fast.ai.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/NeMo">NVIDIA&#x2F;NeMo</a> - Neural Modules is a toolkit for conversational AI by NVIDIA. They are trying to <a target="_blank" rel="noopener" href="https://nvidia.github.io/NeMo/nlp/intro.html#improving-speech-recognition-with-bertx2-post-processing-model">improve speech recognition with BERT post-processing</a>.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/mmbt/">facebook&#x2F;MMBT</a> from Facebook AI - Multimodal transformers model that can accept a transformer model and a computer vision model for classifying image and text.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/dbiir/UER-py">dbiir&#x2F;UER-py</a> from Tencent and RUC - Open Source Pre-training Model Framework in PyTorch &amp; Pre-trained Model Zoo (with more focus on Chinese).</li>
</ol>
<h3 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/Separius/BERT-keras">Separius&#x2F;BERT-keras</a> - Keras implementation of BERT with pre-trained weights.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/CyberZHG/keras-bert">CyberZHG&#x2F;keras-bert</a> - Implementation of BERT that could load official pre-trained models for feature extraction and prediction.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/bojone/bert4keras">bojone&#x2F;bert4keras</a> - Light reimplement of BERT for Keras.</li>
</ol>
<h3 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/guotong1988/BERT-tensorflow">guotong1988&#x2F;BERT-tensorflow</a> - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kimiyoung/transformer-xl">kimiyoung&#x2F;transformer-xl</a> - Code repository associated with the Transformer-XL paper.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/zihangdai/xlnet">zihangdai&#x2F;xlnet</a> - Code repository associated with the XLNet paper.</li>
</ol>
<h3 id="Chainer"><a href="#Chainer" class="headerlink" title="Chainer"></a>Chainer</h3><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/soskek/bert-chainer">soskek&#x2F;bert-chainer</a> - Chainer implementation of “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”.</li>
</ol>
<h2 id="Transfer-Learning-in-NLP"><a href="#Transfer-Learning-in-NLP" class="headerlink" title="Transfer Learning in NLP"></a>Transfer Learning in NLP</h2><p>As Jay Alammar put it:</p>
<blockquote>
<p>The year 2018 has been an inflection point for machine learning models handling text (or more accurately, Natural Language Processing or NLP for short). Our conceptual understanding of how best to represent words and sentences in a way that best captures underlying meanings and relationships is rapidly evolving. Moreover, the NLP community has been putting forward incredibly powerful components that you can freely download and use in your own models and pipelines (It’s been referred to as <a target="_blank" rel="noopener" href="http://ruder.io/nlp-imagenet/">NLP’s ImageNet moment</a>, referencing how years ago similar developments accelerated the development of machine learning in Computer Vision tasks).</p>
<p>One of the latest milestones in this development is the <a target="_blank" rel="noopener" href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">release</a> of <a target="_blank" rel="noopener" href="https://github.com/google-research/bert">BERT</a>, an event <a target="_blank" rel="noopener" href="https://twitter.com/lmthang/status/1050543868041555969">described</a> as marking the beginning of a new era in NLP. BERT is a model that broke several records for how well models can handle language-based tasks. Soon after the release of the paper describing the model, the team also open-sourced the code of the model, and made available for download versions of the model that were already pre-trained on massive datasets. This is a momentous development since it enables anyone building a machine learning model involving language processing to use this powerhouse as a readily-available component – saving the time, energy, knowledge, and resources that would have gone to training a language-processing model from scratch.</p>
<p>BERT builds on top of a number of clever ideas that have been bubbling up in the NLP community recently – including but not limited to <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.01432">Semi-supervised Sequence Learning</a> (by <a target="_blank" rel="noopener" href="https://twitter.com/iamandrewdai">Andrew Dai</a> and <a target="_blank" rel="noopener" href="https://twitter.com/quocleix">Quoc Le</a>), <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05365">ELMo</a> (by Matthew Peters and researchers from <a target="_blank" rel="noopener" href="https://allenai.org/">AI2</a> and <a target="_blank" rel="noopener" href="https://www.engr.washington.edu/about/bldgs/cse">UW CSE</a>), <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.06146">ULMFiT</a> (by <a target="_blank" rel="noopener" href="https://fast.ai/">fast.ai</a> founder <a target="_blank" rel="noopener" href="https://twitter.com/jeremyphoward">Jeremy Howard</a> and <a target="_blank" rel="noopener" href="https://twitter.com/seb_ruder">Sebastian Ruder</a>), the <a target="_blank" rel="noopener" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">OpenAI transformer</a> (by OpenAI researchers <a target="_blank" rel="noopener" href="https://twitter.com/alecrad">Radford</a>, <a target="_blank" rel="noopener" href="https://twitter.com/karthik_r_n">Narasimhan</a>, <a target="_blank" rel="noopener" href="https://twitter.com/timsalimans">Salimans</a>, and <a target="_blank" rel="noopener" href="https://twitter.com/ilyasut">Sutskever</a>), and the Transformer (<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Vaswani et al</a>).</p>
<p><strong>ULMFiT: Nailing down Transfer Learning in NLP</strong></p>
<p><a target="_blank" rel="noopener" href="http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html">ULMFiT introduced methods to effectively utilize a lot of what the model learns during pre-training</a> – more than just embeddings, and more than contextualized embeddings. ULMFiT introduced a language model and a process to effectively fine-tune that language model for various tasks.</p>
<p>NLP finally had a way to do transfer learning probably as well as Computer Vision could.</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="http://nlp.fast.ai/classification/2019/09/10/multifit.html">MultiFiT: Efficient Multi-lingual Language Model Fine-tuning</a> by Sebastian Ruder et al. MultiFiT extends ULMFiT to make it more efficient and more suitable for language modelling beyond English. (<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.04761">EMNLP 2019 paper</a>)</p>
<h2 id="Books"><a href="#Books" class="headerlink" title="Books"></a>Books</h2><ol>
<li><a target="_blank" rel="noopener" href="https://www.manning.com/books/transfer-learning-for-natural-language-processing">Transfer Learning for Natural Language Processing</a> - A book that is a practical primer to transfer learning techniques capable of delivering huge improvements to your NLP models.</li>
</ol>
<h2 id="Other-Resources"><a href="#Other-Resources" class="headerlink" title="Other Resources"></a>Other Resources</h2><details>

<summary><b>Expand Other Resources</b></summary>

<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/hanxiao/bert-as-service">hanxiao&#x2F;bert-as-service</a> - Mapping a variable-length sentence to a fixed-length vector using pretrained BERT model.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/brightmart/bert_language_understanding">brightmart&#x2F;bert_language_understanding</a> - Pre-training of Deep Bidirectional Transformers for Language Understanding: pre-train TextCNN.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/algteam/bert-examples">algteam&#x2F;bert-examples</a> - BERT examples.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/JayYip/bert-multiple-gpu">JayYip&#x2F;bert-multiple-gpu</a> - A multiple GPU support version of BERT.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/HighCWu/keras-bert-tpu">HighCWu&#x2F;keras-bert-tpu</a> - Implementation of BERT that could load official pre-trained models for feature extraction and prediction on TPU.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/whqwill/seq2seq-keyphrase-bert">whqwill&#x2F;seq2seq-keyphrase-bert</a> - Add BERT to encoder part for <a target="_blank" rel="noopener" href="https://github.com/memray/seq2seq-keyphrase-pytorch">https://github.com/memray/seq2seq-keyphrase-pytorch</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/xu-song/bert_as_language_model">xu-song&#x2F;bert_as_language_model</a> - BERT as language model, a fork from Google official BERT implementation.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/Y1ran/NLP-BERT--ChineseVersion">Y1ran&#x2F;NLP-BERT–Chinese version</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/yuanxiaosc/Deep_dynamic_word_representation">yuanxiaosc&#x2F;Deep_dynamic_word_representation</a> - TensorFlow code and pre-trained models for deep dynamic word representation (DDWR). It combines the BERT model and ELMo’s deep context word representation.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/yangbisheng2009/cn-bert">yangbisheng2009&#x2F;cn-bert</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Willyoung2017/Bert_Attempt">Willyoung2017&#x2F;Bert_Attempt</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Pydataman/bert_examples">Pydataman&#x2F;bert_examples</a> - Some examples of BERT. <code>run_classifier.py</code> based on Google BERT for Kaggle Quora Insincere Questions Classification challenge. <code>run_ner.py</code> is based on the first season of the Ruijin Hospital AI contest and a NER written by BERT.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/guotong1988/BERT-chinese">guotong1988&#x2F;BERT-chinese</a> - Pre-training of deep bidirectional transformers for Chinese language understanding.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/zhongyunuestc/bert_multitask">zhongyunuestc&#x2F;bert_multitask</a> - Multi-task.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/Microsoft/AzureML-BERT">Microsoft&#x2F;AzureML-BERT</a> - End-to-end walk through for fine-tuning BERT using Azure Machine Learning.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/bigboNed3/bert_serving">bigboNed3&#x2F;bert_serving</a> - Export BERT model for serving.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/yoheikikuta/bert-japanese">yoheikikuta&#x2F;bert-japanese</a> - BERT with SentencePiece for Japanese text.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/nickwalton/AIDungeon">nickwalton&#x2F;AIDungeon</a> - AI Dungeon 2 is a completely AI generated text adventure built with OpenAI’s largest 1.5B param GPT-2 model. It’s a first of it’s kind game that allows you to enter and will react to any action you can imagine.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/turtlesoupy/this-word-does-not-exist">turtlesoupy&#x2F;this-word-does-not-exist</a> - “This Word Does Not Exist” is a project that allows people to train a variant of GPT-2 that makes up words, definitions and examples from scratch. We’ve never seen fake text so real.</details></li>
</ol>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/jessevig/bertviz">jessevig&#x2F;bertviz</a> - Tool for visualizing attention in the Transformer model.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kaushaltrivedi/fast-bert">FastBert</a> - A simple deep learning library that allows developers and data scientists to train and deploy BERT based models for NLP tasks beginning with text classification. The work on FastBert is inspired by fast.ai.</li>
<li><a target="_blank" rel="noopener" href="https://bellard.org/libnc/gpt2tc.html">gpt2tc</a> - A small program using the GPT-2 LM to complete and compress texts. It has no external dependency, requires no GPU and is quite fast. The smallest model (117M parameters) is provided. Larger models can be downloaded as well. (no waitlist, no sign up required).</li>
</ol>
<h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h2><h3 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named-Entity Recognition (NER)"></a>Named-Entity Recognition (NER)</h3><details>

<summary><b>Expand NER</b></summary>

<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/kyzhouhzau/BERT-NER">kyzhouhzau&#x2F;BERT-NER</a> - Use google BERT to do CoNLL-2003 NER.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/zhpmatrix/bert-sequence-tagging">zhpmatrix&#x2F;bert-sequence-tagging</a> - Chinese sequence labeling.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/JamesGu14/BERT-NER-CLI">JamesGu14&#x2F;BERT-NER-CLI</a> - Bert NER command line tester with step by step setup guide.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/sberbank-ai/ner-bert">sberbank-ai&#x2F;ner-bert</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/mhcao916/NER_Based_on_BERT">mhcao916&#x2F;NER_Based_on_BERT</a> - This project is based on Google BERT model, which is a Chinese NER.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/macanv/BERT-BiLSMT-CRF-NER">macanv&#x2F;BERT-BiLSMT-CRF-NER</a> - TensorFlow solution of NER task using Bi-LSTM-CRF model with Google BERT fine-tuning.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/ProHiryu/bert-chinese-ner">ProHiryu&#x2F;bert-chinese-ner</a> - Use the pre-trained language model BERT to do Chinese NER.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/FuYanzhe2/Name-Entity-Recognition">FuYanzhe2&#x2F;Name-Entity-Recognition</a> - Lstm-CRF, Lattice-CRF, recent NER related papers.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/king-menin/ner-bert">king-menin&#x2F;ner-bert</a> - NER task solution (BERT-Bi-LSTM-CRF) with Google BERT <a target="_blank" rel="noopener" href="https://github.com/google-research">https://github.com/google-research</a>.</details></li>
</ol>
<h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><details>

<summary><b>Expand Classification</b></summary>

<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/brightmart/sentiment_analysis_fine_grain">brightmart&#x2F;sentiment_analysis_fine_grain</a> - Multi-label classification with BERT; Fine Grained Sentiment Analysis from AI challenger.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/zhpmatrix/Kaggle-Quora-Insincere-Questions-Classification">zhpmatrix&#x2F;Kaggle-Quora-Insincere-Questions-Classification</a> - Kaggle baseline—fine-tuning BERT and tensor2tensor based Transformer encoder solution.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/maksna/bert-fine-tuning-for-chinese-multiclass-classification">maksna&#x2F;bert-fine-tuning-for-chinese-multiclass-classification</a> - Use Google pre-training model BERT to fine-tune for the Chinese multiclass classification.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/NLPScott/bert-Chinese-classification-task">NLPScott&#x2F;bert-Chinese-classification-task</a> - BERT Chinese classification practice.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/fooSynaptic/BERT_classifer_trial">fooSynaptic&#x2F;BERT_classifer_trial</a> - BERT trial for Chinese corpus classfication.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/xiaopingzhong/bert-finetune-for-classfier">xiaopingzhong&#x2F;bert-finetune-for-classfier</a> - Fine-tuning the BERT model while building your own dataset for classification.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/Socialbird-AILab/BERT-Classification-Tutorial">Socialbird-AILab&#x2F;BERT-Classification-Tutorial</a> - Tutorial.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/malteos/pytorch-bert-document-classification/">malteos&#x2F;pytorch-bert-document-classification</a> - Enriching BERT with Knowledge Graph Embedding for Document Classification (PyTorch)</details></li>
</ol>
<h3 id="Text-Generation"><a href="#Text-Generation" class="headerlink" title="Text Generation"></a>Text Generation</h3><details>

<summary><b>Expand Text Generation</b></summary>

<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/asyml/texar">asyml&#x2F;texar</a> - Toolkit for Text Generation and Beyond. <a target="_blank" rel="noopener" href="https://texar.io/">Texar</a> is a general-purpose text generation toolkit, has also implemented BERT here for classification, and text generation applications by combining with Texar’s other modules.</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1912.02164">Plug and Play Language Models: a Simple Approach to Controlled Text Generation</a> (PPLM) paper by Uber AI.</details></li>
</ol>
<h3 id="Question-Answering-QA"><a href="#Question-Answering-QA" class="headerlink" title="Question Answering (QA)"></a>Question Answering (QA)</h3><details>

<summary><b>Expand QA</b></summary>

<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/matthew-z/R-net">matthew-z&#x2F;R-net</a> - R-net in PyTorch, with BERT and ELMo.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/vliu15/BERT">vliu15&#x2F;BERT</a> - TensorFlow implementation of BERT for QA.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/benywon/ChineseBert">benywon&#x2F;ChineseBert</a> - This is a Chinese BERT model specific for question answering.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/xzp27/BERT-for-Chinese-Question-Answering">xzp27&#x2F;BERT-for-Chinese-Question-Answering</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/SpanBERT">facebookresearch&#x2F;SpanBERT</a> - Question Answering on SQuAD; improving pre-training by representing and predicting spans.</details></li>
</ol>
<h3 id="Knowledge-Graph"><a href="#Knowledge-Graph" class="headerlink" title="Knowledge Graph"></a>Knowledge Graph</h3><details>

<summary><b>Expand Knowledge Graph</b></summary>

<ol>
<li><a target="_blank" rel="noopener" href="https://github.com/sakuranew/BERT-AttributeExtraction">sakuranew&#x2F;BERT-AttributeExtraction</a> - Using BERT for attribute extraction in knowledge graph. Fine-tuning and feature extraction. The BERT-based fine-tuning and feature extraction methods are used to extract knowledge attributes of Baidu Encyclopedia characters.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/lvjianxin/Knowledge-extraction">lvjianxin&#x2F;Knowledge-extraction</a> - Chinese knowledge-based extraction. Baseline: bi-LSTM+CRF upgrade: BERT pre-training.</details></li>
</ol>
<h2 id="License"><a href="#License" class="headerlink" title="License"></a>License</h2><details>

<summary><b>Expand License</b></summary>

<p>This repository contains a variety of content; some developed by Cedric Chee, and some from third-parties. The third-party content is distributed under the license provided by those parties.</p>
<p><em>I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer.</em></p>
<p>The content developed by Cedric Chee is distributed under the following license:</p>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>The code in this repository, including all code samples in the notebooks listed above, is released under the <a href="LICENSE">MIT license</a>. Read more at the <a target="_blank" rel="noopener" href="https://opensource.org/licenses/MIT">Open Source Initiative</a>.</p>
<h3 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h3><p>The text content of the book is released under the CC-BY-NC-ND license. Read more at <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode">Creative Commons</a>.</p>
</details>

	
	</div>
  <a type="button" href="/2023/12/22/f79db9b7-459c-4d4b-9922-b528ccee0c30/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f81a975f-8ce8-4c8c-9b7a-d398f65c718a/" title="This article discusses a collection of programmer jokes, including a list from Runoob and Telegram channels dedicated to programming humor.">程序员笑话 可当文案 jokes about programmers</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="程序员笑话-可当文案-jokes-about-programmers"><a href="#程序员笑话-可当文案-jokes-about-programmers" class="headerlink" title="程序员笑话 可当文案 jokes about programmers"></a>程序员笑话 可当文案 jokes about programmers</h1><p>runoob coder jokes:<br><a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote_genre/joke/page/2">https://www.runoob.com/w3cnote_genre/joke/page/2</a></p>
<p>telegram channels for programmer jokes</p>

	
	</div>
  <a type="button" href="/2023/12/22/f81a975f-8ce8-4c8c-9b7a-d398f65c718a/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f8398512-6f0b-433a-ad9f-89f730d636f4/" title="This Python script utilizes SymPy for performing various interval operations. It allows you to manage, merge, and sort sets of intervals, detect overlaps, convert continuous data into intervals, solve unions, filter short intervals, and transform interval sets into tuples. The provided functions enable you to obtain a merged interval tuple list and easily handle and manipulate interval sets.">连续区间 离散区间 从离散数据中获得离散区间 交并补</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="连续区间-离散区间-从离散数据中获得离散区间-交并补"><a href="#连续区间-离散区间-从离散数据中获得离散区间-交并补" class="headerlink" title="连续区间 离散区间 从离散数据中获得离散区间 交并补"></a>连续区间 离散区间 从离散数据中获得离散区间 交并补</h1><p>离散区间的获得可以用边界条件判定 即最近n个连续的概率大于多少 容忍值为多少 最近n个小于多少直接作为结束边界的条件 也可以用convolution Gaussian blur</p>
<p>离散区间交并补可以转化为连续区间交并补 更简单省事</p>
<p>如果要做下面的运算 建议用第三方库 比如wolfram swi-prolog的clpr sympy</p>
<p>连续区间交并补 先排序 设置首末端的操作 然后进行相应区间选取 进行下一步操作直到结束 输出总的结果</p>
<h2 id="combining-similar-nearby-bounding-boxes-suppressing-near-duplicate-bounding-boxes-over-short-time"><a href="#combining-similar-nearby-bounding-boxes-suppressing-near-duplicate-bounding-boxes-over-short-time" class="headerlink" title="combining similar&#x2F;nearby bounding boxes, suppressing near duplicate bounding boxes over short time"></a>combining similar&#x2F;nearby bounding boxes, suppressing near duplicate bounding boxes over short time</h2><p><a href="./textbook!.md">see here</a></p>
<p>you can merge a group of things, then analyze them over time using object tracker, tweening them.</p>
<h2 id="Discrete-Interval-Set-Union-Solvers"><a href="#Discrete-Interval-Set-Union-Solvers" class="headerlink" title="Discrete Interval Set Union Solvers"></a>Discrete Interval Set Union Solvers</h2><p>you may want to filter out short intervals. mind the lopen&#x2F;ropen interval after intersection or difference operation.</p>
<p>you may also want to quantize these intervals, set them to nearest possible points. 用到某采样率 还是根本不用吧 就是属于那个区间的离散点上面执行相应的操作变化 但是那个区间如何划分 怎么把离散点归类到不同区间里面 完全是其他的逻辑需要做的事情 一般同类别的区间不能相交 但是之后再考虑吧 怎么用呢 所有的全部弄到一个列表里面 还是选取最小的那个来用？</p>
<p>category with different groups -&gt; subcategories</p>
<p>first the sample set:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import sympy</span><br><span class="line"></span><br><span class="line"><span class="comment"># make sure every subset is ordered.</span></span><br><span class="line">mSet = [(1.0,1.1,1.2),(2.4,2.5,2.6)]</span><br><span class="line">mSet2 = [(0.9,1.05,1.15),(2.45,2.55,2.65,2.75)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert to intervals first please?</span></span><br><span class="line">mSetIntervals = [(x[0],x[-1]) <span class="keyword">for</span> x <span class="keyword">in</span> mSet]</span><br><span class="line">mSet2Intervals = [(x[0],x[-1]) <span class="keyword">for</span> x <span class="keyword">in</span> mSet2]</span><br><span class="line"></span><br><span class="line"><span class="comment"># additional check: these intervals cannot overlap!</span></span><br><span class="line">def checkOverlap(intervalTupleList):</span><br><span class="line">  unionInterval = sympy.EmptySet <span class="comment"># shall be empty here.</span></span><br><span class="line">  <span class="keyword">for</span> start, end <span class="keyword">in</span> intervalTupleList:</span><br><span class="line">    newInterval = sympy.Interval(start,end)</span><br><span class="line">    isOverlapped = (sympy.EmptySet == unionInterval.intersect(newInterval))</span><br><span class="line">    <span class="keyword">if</span> isOverlapped:</span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&quot;INTERVAL&quot;</span>, newInterval, <span class="string">&quot;OVERLAPPED!&quot;</span>)</span><br><span class="line">      <span class="built_in">return</span> isOverlapped</span><br><span class="line">    unionInterval += newInterval</span><br><span class="line">  <span class="built_in">return</span> False</span><br><span class="line"></span><br><span class="line">assert not checkOverlap(mSetIntervals)</span><br><span class="line">assert not checkOverlap(mSet2Intervals)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>then pool and sort all the boundaries of converted intervals:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mPoints = mSetIntervalBoundaries + mSet2IntervalBoundaries</span><br><span class="line">mPoints = list(<span class="built_in">set</span>(mPoints))</span><br><span class="line">mPoints.<span class="built_in">sort</span>()</span><br></pre></td></tr></table></figure>
<h3 id="with-sympy"><a href="#with-sympy" class="headerlink" title="with sympy"></a>with sympy</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># all the same</span></span><br></pre></td></tr></table></figure>
<h3 id="with-less-sympy"><a href="#with-less-sympy" class="headerlink" title="with less sympy"></a>with less sympy</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># all the same</span></span><br></pre></td></tr></table></figure>

<h2 id="Continual-Interval-Set-Union-Solvers"><a href="#Continual-Interval-Set-Union-Solvers" class="headerlink" title="Continual Interval Set Union Solvers"></a>Continual Interval Set Union Solvers</h2><p>you must be able to explicitly point out different group index of different category. maybe you can just do it in all-new subcategories?</p>
<h3 id="less-exponential-solution-here"><a href="#less-exponential-solution-here" class="headerlink" title="less exponential solution here?"></a>less exponential solution here?</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># basically the same example.</span></span><br><span class="line"><span class="comment"># assume no overlapping here.</span></span><br><span class="line">import sympy</span><br><span class="line"></span><br><span class="line">def unionToTupleList(myUnion):</span><br><span class="line">  unionBoundaries = list(myUnion.boundary)</span><br><span class="line">  unionBoundaries.<span class="built_in">sort</span>()</span><br><span class="line">  leftBoundaries = unionBoundaries[::2]</span><br><span class="line">  rightBoundaries = unionBoundaries[1::2]</span><br><span class="line">  <span class="built_in">return</span> list(zip(leftBoundaries, rightBoundaries))</span><br><span class="line"></span><br><span class="line">def tupleSetToUncertain(mSet):</span><br><span class="line">  mUncertain = None</span><br><span class="line">  <span class="keyword">for</span> start, end <span class="keyword">in</span> mSet:</span><br><span class="line">    <span class="keyword">if</span> mUncertain is None:</span><br><span class="line">      mUncertain = sympy.Interval(start,end)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      mUncertain += sympy.Interval(start,end)</span><br><span class="line">  typeUncertain = <span class="built_in">type</span>(mUncertain)</span><br><span class="line">  <span class="built_in">return</span> mUncertain, typeUncertain</span><br><span class="line"></span><br><span class="line">def mergeOverlappedInIntervalTupleList(intervalTupleList):</span><br><span class="line">  mUncertain, _ = tupleSetToUncertain(intervalTupleList)</span><br><span class="line">  mUncertainBoundaryList = list(mUncertain.boundary)</span><br><span class="line">  mUncertainBoundaryList.<span class="built_in">sort</span>()</span><br><span class="line">  mergedIntervalTupleList = list(zip(mUncertainBoundaryList[::2], mUncertainBoundaryList[1::2]))</span><br><span class="line">  <span class="built_in">return</span> mergedIntervalTupleList</span><br><span class="line"></span><br><span class="line">mSet = mergeOverlappedInIntervalTupleList([(0,1), (2,3)])</span><br><span class="line">mSet2 = mergeOverlappedInIntervalTupleList([(0.5,1.5),(1.6,2.5)])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSET&quot;</span>, mSet)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSET2&quot;</span>, mSet2)</span><br><span class="line"></span><br><span class="line">mSetCandidates = [mSet, mSet2]</span><br><span class="line">mSetUnified = [x <span class="keyword">for</span> y <span class="keyword">in</span> mSetCandidates <span class="keyword">for</span> x <span class="keyword">in</span> y]</span><br><span class="line">leftBoundaryList = <span class="built_in">set</span>([x[0] <span class="keyword">for</span> x <span class="keyword">in</span> mSetUnified])</span><br><span class="line">rightBoundaryList = <span class="built_in">set</span>([x[1] <span class="keyword">for</span> x <span class="keyword">in</span> mSetUnified])</span><br><span class="line"><span class="comment"># they may freaking overlap.</span></span><br><span class="line"><span class="comment"># if want nearby-merge strategy, simply just expand all intervals, merge them with union and shrink the individual intervals inside union respectively.</span></span><br><span class="line"></span><br><span class="line">markers = &#123;<span class="string">&quot;enter&quot;</span>:&#123;k:[] <span class="keyword">for</span> k <span class="keyword">in</span> leftBoundaryList&#125;, <span class="string">&quot;exit&quot;</span>:&#123;k:[] <span class="keyword">for</span> k <span class="keyword">in</span> rightBoundaryList&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, mSetCandidate <span class="keyword">in</span> enumerate(mSetCandidates):</span><br><span class="line">  leftBoundaryListOfCandidate = [x[0] <span class="keyword">for</span> x <span class="keyword">in</span> mSetCandidate]</span><br><span class="line">  rightBoundaryListOfCandidate = [x[1] <span class="keyword">for</span> x <span class="keyword">in</span> mSetCandidate]</span><br><span class="line">  <span class="keyword">for</span> leftBoundaryOfCandidate <span class="keyword">in</span> leftBoundaryListOfCandidate:</span><br><span class="line">    markers[<span class="string">&quot;enter&quot;</span>][leftBoundaryOfCandidate].append(index) <span class="comment"># remap this thing!</span></span><br><span class="line">  <span class="keyword">for</span> rightBoundaryOfCandidate <span class="keyword">in</span> rightBoundaryListOfCandidate:</span><br><span class="line">    markers[<span class="string">&quot;exit&quot;</span>][rightBoundaryOfCandidate].append(index) <span class="comment"># remap this thing!</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># now, iterate through the boundaries of mSetUnified.</span></span><br><span class="line">unifiedBoundaryList = leftBoundaryList.union(rightBoundaryList) <span class="comment"># call me a set instead of a list please? now we must sort this thing</span></span><br><span class="line">unifiedBoundaryList = list(unifiedBoundaryList)</span><br><span class="line">unifiedBoundaryList.<span class="built_in">sort</span>()</span><br><span class="line"></span><br><span class="line">unifiedBoundaryMarks = &#123;&#125;</span><br><span class="line">finalMappings = &#123;&#125;</span><br><span class="line"><span class="comment"># print(&quot;MARKERS&quot;, markers)</span></span><br><span class="line"><span class="comment"># breakpoint()</span></span><br><span class="line"><span class="keyword">for</span> index, boundary <span class="keyword">in</span> enumerate(unifiedBoundaryList):</span><br><span class="line">  previousMark = unifiedBoundaryMarks.get(index-1, [])</span><br><span class="line">  enterList = markers[<span class="string">&quot;enter&quot;</span>].get(boundary,[])</span><br><span class="line">  exitList = markers[<span class="string">&quot;exit&quot;</span>].get(boundary,[])</span><br><span class="line">  currentMark = <span class="built_in">set</span>(previousMark + enterList).difference(<span class="built_in">set</span>(exitList))</span><br><span class="line">  currentMark = list(currentMark)</span><br><span class="line">  unifiedBoundaryMarks.update(&#123;index:currentMark&#125;)</span><br><span class="line">  <span class="comment"># now, handle the change? or not?</span></span><br><span class="line">  <span class="comment"># let&#x27;s just deal those empty ones, shall we?</span></span><br><span class="line">  <span class="keyword">if</span> previousMark == []: <span class="comment"># inside it is empty range.</span></span><br><span class="line">  <span class="comment"># elif currentMark == []:</span></span><br><span class="line">    <span class="keyword">if</span> index == 0: <span class="built_in">continue</span> <span class="comment"># just the start, no need to note this down.</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      finalMappings.update(&#123;<span class="string">&quot;empty&quot;</span>:finalMappings.get(<span class="string">&quot;empty&quot;</span>,[])+[(unifiedBoundaryList[index-1], boundary)]&#125;)</span><br><span class="line">    <span class="comment"># the end of previous mark! this interval belongs to previousMark</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    key = previousMark.copy()</span><br><span class="line">    key.sort()</span><br><span class="line">    key = tuple(key)</span><br><span class="line">    finalMappings.update(&#123;key:finalMappings.get(key,[])+[(unifiedBoundaryList[index-1], boundary)]&#125;)</span><br><span class="line">    <span class="comment"># also the end of previous mark! belongs to previousMark.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### NOW THE FINAL OUTPUT ###</span></span><br><span class="line">finalCats = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> key, value <span class="keyword">in</span> finalMappings.items():</span><br><span class="line">  <span class="comment"># value is an array containing subInterval tuples.</span></span><br><span class="line">  value = mergeOverlappedInIntervalTupleList(value)</span><br><span class="line">  finalCats.update(&#123;key: value&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;______________FINAL CATS______________&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(finalCats)</span><br></pre></td></tr></table></figure>

<h3 id="sympy-solution"><a href="#sympy-solution" class="headerlink" title="sympy solution"></a>sympy solution</h3><p>sympy seems to provide support for discrete and continuous interval? will that save any damn time anyway? i’m afraid no? maybe there’s a way!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sympy</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unionToTupleList</span>(<span class="params">myUnion</span>):</span><br><span class="line">  <span class="comment">#  seriously wrong. this will fuck up.</span></span><br><span class="line">  unionBoundaries = <span class="built_in">list</span>(myUnion.boundary)</span><br><span class="line">  unionBoundaries.sort()</span><br><span class="line">  leftBoundaries = unionBoundaries[::<span class="number">2</span>]</span><br><span class="line">  rightBoundaries = unionBoundaries[<span class="number">1</span>::<span class="number">2</span>]</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(leftBoundaries, rightBoundaries))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tupleSetToUncertain</span>(<span class="params">mSet</span>):</span><br><span class="line">  mUncertain = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">for</span> start, end <span class="keyword">in</span> mSet:</span><br><span class="line">    <span class="keyword">if</span> mUncertain <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      mUncertain = sympy.Interval(start,end)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      mUncertain += sympy.Interval(start,end)</span><br><span class="line">  typeUncertain = <span class="built_in">type</span>(mUncertain)</span><br><span class="line">  <span class="keyword">return</span> mUncertain, typeUncertain</span><br><span class="line"></span><br><span class="line"><span class="comment"># borrowed from above code.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mergeOverlappedInIntervalTupleList</span>(<span class="params">intervalTupleList</span>):</span><br><span class="line">  mUncertain, _ = tupleSetToUncertain(intervalTupleList)</span><br><span class="line">  mUncertainBoundaryList = <span class="built_in">list</span>(mUncertain.boundary)</span><br><span class="line">  mUncertainBoundaryList.sort()</span><br><span class="line">  <span class="comment">#  print(mUncertain)</span></span><br><span class="line">  <span class="comment">#  print(mUncertainBoundaryList)</span></span><br><span class="line">  mergedIntervalTupleList = <span class="built_in">list</span>(<span class="built_in">zip</span>(mUncertainBoundaryList[::<span class="number">2</span>], mUncertainBoundaryList[<span class="number">1</span>::<span class="number">2</span>]))</span><br><span class="line">  <span class="comment"># print(mergedIntervalTupleList)</span></span><br><span class="line">  <span class="keyword">return</span> mergedIntervalTupleList</span><br><span class="line"></span><br><span class="line">mSet = [(<span class="number">0</span>,<span class="number">1</span>), (<span class="number">2</span>,<span class="number">3</span>)]</span><br><span class="line">mUncertain, typeUncertain = tupleSetToUncertain(mSet)</span><br><span class="line">unrolledMSet = <span class="built_in">list</span>(mUncertain.boundary)</span><br><span class="line"><span class="comment"># can be either sympy.sets.sets.Interval of sympy.sets.sets.Union</span></span><br><span class="line"></span><br><span class="line">mSet2 = [(<span class="number">0.5</span>,<span class="number">1.5</span>),(<span class="number">1.6</span>,<span class="number">2.5</span>)]</span><br><span class="line">mUncertain2, typeUncertain2 = tupleSetToUncertain(mSet2)</span><br><span class="line">unrolledMSet2 = <span class="built_in">list</span>(mUncertain2.boundary)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSET&quot;</span>, mSet)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSET2&quot;</span>, mSet2)</span><br><span class="line"></span><br><span class="line"><span class="comment">############################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hypothetical mSet2 and mUncertain2! please complete the hypothetical shit and make it runnable!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">checkCommon</span>(<span class="params">subInterval, masterInterval</span>):</span><br><span class="line">  <span class="keyword">return</span> subInterval == sympy.Intersection(subInterval, masterInterval)</span><br><span class="line"></span><br><span class="line">mUncertains = [mUncertain, mUncertain2]</span><br><span class="line">subIntervals = <span class="built_in">list</span>(<span class="built_in">set</span>(unrolledMSet2 + unrolledMSet))</span><br><span class="line">subIntervals.sort()</span><br><span class="line"></span><br><span class="line">subIntervals = <span class="built_in">zip</span>(subIntervals[:-<span class="number">1</span>], subIntervals[<span class="number">1</span>:])</span><br><span class="line">subIntervals = <span class="built_in">list</span>(subIntervals)</span><br><span class="line"><span class="comment">#  breakpoint()</span></span><br><span class="line"><span class="comment"># for subIntervals, it&#x27;s still not real interval but tuple at above line.</span></span><br><span class="line"></span><br><span class="line">reversedCats = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line">subIntervalUnion = functools.reduce(<span class="keyword">lambda</span> a,b: a+b, mUncertains)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> subIntervalIndex, (start, end) <span class="keyword">in</span> <span class="built_in">enumerate</span>(subIntervals):</span><br><span class="line">  subIntervalCandidate = sympy.Interval(start, end)</span><br><span class="line"></span><br><span class="line">  reverseIndex = [] <span class="comment"># there must be at least one such index.</span></span><br><span class="line">  <span class="keyword">for</span> index, uncertainCandidate <span class="keyword">in</span> <span class="built_in">enumerate</span>(mUncertains):</span><br><span class="line">    <span class="keyword">if</span> checkCommon(subIntervalCandidate, uncertainCandidate):</span><br><span class="line">      reverseIndex.append(index) <span class="comment"># this is the index of the in-common set of the original set list</span></span><br><span class="line">  reversedCats.update(&#123;subIntervalIndex:reverseIndex&#125;) <span class="comment"># need to sort and index? or not to sort because this is already done?</span></span><br><span class="line"></span><br><span class="line">normalCats = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> reversedCats.items():</span><br><span class="line">  v.sort()</span><br><span class="line">  v = <span class="built_in">tuple</span>(v)</span><br><span class="line">  normalCats.update(&#123;v:normalCats.get(v, [])+[k]&#125;)</span><br><span class="line"><span class="comment"># we only get interval, not the actural union period!</span></span><br><span class="line"><span class="comment"># how to get interval elements out of union structure for hell sake?</span></span><br><span class="line"></span><br><span class="line">finalCats = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> normalCats.items():</span><br><span class="line">  <span class="comment"># now k is the original set index list, representing belonging of the below union.</span></span><br><span class="line">  <span class="comment">#  print(subIntervals)</span></span><br><span class="line">  <span class="comment">#  print(index)</span></span><br><span class="line">  <span class="comment">#  print(v)</span></span><br><span class="line">  <span class="comment">#  breakpoint()</span></span><br><span class="line">  mFinalUnionCandidate = [subIntervals[index] <span class="keyword">for</span> index <span class="keyword">in</span> v]</span><br><span class="line"></span><br><span class="line">  <span class="comment">## REPLACED ##</span></span><br><span class="line">  <span class="comment"># mFinalUnionCandidate, _ = tupleSetToUncertain(mFinalUnionCandidate)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">##### union to tuple list, could be replaced #####</span></span><br><span class="line">  <span class="comment">#mFinalUnionCandidateBoundaryList = list(mFinalUnionCandidate.boundary)</span></span><br><span class="line">  <span class="comment">#left_bounds, right_bounds = mFinalUnionCandidateBoundaryList[0::2],mFinalUnionCandidateBoundaryList[1::2] # check it dammit! not sure how to step the list properly?</span></span><br><span class="line">  <span class="comment">#mFinalIntervalListCandidate = list(zip(left_bounds, right_bounds))</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># mFinalIntervalListCandidate = unionToTupleList(mFinalUnionCandidate)</span></span><br><span class="line">  <span class="comment">##### union to tuple list, could be replaced #####</span></span><br><span class="line">  <span class="comment">## REPLACED ##</span></span><br><span class="line">  <span class="comment"># print(&quot;M_FINAL_UNION_CANDIDATE&quot;,mFinalUnionCandidate)</span></span><br><span class="line"></span><br><span class="line">  mFinalIntervalListCandidate = mergeOverlappedInIntervalTupleList(mFinalUnionCandidate)</span><br><span class="line">  <span class="comment"># print(&quot;M_FINAL_INTERVAL_LIST_CANDIDATE&quot;, mFinalIntervalListCandidate)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># breakpoint()</span></span><br><span class="line">  finalCats.update(&#123;k:mFinalIntervalListCandidate.copy()&#125;)</span><br><span class="line"><span class="comment"># this whole calculation could just be exponential. goddamn it?</span></span><br><span class="line"><span class="comment"># before that, we need to get the &quot;empty&quot; out. but is that really necessary? i think it is, as an important feature.</span></span><br><span class="line"><span class="comment">#  subIntervalsStart, subIntervalsEnd = subIntervals[0][0], subIntervals[-1][-1]</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  relativeCompleteInterval = sympy.Interval(subIntervalsStart, subIntervalsEnd)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># subIntervalUnion</span></span><br><span class="line"><span class="comment">#  emptyIntervalUnion = relativeCompleteInterval - subIntervalUnion # really uncertain if it is just a union or not.</span></span><br><span class="line"><span class="comment">#  emptyIntervalTupleList = unionToTupleList(emptyIntervalUnion)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  finalCats.update(&#123;&quot;empty&quot;:emptyIntervalTupleList&#125;)</span></span><br><span class="line">finalCats.update(&#123;<span class="string">&quot;empty&quot;</span>:finalCats[()]&#125;)</span><br><span class="line"><span class="keyword">del</span> finalCats[()]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;_____FINAL CATS_____&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(finalCats)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/2023/12/22/f8398512-6f0b-433a-ad9f-89f730d636f4/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/" title="This article provides insights into accessing free proxies using tools like Clash, SSR, Proxy, ShadowSocks, V2Ray, and Fanqiang. It recommends searching GitHub for updated repositories and utilizing resources such as proxyscan.io, Telegram bots, self-hosted options, or cloud/CI alternatives. Additionally, Lantern is suggested to be used alongside Clash-ctl controllers.">free proxies: openit proxy pool has been seized, what to do</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="free-proxies-openit-proxy-pool-has-been-seized-what-to-do"><a href="#free-proxies-openit-proxy-pool-has-been-seized-what-to-do" class="headerlink" title="free proxies: openit proxy pool has been seized, what to do"></a>free proxies: openit proxy pool has been seized, what to do</h1><p>there are some code in his repo about scraping proxies. running this on kaggle or github ci providers.</p>
<p>on github search for “clash” “ssr” “proxy” “shadowsocks” “v2ray” “fanqiang” or some keywords obvious to you then sort by “recently updated” since available proxy pool will be constantly updated.</p>
<p>or you could use lantern.</p>
<h2 id="sources"><a href="#sources" class="headerlink" title="sources"></a>sources</h2><h3 id="proxyscan-io"><a href="#proxyscan-io" class="headerlink" title="proxyscan.io"></a><a target="_blank" rel="noopener" href="https://www.proxyscan.io/api">proxyscan.io</a></h3><p>referred by <a target="_blank" rel="noopener" href="https://github.com/ShiftyTR/Proxy-List">Proxy-List</a></p>
<h3 id="telegram-bots"><a href="#telegram-bots" class="headerlink" title="telegram bots"></a>telegram bots</h3><p><a target="_blank" rel="noopener" href="https://t.me/HQPROX">high quality proxy (channel)</a></p>
<p><a target="_blank" rel="noopener" href="https://t.me/socks5_bot">socks5 bot</a></p>
<h3 id="self-hosted-or-cloud-CI-based"><a href="#self-hosted-or-cloud-CI-based" class="headerlink" title="self-hosted or cloud&#x2F;CI based"></a>self-hosted or cloud&#x2F;CI based</h3><p><a target="_blank" rel="noopener" href="https://github.com/fate0/proxylist">proxylist</a> by fate0 (ceased contribution for long) has stopped working since broken github action settings, though <a target="_blank" rel="noopener" href="https://github.com/fate0/getproxy">getproxy</a> still works (collecting unchecked proxies via travis-ci). i think clash can handle that automatically though.</p>
<h2 id="tools"><a href="#tools" class="headerlink" title="tools"></a>tools</h2><h3 id="controllers"><a href="#controllers" class="headerlink" title="controllers"></a>controllers</h3><p><a target="_blank" rel="noopener" href="https://github.com/Dreamacro/clash-ctl">clash-ctl</a> control clash from commandline</p>
<p><a target="_blank" rel="noopener" href="https://github.com/George-Miao/clashctl">clashctl</a> clash controller in rust, with tui and commandline interface</p>
<h3 id="link-converters"><a href="#link-converters" class="headerlink" title="link converters"></a>link converters</h3><p><a target="_blank" rel="noopener" href="https://subconverter.speedupvpn.com/">机场订阅转换器-V2ray,Clash,SSR,SS等订阅链接在线转换</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tindy2013/subconverter">subconverter</a> self-hosted utility to convert between various subscription format</p>
<h3 id="scrapers"><a href="#scrapers" class="headerlink" title="scrapers"></a>scrapers</h3><p><a target="_blank" rel="noopener" href="https://github.com/yu-steven/proxypool">proxypool</a></p>
<h3 id="routing-rules"><a href="#routing-rules" class="headerlink" title="routing rules"></a>routing rules</h3><p><a target="_blank" rel="noopener" href="https://github.com/Goojoe/clash_rules">clash_rules</a></p>
<h2 id="providers"><a href="#providers" class="headerlink" title="providers"></a>providers</h2><h3 id="subscription-links"><a href="#subscription-links" class="headerlink" title="subscription links"></a>subscription links</h3><p><a target="_blank" rel="noopener" href="https://github.com/zevtyardt/proxy-list">proxy-list</a> 20000+</p>
<p><a target="_blank" rel="noopener" href="https://github.com/freefq/free">freefq</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/4ooc/clash_sync">clash_sync&#x2F;clash_auto</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/mahdibland/ShadowsocksAggregator">ShadowsocksAggregator</a> use its <code>Eternity.yml</code> in clash. it also has many sources avaliable for check in <code>README.md</code></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tbbatbb/Proxy">Proxy</a> update hourly</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Pawdroid/Free-servers">free-servers</a> v2ray subscription</p>
<p><a target="_blank" rel="noopener" href="https://github.com/learnhard-cn/free_proxy_ss">free-proxy-ss</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/anaer/Sub">Sub</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/openRunner/clash-freenode">clash-freenode</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/aiboboxx/clashfree">clashfree</a></p>
<h3 id="clients"><a href="#clients" class="headerlink" title="clients"></a>clients</h3><p><a target="_blank" rel="noopener" href="https://github.com/YoulianBoshi/lantern-vpn/blob/master/Windows%E7%81%AF_%E6%97%A0%E9%99%90%E6%B5%81%E9%87%8F%E6%9B%B4%E6%96%B0">crack lantern win 6.8.8</a></p>
<p><a target="_blank" rel="noopener" href="https://ylbs.lanzoui.com/i4rlLtxl2hc">lantern win 6.8.5</a></p>
<p><a target="_blank" rel="noopener" href="https://ylbs.lanzoui.com/b0066e7mb">a bunch of cracked clients</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/getlantern/lantern/releases/tag/6.8.7">lantern 6.8.7</a></p>

	
	</div>
  <a type="button" href="/2023/12/22/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f8de6157-4e2e-49e7-8d1b-8860e4e8184a/" title="This article explains how to connect a HarmonyOS device&#39;s logs to MySQL, providing the necessary login credentials and log file structure. It also provides guidance on decompressing .gz files and understanding their format for analysis.">HarmonyOS Device Log to MySQL</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="HarmonyOS-Device-Log-to-MySQL"><a href="#HarmonyOS-Device-Log-to-MySQL" class="headerlink" title="HarmonyOS Device Log to MySQL"></a>HarmonyOS Device Log to MySQL</h1><p>mysql path:<br>jdbc:mysql:&#x2F;&#x2F;10.33.163.33:3306&#x2F;HTS_DB?characterEncoding&#x3D;UTF-8<br>root<br>pipeline@123</p>
<p>Logs Path:<br>&#x2F;data&#x2F;data&#x2F;Local&#x2F;DeviceTest&#x2F;20220406163617_hts_project&#x2F;resources&#x2F;HTS&#x2F;android-hts&#x2F;logs</p>
<p>under logs:<br>%Y.%m.%d_%H.%M.%S_<serial_number><br>select the latest folder</p>
<p>under selected folder:<br>device_logcat_test_<serial_number>_<unknownInteger>.txt.gz</p>
<p>decompress using: (before that os.chdir to the selected folder)<br>gzip -d <file></p>
<p>does the decompression remove the .gz file?<br>it will.</p>
<p>log format per line:<br>DfxTestLog: A1<testName>_<testName2_contain_test_serial>_DfxTestTime &#x3D; <value> datai&#x3D;4</p>
<p>from 1 to 13:<br>A1test1..4<br>A2test5<br>A3test1..2<br>B1test1<br>B2test4..6<br>D1test1<br>M1test1</p>
<p>Tables:</p>
<p>Performance_Baseline_Info<br>testValue date(%Y-%m-%d) hmsVersion(HMSCore660319) baselineId_id deviceId_id(1,2,4,3,5) deviceType(phone&lt;-1|wearable&lt;-2|car&lt;-4|tv&lt;-3|ecodevice&lt;-5)</p>
<p>Performance_Daily_Data<br>id features indicators baseValue</p>
<p>Performance_Device_Info<br>id(to the deviceId_id) model type sn cpu</p>

	
	</div>
  <a type="button" href="/2023/12/22/f8de6157-4e2e-49e7-8d1b-8860e4e8184a/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2023-12-22 </div>
			<div class="article-title"><a href="/2023/12/22/f91372e4-2505-4cab-baa7-3242a0c10d5f/" title="This article delves into RSS feed sources and customizable aggregators, recommending the use of social media for content dissemination. It further explores Python RSS libraries and a JavaScript readability library for image and fingerprint handling. Installation instructions using npm and pip are provided for Node.js and Python.">RSS Feeds</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="RSS-Feeds"><a href="#RSS-Feeds" class="headerlink" title="RSS Feeds"></a>RSS Feeds</h1><p><a target="_blank" rel="noopener" href="https://www.kuxai.com/">kuxai</a> ai related articles, there’s some bot keep posting this shit to qq group</p>
<p><a target="_blank" rel="noopener" href="https://github.com/DIYgod/RSSHub">rsshub</a> most extensible rss feeder, can turn bilibili, zhihu, or anything into rss</p>
<p>medium.com</p>
<p>Searching for existing rss sources. You may want to make your own by means of social media. It could be the feeding source of reviewer or producer.</p>
<p><a target="_blank" rel="noopener" href="https://www.baidu.com/ssid=4d994e69636f5f4e69636f6c6532353311dd/from=844b/s?word=rss%E8%AE%A2%E9%98%85%E6%BA%90&ts=7538593&t_kt=0&ie=utf-8&fm_kl=021394be2f&rsv_iqid=4109465110&rsv_t=a02fgTXA5yrpeGBRWrTCqcc9bK%252FKmzIRzII6usvAqgJjawViUjevc88MAg&sa=is_5&ms=1&rsv_pq=4109465110&rsv_sug4=6166&tj=1&ss=110&inputT=3395&sugid=110161509475552&rq=rss">https://www.baidu.com/ssid=4d994e69636f5f4e69636f6c6532353311dd/from=844b/s?word=rss订阅源&amp;ts=7538593&amp;t_kt=0&amp;ie=utf-8&amp;fm_kl=021394be2f&amp;rsv_iqid=4109465110&amp;rsv_t=a02fgTXA5yrpeGBRWrTCqcc9bK%252FKmzIRzII6usvAqgJjawViUjevc88MAg&amp;sa=is_5&amp;ms=1&amp;rsv_pq=4109465110&amp;rsv_sug4=6166&amp;tj=1&amp;ss=110&amp;inputT=3395&amp;sugid=110161509475552&amp;rq=rss</a><br><a target="_blank" rel="noopener" href="https://www.appstoredate.com/iphone/6990.html">https://www.appstoredate.com/iphone/6990.html</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/wangjialiang/article/details/121510405">https://blog.csdn.net/wangjialiang/article/details/121510405</a><br><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1677152782752706400&wfr=spider&for=pc&searchword=rss%E8%AE%A2%E9%98%85%E6%BA%90">https://baijiahao.baidu.com/s?id=1677152782752706400&amp;wfr=spider&amp;for=pc&amp;searchword=rss订阅源</a><br><a target="_blank" rel="noopener" href="https://www.bilibili.com/read/mobile?id=8961024">https://www.bilibili.com/read/mobile?id=8961024</a><br><a target="_blank" rel="noopener" href="https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=rss%E6%BA%90%E5%9C%B0%E5%9D%80%E8%AE%A2%E9%98%85%E5%A4%A7%E5%85%A8&sa=brs_7&rq=rss%E8%AE%A2%E9%98%85%E6%BA%90&rsf=100631857&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san">https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=rss源地址订阅大全&amp;sa=brs_7&amp;rq=rss订阅源&amp;rsf=100631857&amp;pqid=8915434938561485118&amp;ms=1&amp;rqid=8915434938561485118&amp;params_ssrt=node-san</a><br><a target="_blank" rel="noopener" href="https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=%E8%AE%A2%E9%98%85%E6%BA%90%E6%95%B4%E5%90%88&sa=brs_6&rq=rss%E8%AE%A2%E9%98%85%E6%BA%90&rsf=100631112&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san">https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=订阅源整合&amp;sa=brs_6&amp;rq=rss订阅源&amp;rsf=100631112&amp;pqid=8915434938561485118&amp;ms=1&amp;rqid=8915434938561485118&amp;params_ssrt=node-san</a><br><a target="_blank" rel="noopener" href="https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=%E7%9F%A5%E4%B9%8E%E6%97%A5%E6%8A%A5rss%E6%BA%90&sa=brs_4&rq=rss%E8%AE%A2%E9%98%85%E6%BA%90&rsf=100631113&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san">https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=知乎日报rss源&amp;sa=brs_4&amp;rq=rss订阅源&amp;rsf=100631113&amp;pqid=8915434938561485118&amp;ms=1&amp;rqid=8915434938561485118&amp;params_ssrt=node-san</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/25071126/answer/875901493">https://www.zhihu.com/question/25071126/answer/875901493</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53989966">https://zhuanlan.zhihu.com/p/53989966</a><br><a target="_blank" rel="noopener" href="https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=%E5%90%84%E5%A4%A7%E7%BD%91%E7%AB%99RSS%E8%AE%A2%E9%98%85%E6%BA%90%E5%9C%B0%E5%9D%80&sa=re_dl_prs_34689_1&rqid=10035302357898163828&params_ssrt=node-san&rq=%E7%9F%A5%E4%B9%8E%E6%97%A5%E6%8A%A5rss%E6%BA%90&rsf=100631113&asctag=2470">https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=各大网站RSS订阅源地址&amp;sa=re_dl_prs_34689_1&amp;rqid=10035302357898163828&amp;params_ssrt=node-san&amp;rq=知乎日报rss源&amp;rsf=100631113&amp;asctag=2470</a><br><a target="_blank" rel="noopener" href="https://www.tutorialspoint.com/python_text_processing/python_reading_rss_feed.htm">https://www.tutorialspoint.com/python_text_processing/python_reading_rss_feed.htm</a><br><a target="_blank" rel="noopener" href="https://www.datasciencelearner.com/how-to-read-rss-feed-in-python/">https://www.datasciencelearner.com/how-to-read-rss-feed-in-python/</a><br><a target="_blank" rel="noopener" href="https://wiki.python.org/moin/RssLibraries">https://wiki.python.org/moin/RssLibraries</a><br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/2244836/rss-feed-parser-library-in-python">https://stackoverflow.com/questions/2244836/rss-feed-parser-library-in-python</a><br><a target="_blank" rel="noopener" href="https://pypi.org/project/rss-reader/">https://pypi.org/project/rss-reader/</a><br><a target="_blank" rel="noopener" href="https://github.com/lemon24/reader">https://github.com/lemon24/reader</a><br><a target="_blank" rel="noopener" href="https://reader.readthedocs.io/en/latest/">https://reader.readthedocs.io/en/latest/</a></p>
<p>we need cleaner view by using readbility.js, but how to preserve pictures? is it built-in?</p>
<p>pictures could be a big fingerprint. better deal them with link extracter and shufflers.</p>
<p>you want python version or nodejs version?</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install @mozilla/readability</span><br><span class="line"><span class="comment"># it can be invoked via api, standalone!</span></span><br><span class="line"><span class="comment"># you might want to call javascript from python</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip3 install readability-lxml</span><br><span class="line"><span class="comment"># some lags behind?</span></span><br></pre></td></tr></table></figure>

<p>this is for the reader mode, make webpage readable</p>
<p><a target="_blank" rel="noopener" href="https://github.com/luin/readability">https://github.com/luin/readability</a><br><a target="_blank" rel="noopener" href="https://github.com/phpdocker-io/readability-js-server">https://github.com/phpdocker-io/readability-js-server</a><br><a target="_blank" rel="noopener" href="https://github.com/mozilla/readability">https://github.com/mozilla/readability</a><br><a target="_blank" rel="noopener" href="https://github.com/alan-turing-institute/ReadabiliPy">https://github.com/alan-turing-institute/ReadabiliPy</a><br><a target="_blank" rel="noopener" href="https://github.com/edgartaor/kindleServer">https://github.com/edgartaor/kindleServer</a><br><a target="_blank" rel="noopener" href="https://requests-html.kennethreitz.org/">https://requests-html.kennethreitz.org</a><br><a target="_blank" rel="noopener" href="https://github.com/psf/requests-html">https://github.com/psf/requests-html</a><br><a target="_blank" rel="noopener" href="https://github.com/MHordecki/readability-redux/blob/master/readability/readability.js">https://github.com/MHordecki/readability-redux/blob/master/readability/readability.js</a><br><a target="_blank" rel="noopener" href="https://github.com/buriy/python-readability">https://github.com/buriy/python-readability</a><br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/56857506/how-to-enable-reader-mode-distill-page-with-puppeteer">https://stackoverflow.com/questions/56857506/how-to-enable-reader-mode-distill-page-with-puppeteer</a></p>

	
	</div>
  <a type="button" href="/2023/12/22/f91372e4-2505-4cab-baa7-3242a0c10d5f/#more" class="btn btn-default more">Read More</a>
</div>

           
		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">
<ul class="pagination">
	 
		
		<li class="prev"><a href="/page/103/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i> Prev</a></li>
  		

        <li><a href="/"><i class="fa fa-home"></i>Home</a></li>

		
		   <li class="next"> <a href="/page/105/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a> </li>
        
	
</ul>
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			<div class="widget">
    
	    <h4 class="dsq-widget-title">Recent Comments</h4>
		<div id="recent-comments"></div>
		<script type="text/javascript">
		    getRecentCommentsList({
			   type: "github" ? "github" : "github",
			   user: "james4ever0",
               repo: "my_blog",
               client_id: "",
               client_secret: "",
			   count: "5" ? "5" : 5,
			   recent_comments_target: "#recent-comments"
			});
		</script>
	
</div>

		
			
	<div class="widget">
		<h4>Categories</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/categories/2D-Animation/">2D Animation<span>2</span></a></li>
		
			<li><a href="/categories/3D-Avatar-Creation/">3D Avatar Creation<span>2</span></a></li>
		
			<li><a href="/categories/3D-Modeling/">3D Modeling<span>4</span></a></li>
		
			<li><a href="/categories/3D-Rendering/">3D Rendering<span>2</span></a></li>
		
			<li><a href="/categories/AI/">AI<span>14</span></a></li>
		
			<li><a href="/categories/AI-Accelerators/">AI Accelerators<span>2</span></a></li>
		
			<li><a href="/categories/AI-Competitions/">AI Competitions<span>2</span></a></li>
		
			<li><a href="/categories/AI-Libraries/">AI Libraries<span>2</span></a></li>
		
			<li><a href="/categories/AI-Optimization/">AI Optimization<span>2</span></a></li>
		
			<li><a href="/categories/AI-System-Design-Guidelines/">AI System Design Guidelines<span>2</span></a></li>
		
			<li><a href="/categories/AI-Techniques-for-Text-Generation-and-Paraphrasing/">AI Techniques for Text Generation and Paraphrasing<span>2</span></a></li>
		
			<li><a href="/categories/AI-Video-Generation/">AI Video Generation<span>2</span></a></li>
		
			<li><a href="/categories/AI-development/">AI development<span>4</span></a></li>
		
			<li><a href="/categories/AI-tools-collections/">AI tools collections<span>2</span></a></li>
		
			<li><a href="/categories/AI-Generated-Singing-Voices/">AI-Generated Singing Voices<span>2</span></a></li>
		
			<li><a href="/categories/AI-generated-Art/">AI-generated Art<span>2</span></a></li>
		
			<li><a href="/categories/API/">API<span>10</span></a></li>
		
			<li><a href="/categories/API-Development/">API Development<span>2</span></a></li>
		
			<li><a href="/categories/API-Scraping/">API Scraping<span>2</span></a></li>
		
			<li><a href="/categories/APIs/">APIs<span>4</span></a></li>
		
			<li><a href="/categories/Academic-Articles/">Academic Articles<span>2</span></a></li>
		
			<li><a href="/categories/Accessibility-tools/">Accessibility tools<span>2</span></a></li>
		
			<li><a href="/categories/Account-Disabling/">Account Disabling<span>1</span></a></li>
		
			<li><a href="/categories/Account-Management/">Account Management<span>2</span></a></li>
		
			<li><a href="/categories/Account-Registration/">Account Registration<span>2</span></a></li>
		
			<li><a href="/categories/Advanced-AI-powered-video-editors/">Advanced AI-powered video editors<span>2</span></a></li>
		
			<li><a href="/categories/Android/">Android<span>2</span></a></li>
		
			<li><a href="/categories/Android-Development/">Android Development<span>4</span></a></li>
		
			<li><a href="/categories/Android-Reverse-Engineering/">Android Reverse Engineering<span>2</span></a></li>
		
			<li><a href="/categories/Android-Security/">Android Security<span>2</span></a></li>
		
			<li><a href="/categories/Android-automation/">Android automation<span>2</span></a></li>
		
			<li><a href="/categories/Android-emulators/">Android emulators<span>2</span></a></li>
		
			<li><a href="/categories/Animation-Tools/">Animation Tools<span>4</span></a></li>
		
			<li><a href="/categories/Anime/">Anime<span>4</span></a></li>
		
			<li><a href="/categories/Anime-Video-Downloads/">Anime Video Downloads<span>2</span></a></li>
		
			<li><a href="/categories/Annotation-Tools/">Annotation Tools<span>1</span></a></li>
		
			<li><a href="/categories/App-Compatibility/">App Compatibility<span>2</span></a></li>
		
			<li><a href="/categories/Artificial-General-Intelligence/">Artificial General Intelligence<span>2</span></a></li>
		
			<li><a href="/categories/Artificial-Intelligence/">Artificial Intelligence<span>32</span></a></li>
		
			<li><a href="/categories/Asynchronous-Requests/">Asynchronous Requests<span>2</span></a></li>
		
			<li><a href="/categories/Audio-Processing/">Audio Processing<span>8</span></a></li>
		
			<li><a href="/categories/Audio-Production/">Audio Production<span>2</span></a></li>
		
			<li><a href="/categories/Audio-Recognition/">Audio Recognition<span>2</span></a></li>
		
			<li><a href="/categories/Augmented-Reality/">Augmented Reality<span>2</span></a></li>
		
			<li><a href="/categories/Automated-Essay-Scoring/">Automated Essay Scoring<span>2</span></a></li>
		
			<li><a href="/categories/Automation/">Automation<span>2</span></a></li>
		
			<li><a href="/categories/Automotive-Computer-Research/">Automotive Computer Research<span>2</span></a></li>
		
			<li><a href="/categories/Backup-software/">Backup software<span>2</span></a></li>
		
			<li><a href="/categories/Battery-Damage-Prevention/">Battery Damage Prevention<span>2</span></a></li>
		
			<li><a href="/categories/Behavior-Driven-Development/">Behavior Driven Development<span>2</span></a></li>
		
			<li><a href="/categories/Best-Earphones/">Best Earphones<span>2</span></a></li>
		
			<li><a href="/categories/Bilibili/">Bilibili<span>4</span></a></li>
		
			<li><a href="/categories/Biology/">Biology<span>2</span></a></li>
		
			<li><a href="/categories/Bot-Development/">Bot Development<span>2</span></a></li>
		
			<li><a href="/categories/Browser-Extensions/">Browser Extensions<span>4</span></a></li>
		
			<li><a href="/categories/CACANi-Software/">CACANi Software<span>2</span></a></li>
		
			<li><a href="/categories/CITIC-Security-Account/">CITIC Security Account<span>1</span></a></li>
		
			<li><a href="/categories/Captcha-recognition/">Captcha recognition<span>2</span></a></li>
		
			<li><a href="/categories/Cheminformatics/">Cheminformatics<span>2</span></a></li>
		
			<li><a href="/categories/Chinese-Input-Methods/">Chinese Input Methods<span>2</span></a></li>
		
			<li><a href="/categories/Chocolatey/">Chocolatey<span>2</span></a></li>
		
			<li><a href="/categories/Chromium-Policies/">Chromium Policies<span>2</span></a></li>
		
			<li><a href="/categories/Clash-GitHub-Fastgithub-DNS-settings-macOS-Linux-monit-shell-scripts/">Clash, GitHub, Fastgithub, DNS settings, macOS, Linux, monit, shell scripts<span>2</span></a></li>
		
			<li><a href="/categories/Clipboard-issue-in-Android-10/">Clipboard issue in Android 10<span>2</span></a></li>
		
			<li><a href="/categories/Code-Auditing/">Code Auditing<span>2</span></a></li>
		
			<li><a href="/categories/Code-Refactoring/">Code Refactoring<span>2</span></a></li>
		
			<li><a href="/categories/Collaborative-Programming/">Collaborative Programming<span>2</span></a></li>
		
			<li><a href="/categories/Color-Palette-Extraction/">Color Palette Extraction<span>2</span></a></li>
		
			<li><a href="/categories/Colorization/">Colorization<span>1</span></a></li>
		
			<li><a href="/categories/Command-line-Tools/">Command-line Tools<span>2</span></a></li>
		
			<li><a href="/categories/Community-Detection/">Community Detection<span>2</span></a></li>
		
			<li><a href="/categories/Computer-Vision/">Computer Vision<span>6</span></a></li>
		
			<li><a href="/categories/Content-Creation/">Content Creation<span>8</span></a></li>
		
			<li><a href="/categories/Content-Promotion/">Content Promotion<span>2</span></a></li>
		
			<li><a href="/categories/Copying-and-Moving-Files/">Copying and Moving Files<span>2</span></a></li>
		
			<li><a href="/categories/Cross-Platform-Apps/">Cross-Platform Apps<span>2</span></a></li>
		
			<li><a href="/categories/Cross-Platform-Publishing/">Cross-Platform Publishing<span>2</span></a></li>
		
			<li><a href="/categories/Cybergod-Projects/">Cybergod Projects<span>2</span></a></li>
		
			<li><a href="/categories/Cybersecurity/">Cybersecurity<span>10</span></a></li>
		
			<li><a href="/categories/DNS-proxies/">DNS proxies<span>2</span></a></li>
		
			<li><a href="/categories/DWG-to-DXF-conversion/">DWG to DXF conversion<span>2</span></a></li>
		
			<li><a href="/categories/Dark-Web/">Dark Web<span>2</span></a></li>
		
			<li><a href="/categories/Data-Annotation-Tools/">Data Annotation Tools<span>4</span></a></li>
		
			<li><a href="/categories/Data-Backup/">Data Backup<span>4</span></a></li>
		
			<li><a href="/categories/Data-Capture/">Data Capture<span>4</span></a></li>
		
			<li><a href="/categories/Data-Scraping/">Data Scraping<span>2</span></a></li>
		
			<li><a href="/categories/Data-Security/">Data Security<span>2</span></a></li>
		
			<li><a href="/categories/Database/">Database<span>2</span></a></li>
		
			<li><a href="/categories/Database-Management/">Database Management<span>4</span></a></li>
		
			<li><a href="/categories/Deep-Learning/">Deep Learning<span>4</span></a></li>
		
			<li><a href="/categories/Digital-Identity/">Digital Identity<span>2</span></a></li>
		
			<li><a href="/categories/Digital-Marketing/">Digital Marketing<span>2</span></a></li>
		
			<li><a href="/categories/Discord-Channels/">Discord Channels<span>2</span></a></li>
		
			<li><a href="/categories/Disk-Management/">Disk Management<span>4</span></a></li>
		
			<li><a href="/categories/Docker/">Docker<span>6</span></a></li>
		
			<li><a href="/categories/Domain-specific-languages-DSL/">Domain-specific languages (DSL)<span>2</span></a></li>
		
			<li><a href="/categories/Drivers-updates/">Drivers updates<span>2</span></a></li>
		
			<li><a href="/categories/Dynamic-Classification-Systems/">Dynamic Classification Systems<span>2</span></a></li>
		
			<li><a href="/categories/E-book-conversion/">E-book conversion<span>2</span></a></li>
		
			<li><a href="/categories/Education/">Education<span>7</span></a></li>
		
			<li><a href="/categories/Emotion-Manipulation/">Emotion Manipulation<span>2</span></a></li>
		
			<li><a href="/categories/Energy-System-Simulation/">Energy System Simulation<span>2</span></a></li>
		
			<li><a href="/categories/Ergonomics/">Ergonomics<span>2</span></a></li>
		
			<li><a href="/categories/Error-Resolution/">Error Resolution<span>2</span></a></li>
		
			<li><a href="/categories/Evolution/">Evolution<span>2</span></a></li>
		
			<li><a href="/categories/Exception-Handling/">Exception Handling<span>2</span></a></li>
		
			<li><a href="/categories/Expect-Send/">Expect Send<span>2</span></a></li>
		
			<li><a href="/categories/Extensions/">Extensions<span>2</span></a></li>
		
			<li><a href="/categories/Facial-Expression-Detection/">Facial Expression Detection<span>2</span></a></li>
		
			<li><a href="/categories/Fake-Content-Detection/">Fake Content Detection<span>2</span></a></li>
		
			<li><a href="/categories/FastAPI/">FastAPI<span>2</span></a></li>
		
			<li><a href="/categories/File-Hosting-Services/">File Hosting Services<span>2</span></a></li>
		
			<li><a href="/categories/File-Transfer/">File Transfer<span>3</span></a></li>
		
			<li><a href="/categories/Filesystem-Cache/">Filesystem Cache<span>2</span></a></li>
		
			<li><a href="/categories/GUI-Programming/">GUI Programming<span>2</span></a></li>
		
			<li><a href="/categories/Generative-Adversarial-Networks-GAN/">Generative Adversarial Networks (GAN)<span>2</span></a></li>
		
			<li><a href="/categories/Generative-Adversarial-Networks-GANs/">Generative Adversarial Networks (GANs)<span>2</span></a></li>
		
			<li><a href="/categories/Geometry/">Geometry<span>2</span></a></li>
		
			<li><a href="/categories/GitFS/">GitFS<span>2</span></a></li>
		
			<li><a href="/categories/GitHub/">GitHub<span>6</span></a></li>
		
			<li><a href="/categories/Graph-Databases/">Graph Databases<span>1</span></a></li>
		
			<li><a href="/categories/Hacking/">Hacking<span>6</span></a></li>
		
			<li><a href="/categories/Hacking-Tutorials/">Hacking Tutorials<span>2</span></a></li>
		
			<li><a href="/categories/Hacking-techniques/">Hacking techniques<span>2</span></a></li>
		
			<li><a href="/categories/Health/">Health<span>4</span></a></li>
		
			<li><a href="/categories/Home-Appliances/">Home Appliances<span>2</span></a></li>
		
			<li><a href="/categories/Hot-Reloading/">Hot Reloading<span>2</span></a></li>
		
			<li><a href="/categories/Huggingface/">Huggingface<span>2</span></a></li>
		
			<li><a href="/categories/Human-in-the-Loop-AI/">Human-in-the-Loop AI<span>2</span></a></li>
		
			<li><a href="/categories/Image-Classification/">Image Classification<span>2</span></a></li>
		
			<li><a href="/categories/Image-Generation/">Image Generation<span>2</span></a></li>
		
			<li><a href="/categories/Image-Processing/">Image Processing<span>10</span></a></li>
		
			<li><a href="/categories/Image-Search-Tools/">Image Search Tools<span>2</span></a></li>
		
			<li><a href="/categories/Image-restoration/">Image restoration<span>2</span></a></li>
		
			<li><a href="/categories/Information-Management/">Information Management<span>2</span></a></li>
		
			<li><a href="/categories/Installation/">Installation<span>4</span></a></li>
		
			<li><a href="/categories/Installation-Instructions/">Installation Instructions<span>2</span></a></li>
		
			<li><a href="/categories/Interactive-Interfaces/">Interactive Interfaces<span>2</span></a></li>
		
			<li><a href="/categories/Interpolation-Techniques/">Interpolation Techniques<span>2</span></a></li>
		
			<li><a href="/categories/Interval-set-manipulation/">Interval set manipulation<span>2</span></a></li>
		
			<li><a href="/categories/IoT/">IoT<span>2</span></a></li>
		
			<li><a href="/categories/JavaScript/">JavaScript<span>4</span></a></li>
		
			<li><a href="/categories/Kafka-System-Design/">Kafka System Design<span>2</span></a></li>
		
			<li><a href="/categories/Kali-Linux/">Kali Linux<span>4</span></a></li>
		
			<li><a href="/categories/Karaoke/">Karaoke<span>2</span></a></li>
		
			<li><a href="/categories/Keyboard-Shortcuts/">Keyboard Shortcuts<span>2</span></a></li>
		
			<li><a href="/categories/Kotlin-ORM-libraries/">Kotlin ORM libraries<span>2</span></a></li>
		
			<li><a href="/categories/Kotlin-Spring-Boot/">Kotlin Spring Boot<span>2</span></a></li>
		
			<li><a href="/categories/Library-Management/">Library Management<span>2</span></a></li>
		
			<li><a href="/categories/Linux/">Linux<span>12</span></a></li>
		
			<li><a href="/categories/Live-Streaming/">Live Streaming<span>4</span></a></li>
		
			<li><a href="/categories/Live-broadcasting/">Live broadcasting<span>2</span></a></li>
		
			<li><a href="/categories/Logo-Finders/">Logo Finders<span>2</span></a></li>
		
			<li><a href="/categories/Lua-Python-Bridge/">Lua Python Bridge<span>2</span></a></li>
		
			<li><a href="/categories/MIDI-Conversion-Tools/">MIDI Conversion Tools<span>2</span></a></li>
		
			<li><a href="/categories/Machine-Learning/">Machine Learning<span>16</span></a></li>
		
			<li><a href="/categories/Man-in-the-middle-proxy/">Man-in-the-middle proxy<span>2</span></a></li>
		
			<li><a href="/categories/Manga/">Manga<span>4</span></a></li>
		
			<li><a href="/categories/Markdown-to-PDF-Conversion/">Markdown to PDF Conversion<span>2</span></a></li>
		
			<li><a href="/categories/Mass-Email-SMS-Tools/">Mass Email/SMS Tools<span>2</span></a></li>
		
			<li><a href="/categories/Mathematica/">Mathematica<span>2</span></a></li>
		
			<li><a href="/categories/Mathematica-software/">Mathematica software<span>2</span></a></li>
		
			<li><a href="/categories/Mathematics/">Mathematics<span>4</span></a></li>
		
			<li><a href="/categories/Media-Filtering/">Media Filtering<span>2</span></a></li>
		
			<li><a href="/categories/Media-repurposing-tools/">Media repurposing tools<span>2</span></a></li>
		
			<li><a href="/categories/Memory-Errors/">Memory Errors<span>1</span></a></li>
		
			<li><a href="/categories/Meta-Search-Engines/">Meta Search Engines<span>2</span></a></li>
		
			<li><a href="/categories/Metasploit-Python-scripting/">Metasploit Python scripting<span>2</span></a></li>
		
			<li><a href="/categories/Mini-ITX-Computers/">Mini-ITX Computers<span>2</span></a></li>
		
			<li><a href="/categories/Mitmproxy-tool/">Mitmproxy tool<span>2</span></a></li>
		
			<li><a href="/categories/Mobile/">Mobile<span>1</span></a></li>
		
			<li><a href="/categories/Mobile-App-Development/">Mobile App Development<span>2</span></a></li>
		
			<li><a href="/categories/Mobile-Phones/">Mobile Phones<span>2</span></a></li>
		
			<li><a href="/categories/Model-Optimization/">Model Optimization<span>2</span></a></li>
		
			<li><a href="/categories/Model-Uploading/">Model Uploading<span>2</span></a></li>
		
			<li><a href="/categories/Model-zoos/">Model zoos<span>2</span></a></li>
		
			<li><a href="/categories/Molecular-dynamics-simulations/">Molecular dynamics simulations<span>2</span></a></li>
		
			<li><a href="/categories/Movies/">Movies<span>2</span></a></li>
		
			<li><a href="/categories/Music/">Music<span>2</span></a></li>
		
			<li><a href="/categories/Music-Discovery/">Music Discovery<span>2</span></a></li>
		
			<li><a href="/categories/Music-Generation/">Music Generation<span>2</span></a></li>
		
			<li><a href="/categories/Music-Platforms/">Music Platforms<span>2</span></a></li>
		
			<li><a href="/categories/Music-Production/">Music Production<span>2</span></a></li>
		
			<li><a href="/categories/NAS/">NAS<span>2</span></a></li>
		
			<li><a href="/categories/NLP-Frameworks/">NLP Frameworks<span>2</span></a></li>
		
			<li><a href="/categories/NLP-Tools/">NLP Tools<span>2</span></a></li>
		
			<li><a href="/categories/NTFS-Recovery-Tools/">NTFS Recovery Tools<span>2</span></a></li>
		
			<li><a href="/categories/NVIDIA-drivers/">NVIDIA drivers<span>2</span></a></li>
		
			<li><a href="/categories/Natural-Language-Generation/">Natural Language Generation<span>2</span></a></li>
		
			<li><a href="/categories/Natural-Language-Processing/">Natural Language Processing<span>12</span></a></li>
		
			<li><a href="/categories/Neo4j/">Neo4j<span>2</span></a></li>
		
			<li><a href="/categories/Neo4j-Cypher-Cheatsheet/">Neo4j Cypher Cheatsheet<span>2</span></a></li>
		
			<li><a href="/categories/Neo4j-Graph-Data-Science/">Neo4j Graph Data Science<span>2</span></a></li>
		
			<li><a href="/categories/Network-Switching/">Network Switching<span>2</span></a></li>
		
			<li><a href="/categories/Network-communication/">Network communication<span>2</span></a></li>
		
			<li><a href="/categories/Networking/">Networking<span>8</span></a></li>
		
			<li><a href="/categories/Neural-Search-Engines/">Neural Search Engines<span>2</span></a></li>
		
			<li><a href="/categories/NeuralDiff/">NeuralDiff<span>2</span></a></li>
		
			<li><a href="/categories/Note-Syncing/">Note Syncing<span>2</span></a></li>
		
			<li><a href="/categories/Notes-and-Scripts-Backup/">Notes and Scripts Backup<span>2</span></a></li>
		
			<li><a href="/categories/Numpy/">Numpy<span>2</span></a></li>
		
			<li><a href="/categories/OCR-Techniques/">OCR Techniques<span>2</span></a></li>
		
			<li><a href="/categories/OCR-Tools/">OCR Tools<span>2</span></a></li>
		
			<li><a href="/categories/Online-Movies/">Online Movies<span>2</span></a></li>
		
			<li><a href="/categories/Online-Security-and-Privacy/">Online Security and Privacy<span>2</span></a></li>
		
			<li><a href="/categories/Online-Shopping/">Online Shopping<span>1</span></a></li>
		
			<li><a href="/categories/Online-Tools/">Online Tools<span>2</span></a></li>
		
			<li><a href="/categories/Online-security-and-privacy/">Online security and privacy<span>2</span></a></li>
		
			<li><a href="/categories/Open-source-Android-Automation/">Open-source Android Automation<span>2</span></a></li>
		
			<li><a href="/categories/Open-source-Chinese-Fonts/">Open-source Chinese Fonts<span>2</span></a></li>
		
			<li><a href="/categories/Open-source-Software/">Open-source Software<span>2</span></a></li>
		
			<li><a href="/categories/OpenCV/">OpenCV<span>2</span></a></li>
		
			<li><a href="/categories/Opqbot/">Opqbot<span>2</span></a></li>
		
			<li><a href="/categories/Optical-Flow-Techniques/">Optical Flow Techniques<span>2</span></a></li>
		
			<li><a href="/categories/Optimization-Techniques/">Optimization Techniques<span>2</span></a></li>
		
			<li><a href="/categories/Package-Management/">Package Management<span>4</span></a></li>
		
			<li><a href="/categories/Package-Managers/">Package Managers<span>2</span></a></li>
		
			<li><a href="/categories/Paraphrasing/">Paraphrasing<span>2</span></a></li>
		
			<li><a href="/categories/Password-Reset/">Password Reset<span>2</span></a></li>
		
			<li><a href="/categories/Payment-Systems/">Payment Systems<span>2</span></a></li>
		
			<li><a href="/categories/Platform-Tutorials/">Platform Tutorials<span>2</span></a></li>
		
			<li><a href="/categories/Playwright/">Playwright<span>2</span></a></li>
		
			<li><a href="/categories/Politics-and-Capitalism/">Politics and Capitalism<span>2</span></a></li>
		
			<li><a href="/categories/Probabilistic-Programming/">Probabilistic Programming<span>4</span></a></li>
		
			<li><a href="/categories/Process-Management/">Process Management<span>2</span></a></li>
		
			<li><a href="/categories/Process-Monitoring/">Process Monitoring<span>2</span></a></li>
		
			<li><a href="/categories/Producer-flags/">Producer flags<span>2</span></a></li>
		
			<li><a href="/categories/Product-Issues/">Product Issues<span>2</span></a></li>
		
			<li><a href="/categories/Programming/">Programming<span>4</span></a></li>
		
			<li><a href="/categories/Programming-Humor/">Programming Humor<span>2</span></a></li>
		
			<li><a href="/categories/Programming-Languages/">Programming Languages<span>8</span></a></li>
		
			<li><a href="/categories/Project-Planning/">Project Planning<span>2</span></a></li>
		
			<li><a href="/categories/Propagation-Science/">Propagation Science<span>2</span></a></li>
		
			<li><a href="/categories/Proxies/">Proxies<span>2</span></a></li>
		
			<li><a href="/categories/PyTorch/">PyTorch<span>3</span></a></li>
		
			<li><a href="/categories/Python/">Python<span>8</span></a></li>
		
			<li><a href="/categories/Python-Libraries/">Python Libraries<span>4</span></a></li>
		
			<li><a href="/categories/Python-Performance/">Python Performance<span>2</span></a></li>
		
			<li><a href="/categories/Python-Programming/">Python Programming<span>6</span></a></li>
		
			<li><a href="/categories/Python-Testing/">Python Testing<span>2</span></a></li>
		
			<li><a href="/categories/Python-Tools/">Python Tools<span>2</span></a></li>
		
			<li><a href="/categories/Python-programming/">Python programming<span>14</span></a></li>
		
			<li><a href="/categories/QQ-password/">QQ password<span>1</span></a></li>
		
			<li><a href="/categories/Quantitative-Trading-Platforms/">Quantitative Trading Platforms<span>2</span></a></li>
		
			<li><a href="/categories/Quantum-Computing/">Quantum Computing<span>2</span></a></li>
		
			<li><a href="/categories/RAM-Disk/">RAM Disk<span>2</span></a></li>
		
			<li><a href="/categories/RSS-Feeds-and-Aggregators/">RSS Feeds and Aggregators<span>2</span></a></li>
		
			<li><a href="/categories/RWKV-Language-Models/">RWKV Language Models<span>2</span></a></li>
		
			<li><a href="/categories/Radar-systems/">Radar systems<span>2</span></a></li>
		
			<li><a href="/categories/Random-Number-Generation/">Random Number Generation<span>2</span></a></li>
		
			<li><a href="/categories/Recaptcha-Solving-Solutions/">Recaptcha Solving Solutions<span>2</span></a></li>
		
			<li><a href="/categories/Recommendation-Algorithms/">Recommendation Algorithms<span>2</span></a></li>
		
			<li><a href="/categories/Recovery-USB/">Recovery USB<span>2</span></a></li>
		
			<li><a href="/categories/Rectangularization-Methods/">Rectangularization Methods<span>2</span></a></li>
		
			<li><a href="/categories/Redis/">Redis<span>2</span></a></li>
		
			<li><a href="/categories/Redis-py-library/">Redis-py library<span>2</span></a></li>
		
			<li><a href="/categories/Reinforcement-Learning/">Reinforcement Learning<span>4</span></a></li>
		
			<li><a href="/categories/Remote-Connection/">Remote Connection<span>2</span></a></li>
		
			<li><a href="/categories/Remote-Jobs/">Remote Jobs<span>2</span></a></li>
		
			<li><a href="/categories/Remote-Procedure-Call-Technologies/">Remote Procedure Call Technologies<span>2</span></a></li>
		
			<li><a href="/categories/Retry-Libraries/">Retry Libraries<span>2</span></a></li>
		
			<li><a href="/categories/Reverse-Engineering/">Reverse Engineering<span>4</span></a></li>
		
			<li><a href="/categories/Robotics/">Robotics<span>2</span></a></li>
		
			<li><a href="/categories/Royalty-free-video-sources/">Royalty-free video sources<span>2</span></a></li>
		
			<li><a href="/categories/SEO/">SEO<span>2</span></a></li>
		
			<li><a href="/categories/SQL-Injection-Attacks/">SQL Injection Attacks<span>2</span></a></li>
		
			<li><a href="/categories/SQLite-ORM/">SQLite ORM<span>2</span></a></li>
		
			<li><a href="/categories/SSH-keys/">SSH keys<span>2</span></a></li>
		
			<li><a href="/categories/Scraping/">Scraping<span>2</span></a></li>
		
			<li><a href="/categories/Search-Engine-Optimization/">Search Engine Optimization<span>2</span></a></li>
		
			<li><a href="/categories/Search-Engines/">Search Engines<span>6</span></a></li>
		
			<li><a href="/categories/Search-Methods/">Search Methods<span>2</span></a></li>
		
			<li><a href="/categories/Security/">Security<span>16</span></a></li>
		
			<li><a href="/categories/Security-Tools/">Security Tools<span>2</span></a></li>
		
			<li><a href="/categories/Semantic-Search/">Semantic Search<span>2</span></a></li>
		
			<li><a href="/categories/Session-Management/">Session Management<span>2</span></a></li>
		
			<li><a href="/categories/Short-URL-generators/">Short URL generators<span>2</span></a></li>
		
			<li><a href="/categories/Sketch-based-Applications/">Sketch-based Applications<span>2</span></a></li>
		
			<li><a href="/categories/Skin-Products-and-Diet/">Skin Products and Diet<span>2</span></a></li>
		
			<li><a href="/categories/Sleep/">Sleep<span>2</span></a></li>
		
			<li><a href="/categories/Smartwatches/">Smartwatches<span>4</span></a></li>
		
			<li><a href="/categories/Social-Media/">Social Media<span>2</span></a></li>
		
			<li><a href="/categories/Social-Media-Transformation/">Social Media Transformation<span>2</span></a></li>
		
			<li><a href="/categories/Software/">Software<span>4</span></a></li>
		
			<li><a href="/categories/Software-Security/">Software Security<span>2</span></a></li>
		
			<li><a href="/categories/Software-Testing-Efficiency-Metrics/">Software Testing Efficiency Metrics<span>2</span></a></li>
		
			<li><a href="/categories/Software-Tools/">Software Tools<span>2</span></a></li>
		
			<li><a href="/categories/Software-Troubleshooting/">Software Troubleshooting<span>6</span></a></li>
		
			<li><a href="/categories/Software-activation/">Software activation<span>2</span></a></li>
		
			<li><a href="/categories/Software-as-a-Service-SaaS/">Software as a Service (SaaS)<span>2</span></a></li>
		
			<li><a href="/categories/Software-troubleshooting/">Software troubleshooting<span>2</span></a></li>
		
			<li><a href="/categories/Sound-Effects/">Sound Effects<span>2</span></a></li>
		
			<li><a href="/categories/Speaker-Detection/">Speaker Detection<span>2</span></a></li>
		
			<li><a href="/categories/Speech-to-Text-Conversion/">Speech-to-Text Conversion<span>2</span></a></li>
		
			<li><a href="/categories/Stock-Data/">Stock Data<span>2</span></a></li>
		
			<li><a href="/categories/Stock-Market-Analysis/">Stock Market Analysis<span>2</span></a></li>
		
			<li><a href="/categories/Stock-Selection/">Stock Selection<span>2</span></a></li>
		
			<li><a href="/categories/Story-Dalle/">Story-Dalle<span>2</span></a></li>
		
			<li><a href="/categories/Synchronization/">Synchronization<span>2</span></a></li>
		
			<li><a href="/categories/System-Administration/">System Administration<span>2</span></a></li>
		
			<li><a href="/categories/System-Monitoring/">System Monitoring<span>2</span></a></li>
		
			<li><a href="/categories/Tab-Management/">Tab Management<span>2</span></a></li>
		
			<li><a href="/categories/Technology/">Technology<span>4</span></a></li>
		
			<li><a href="/categories/Technology-and-Innovation/">Technology and Innovation<span>2</span></a></li>
		
			<li><a href="/categories/Telegram-Bots/">Telegram Bots<span>1</span></a></li>
		
			<li><a href="/categories/Temperature-Management/">Temperature Management<span>2</span></a></li>
		
			<li><a href="/categories/TensorFlow-js/">TensorFlow.js<span>2</span></a></li>
		
			<li><a href="/categories/Tensorly-and-Torch-based-Liquid-State-Machine-for-Efficient-Data-Processing-of-Complex-Datasets-like-Brain-Neurons/">Tensorly and Torch-based Liquid State Machine for Efficient Data Processing of Complex Datasets like Brain Neurons<span>2</span></a></li>
		
			<li><a href="/categories/Terminal-autocomplete/">Terminal autocomplete<span>2</span></a></li>
		
			<li><a href="/categories/Termux/">Termux<span>6</span></a></li>
		
			<li><a href="/categories/Text-Editors/">Text Editors<span>2</span></a></li>
		
			<li><a href="/categories/Text-to-Speech/">Text to Speech<span>2</span></a></li>
		
			<li><a href="/categories/Text-to-Video-Projects/">Text-to-Video Projects<span>2</span></a></li>
		
			<li><a href="/categories/Throat-Care/">Throat Care<span>2</span></a></li>
		
			<li><a href="/categories/Time-Series-Analysis/">Time Series Analysis<span>2</span></a></li>
		
			<li><a href="/categories/Torrent-Search-Engines/">Torrent Search Engines<span>2</span></a></li>
		
			<li><a href="/categories/Training-Large-Language-Models/">Training Large Language Models<span>2</span></a></li>
		
			<li><a href="/categories/Trash-Management/">Trash Management<span>2</span></a></li>
		
			<li><a href="/categories/Troubleshooting/">Troubleshooting<span>16</span></a></li>
		
			<li><a href="/categories/Tutorial/">Tutorial<span>2</span></a></li>
		
			<li><a href="/categories/Unblocked-content/">Unblocked content<span>2</span></a></li>
		
			<li><a href="/categories/Unlocking-Bootloader/">Unlocking Bootloader<span>2</span></a></li>
		
			<li><a href="/categories/Video-Analysis/">Video Analysis<span>2</span></a></li>
		
			<li><a href="/categories/Video-Compression/">Video Compression<span>2</span></a></li>
		
			<li><a href="/categories/Video-Creation-Methods/">Video Creation Methods<span>2</span></a></li>
		
			<li><a href="/categories/Video-Downloaders/">Video Downloaders<span>4</span></a></li>
		
			<li><a href="/categories/Video-Downloading-Tools/">Video Downloading Tools<span>4</span></a></li>
		
			<li><a href="/categories/Video-Editing/">Video Editing<span>10</span></a></li>
		
			<li><a href="/categories/Video-Editing-Software/">Video Editing Software<span>4</span></a></li>
		
			<li><a href="/categories/Video-Editing-Tools/">Video Editing Tools<span>2</span></a></li>
		
			<li><a href="/categories/Video-Enhancement/">Video Enhancement<span>2</span></a></li>
		
			<li><a href="/categories/Video-Manipulation/">Video Manipulation<span>2</span></a></li>
		
			<li><a href="/categories/Video-Object-Tracking/">Video Object Tracking<span>2</span></a></li>
		
			<li><a href="/categories/Video-Processing/">Video Processing<span>8</span></a></li>
		
			<li><a href="/categories/Video-Production/">Video Production<span>2</span></a></li>
		
			<li><a href="/categories/Video-Quality-Assessment/">Video Quality Assessment<span>2</span></a></li>
		
			<li><a href="/categories/Video-Search/">Video Search<span>2</span></a></li>
		
			<li><a href="/categories/Video-Sharing-Platforms/">Video Sharing Platforms<span>2</span></a></li>
		
			<li><a href="/categories/Video-and-Audio-Processing/">Video and Audio Processing<span>2</span></a></li>
		
			<li><a href="/categories/Virtual-Environments/">Virtual Environments<span>2</span></a></li>
		
			<li><a href="/categories/Virtual-Reality/">Virtual Reality<span>1</span></a></li>
		
			<li><a href="/categories/Virtualization/">Virtualization<span>2</span></a></li>
		
			<li><a href="/categories/Visual-Studio-Code/">Visual Studio Code<span>2</span></a></li>
		
			<li><a href="/categories/Volume-Management/">Volume Management<span>2</span></a></li>
		
			<li><a href="/categories/Water-Cooling-Systems/">Water Cooling Systems<span>2</span></a></li>
		
			<li><a href="/categories/Wearable-Devices/">Wearable Devices<span>2</span></a></li>
		
			<li><a href="/categories/Web-Application-Security/">Web Application Security<span>6</span></a></li>
		
			<li><a href="/categories/Web-Applications/">Web Applications<span>4</span></a></li>
		
			<li><a href="/categories/Web-Customization/">Web Customization<span>2</span></a></li>
		
			<li><a href="/categories/Web-Development/">Web Development<span>4</span></a></li>
		
			<li><a href="/categories/Web-Scraping/">Web Scraping<span>14</span></a></li>
		
			<li><a href="/categories/Webhooks/">Webhooks<span>2</span></a></li>
		
			<li><a href="/categories/Webpage-Rendering/">Webpage Rendering<span>2</span></a></li>
		
			<li><a href="/categories/Website-Resources/">Website Resources<span>2</span></a></li>
		
			<li><a href="/categories/Wi-Fi-Troubleshooting/">Wi-Fi Troubleshooting<span>2</span></a></li>
		
			<li><a href="/categories/WiFi/">WiFi<span>1</span></a></li>
		
			<li><a href="/categories/Window-Management/">Window Management<span>4</span></a></li>
		
			<li><a href="/categories/Windows/">Windows<span>2</span></a></li>
		
			<li><a href="/categories/Windows-10-Performance/">Windows 10 Performance<span>2</span></a></li>
		
			<li><a href="/categories/Yoga/">Yoga<span>2</span></a></li>
		
			<li><a href="/categories/YouTube-Monetization/">YouTube Monetization<span>2</span></a></li>
		
			<li><a href="/categories/Zhihu/">Zhihu<span>2</span></a></li>
		
			<li><a href="/categories/anti-censorship/">anti-censorship<span>2</span></a></li>
		
			<li><a href="/categories/bilibili/">bilibili<span>2</span></a></li>
		
			<li><a href="/categories/book-scanning/">book scanning<span>2</span></a></li>
		
			<li><a href="/categories/brainwave-translation/">brainwave translation<span>2</span></a></li>
		
			<li><a href="/categories/copyright/">copyright<span>2</span></a></li>
		
			<li><a href="/categories/ctf-competitions/">ctf competitions<span>2</span></a></li>
		
			<li><a href="/categories/data-security/">data security<span>2</span></a></li>
		
			<li><a href="/categories/deobfustication/">deobfustication<span>2</span></a></li>
		
			<li><a href="/categories/filename-issues/">filename issues<span>2</span></a></li>
		
			<li><a href="/categories/fire-prevention/">fire_prevention<span>2</span></a></li>
		
			<li><a href="/categories/gaming/">gaming<span>2</span></a></li>
		
			<li><a href="/categories/hacking/">hacking<span>2</span></a></li>
		
			<li><a href="/categories/hardware-simulator/">hardware_simulator<span>2</span></a></li>
		
			<li><a href="/categories/iOS-device-control/">iOS device control<span>2</span></a></li>
		
			<li><a href="/categories/javascript/">javascript<span>2</span></a></li>
		
			<li><a href="/categories/macOS/">macOS<span>2</span></a></li>
		
			<li><a href="/categories/noise-generation/">noise_generation<span>2</span></a></li>
		
			<li><a href="/categories/npm/">npm<span>2</span></a></li>
		
			<li><a href="/categories/package-managers/">package_managers<span>2</span></a></li>
		
			<li><a href="/categories/podcasts/">podcasts<span>2</span></a></li>
		
			<li><a href="/categories/pwntools/">pwntools<span>2</span></a></li>
		
			<li><a href="/categories/search-engines/">search_engines<span>2</span></a></li>
		
			<li><a href="/categories/seo-tools/">seo_tools<span>2</span></a></li>
		
			<li><a href="/categories/strategies-for-defeating-deduplicate-algorithms/">strategies for defeating deduplicate algorithms<span>2</span></a></li>
		
			<li><a href="/categories/systemd/">systemd<span>2</span></a></li>
		
			<li><a href="/categories/text-mining/">text-mining<span>2</span></a></li>
		
			<li><a href="/categories/video-sites/">video_sites<span>2</span></a></li>
		
			<li><a href="/categories/viral-strategies/">viral_strategies<span>2</span></a></li>
		
			<li><a href="/categories/vulnerability-discovery/">vulnerability_discovery<span>1</span></a></li>
		
		</ul>
	</div>

		
			
	<div class="widget">
		<h4>Tag Cloud</h4>
		<ul class="tag_box inline list-unstyled">		
		
			<li><a href="/tags/MITM-attacks/">MITM attacks<span>2</span></a></li>
		
			<li><a href="/tags/Redis-LRU-cache-for-decorators/">Redis LRU cache for decorators<span>2</span></a></li>
		
			<li><a href="/tags/Implementation-Details/">Implementation Details<span>2</span></a></li>
		
			<li><a href="/tags/picture-enhancement/">picture enhancement<span>2</span></a></li>
		
			<li><a href="/tags/usage/">usage<span>2</span></a></li>
		
			<li><a href="/tags/Kdenlive/">Kdenlive<span>2</span></a></li>
		
			<li><a href="/tags/live-broadcast/">live broadcast<span>2</span></a></li>
		
			<li><a href="/tags/Ufw/">Ufw<span>2</span></a></li>
		
			<li><a href="/tags/Entertainment-Data/">Entertainment Data<span>2</span></a></li>
		
			<li><a href="/tags/NewSinaFinance-API/">NewSinaFinance API<span>2</span></a></li>
		
			<li><a href="/tags/jobs/">jobs<span>2</span></a></li>
		
			<li><a href="/tags/room/">room<span>2</span></a></li>
		
			<li><a href="/tags/open-source-software/">open source software<span>2</span></a></li>
		
			<li><a href="/tags/puby/">puby<span>2</span></a></li>
		
			<li><a href="/tags/libraries/">libraries<span>2</span></a></li>
		
			<li><a href="/tags/Nessus/">Nessus<span>2</span></a></li>
		
			<li><a href="/tags/sparse-matrix/">sparse matrix<span>2</span></a></li>
		
			<li><a href="/tags/OCR-recognition/">OCR recognition<span>2</span></a></li>
		
			<li><a href="/tags/TESPy/">TESPy<span>2</span></a></li>
		
			<li><a href="/tags/Themida/">Themida<span>2</span></a></li>
		
		
		   <li><a href="/tags">...<span>2367</span></a></li>
		 
		</ul>
	</div>


		
			
<div class="widget">
  <h4>Recent Posts</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2023/12/26/32219f38-dc6e-4219-8626-6f68d7f08772/"  title="A compilation of various projects related to Cybergod, which are clones from different GitHub repositories such as Q-Star, QStarLearning, open_qstar, Video-Pre-Training, SingularGPT, GPT-4V-Act, gpt-eyes, self-operating-computer, gpt4v-browsing, CogVLM, and AppAgent. These projects aim to develop various tools and models for diverse purposes within the Cybergod framework." ><i class="fa fa-file-o"></i>cybergod related projects</a>
      </li>
    
      <li>
        <a href="/2023/12/26/94043d9a-08e0-43ba-8c58-876d65a7f546/"  title="A compilation of various projects related to Cybergod, which are clones from different GitHub repositories such as Q-Star, QStarLearning, open_qstar, Video-Pre-Training, SingularGPT, GPT-4V-Act, gpt-eyes, self-operating-computer, gpt4v-browsing, CogVLM, and AppAgent. These projects aim to develop various tools and models for diverse purposes within the Cybergod framework." ><i class="fa fa-file-o"></i>cybergod related projects</a>
      </li>
    
      <li>
        <a href="/2023/12/22/001f5273-9edf-4108-8139-8035186da6ba/"  title="This text delves into the process of (de)obfustication, which encompasses techniques such as adding or removing redundant code and employing packers like Themida, Code Virtualizer, VMProtect, and ExeCryptor. The article furnishes details on a PDF and GitHub topics addressing protectors and junk code generators, along with a guide on utilizing IdA Pro for removing unnecessary code." ><i class="fa fa-file-o"></i>(de)obfustication, junk cod...</a>
      </li>
    
      <li>
        <a href="/2023/12/22/002a30c9-b48c-4035-8369-cf5265f8344a/"  title="RSIBreak is a smartwatch app designed to prevent RSI injuries. It is compatible with WearOS and Apple alternatives, offering customization options such as 3D printed cases from Shapeways or DIY solutions on macOS. Additionally, alternatives like BreakTimer are available for various platforms." ><i class="fa fa-file-o"></i>RSIBreak, Break Reminder</a>
      </li>
    
      <li>
        <a href="/2023/12/22/002dd458-e9b8-4128-abe7-7b11ec870fc7/"  title="The article discusses an open API for generating cat-themed content through the website &#39;cataas.com&#39;. This platform offers a range of options to create and personalize images featuring cats, making it an entertaining and engaging service." ><i class="fa fa-file-o"></i>开放api 信息来源</a>
      </li>
    
  </ul>
</div>

		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	

</div> <!-- row-fluid -->


    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2023 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->

  <script>
  marked.setOptions({
    highlight: function (code, lang) {
        return hljs.highlightAuto(code).value;
    }
  });
  function Highlighting(){
    var markdowns = document.getElementsByClassName('markdown');
    for(var i=0;i<markdowns.length;i++){
        if(markdowns[i].innerHTML) markdowns[i].innerHTML =marked(markdowns[i].innerHTML);
    }
  }
  window.addEventListener('DOMContentLoaded', Highlighting, false);
  window.addEventListener('load', Highlighting, false);
  </script>


</body>
</html>