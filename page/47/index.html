<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Page 47 | Blog of James Brown</title>
  <meta name="author" content="James Brown">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Blog of James Brown"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/blog/atom.xml" title="Blog of James Brown" type="application/atom+xml">
  
  
    <link href="/blog/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/css/themes/cerulean.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/blog/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/blog/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/blog/">Blog of James Brown</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/blog/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/blog/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      <div class="page-header page-header-inverse ">
  <h1 class="title title-inverse ">Blog of James Brown</h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		
<div class="slogan">
      <i class="fa fa-heart"></i>
      Autonomous Machines &amp; Society.
</div>


		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
        <!-- render top articles firstly -->
        
        <!-- render other articles -->
        
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-13 </div>
			<div class="article-title"><a href="/blog/2022/05/13/7aa059cd-4abf-4b43-acf1-f35f5aa93d77/" title="The VToonify framework offers a method for creating high-quality artistic portrait videos with a cartoon style, using StyleGAN layers and features to preserve frame details. It is compatible with existing image cartoonization models.">The Singing Bot</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="the-still-image-to-singing-face-bot-lip-sync-video-generation"><a href="#the-still-image-to-singing-face-bot-lip-sync-video-generation" class="headerlink" title="the still image to singing face bot, lip-sync video generation"></a>the still image to singing face bot, lip-sync video generation</h1><p>sadtalker</p>
<p>wombo.ai, likely to be talking head or yanderifier</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mchong6/GANsNRoses/">https://github.com/mchong6/GANsNRoses/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/williamyang1991/VToonify">https://github.com/williamyang1991/VToonify</a></p>
<p>生成高质量的艺术人像视频是计算机图形学和视觉中一项重要且理想的任务。虽然已经提出了一系列基于强大的 StyleGAN 成功的人像图像卡通化模型，但这些面向图像的方法在应用于视频时存在明显的局限性，在这项工作中，我们通过引入一种新颖的 VToonify 框架来研究具有挑战性的可控高分辨率肖像视频风格迁移。具体来说，VToonify 利用StyleGAN 的中高分辨率层基于编码器提取的多尺度内容特征来渲染高质量的艺术肖像，以更好地保留帧细节。作为输入，有助于输出具有自然运动的完整面部区域。 amework 与现有的基于 StyleGAN 的图像卡通化模型兼容，以将其扩展到视频卡通化，并继承了这些模型的吸引人的特性，可灵活地控制颜色和强度。这项工作展示了基于 Toonify 和 DualStyleGAN 的 VToonify 的两个实例，用于基于集合广泛的实验结果证明了我们提出的 VToonify 框架在生成具有灵活风格控制的高质量和时间连贯的艺术肖像视频方面优于现有方法的有效性</p>
<p>all in one colab text to talking face generation, also consider paddlespeech example:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ChintanTrivedi/ask-fake-ai-karen">https://github.com/ChintanTrivedi/ask-fake-ai-karen</a></p>
<p>avaliable from paddlegan as an example used in paddlespeech, the artificial host.</p>
<p>lip-sync accurate wav2lip:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Rudrabha/Wav2Lip">https://github.com/Rudrabha/Wav2Lip</a></p>
<p>lipgan generate realistic lip-sync talking head animation(fully_pythonic branch or google colab notebook):</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Rudrabha/LipGAN">https://github.com/Rudrabha/LipGAN</a></p>
<p>google’s lipsync implementation, using tensorflow facemesh:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/google/lipsync">https://github.com/google/lipsync</a></p>
<p><a target="_blank" rel="noopener" href="https://lipsync.withyoutube.com/">https://lipsync.withyoutube.com/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tensorflow/tfjs-models/tree/master/facemesh">https://github.com/tensorflow/tfjs-models/tree/master/facemesh</a></p>
<p>network reverse engineering for wombo.ai:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/the-garlic-os/wombo-reverse-engineering">https://github.com/the-garlic-os/wombo-reverse-engineering</a></p>
<p>matamata using vosk models, recommend to use gentle lip-sync method:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/AI-Spawn/Auto-Lip-Sync">https://github.com/AI-Spawn/Auto-Lip-Sync</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Matamata-Animator/Matamata-Core">https://github.com/Matamata-Animator/Matamata-Core</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Yey007/Auto-Lip-Sync">https://github.com/Yey007/Auto-Lip-Sync</a></p>
<p>ai-based lip reading might be irrelevant to lip-sync video generation:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/eflood23/lipsync">https://github.com/eflood23/lipsync</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/13/7aa059cd-4abf-4b43-acf1-f35f5aa93d77/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-13 </div>
			<div class="article-title"><a href="/blog/2022/05/13/ad54ad82-1316-4bf0-8d5b-9dc82537d356/" title="This article explores tactics for creating viral content by merging videos and essays, targeting the largest audience through native languages. It recommends sharing this content on platforms like QQ using images or links.">Attractive Dynamic Plus Attractive Video</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<p>Some contents are viral to the users. Will add extra watches if combined with related video or essay.</p>
<p>May apply the same rule to other platforms. Must select those with largest views, or verified by trained grading models. Native language only, or we have to translate and verify&#x2F;convey it into native form. Post it to QQ, other platforms in the form of pictures, links.</p>

	
	</div>
  <a type="button" href="/blog/2022/05/13/ad54ad82-1316-4bf0-8d5b-9dc82537d356/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-11 </div>
			<div class="article-title"><a href="/blog/2022/05/11/fcdd7d7c-f812-421e-9c96-67407ebe73d3/" title="The article discusses a method for detecting and segregating anime heads through processes such as object detection, segmentation, and their potential use in facial recognition. Additionally, it explores the possibility of analyzing character attributes including position, clothing type, gender, and subtitle recognition.">Anime Smile Detection_ Segmentation</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="Anime-smile-detection-segmentation"><a href="#Anime-smile-detection-segmentation" class="headerlink" title="Anime smile detection&#x2F; segmentation"></a>Anime smile detection&#x2F; segmentation</h1><p>when an anime head is detected, cut it out and create dataset with labels. may augmented it with grayscale or edge detection.</p>
<p>segmentation using labeled data and train it on pretrained models. using anme head detection as double verification. no double heads.</p>
<p>ppse recognition may be applied without further training, or else.</p>
<p>我分析需要YOLO确定人物位置 CNN判断服装类型 人物性别 ocr识别字幕 音频分析识别语气 性别 音乐类型 再用seq2seq来把所有的输出概括成我的描述</p>
<p>或者看看有没有文字转关键词的模型</p>
<p>可以的话加上人物姿态估计 动漫人物的</p>
<p>关于光流算法：</p>
<p>熵就是梯度的标准差</p>
<p>一段范围的熵就是起始时间到末尾的熵的标准差</p>
<p>或者起始到末尾的梯度的标准差</p>

	
	</div>
  <a type="button" href="/blog/2022/05/11/fcdd7d7c-f812-421e-9c96-67407ebe73d3/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-11 </div>
			<div class="article-title"><a href="/blog/2022/05/11/de7d44f0-f3ae-4336-a009-64d75fbadd20/" title="This article discusses various audio and music recognition tools like audioFlux, inaSpeechSegmenter, Mousai, Music Emotion Recognition, Picard, AcoustID, MixingBear, madmom, pyaudioanalysis, MUSIC21, urbanSound8k dataset, MeowDetector, and more. It also mentions using QQ Music&#39;s recognition engine for domestic audio identification and Premier plugins for categorizing humorous videos based on music structure.">踩点 音乐识别</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="踩点-音乐识别-搞笑视频收集"><a href="#踩点-音乐识别-搞笑视频收集" class="headerlink" title="踩点 音乐识别 搞笑视频收集"></a>踩点 音乐识别 搞笑视频收集</h1><p>now we have <a target="_blank" rel="noopener" href="https://github.com/libAudioFlux/audioFlux">audioFlux</a>, alternative to librosa, but faster</p>
<hr>
<p>audioowl for tempo, beat and notes identification:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/dodiku/AudioOwl">https://github.com/dodiku/AudioOwl</a></p>
<p>cnn based audio segmentation toolkit allow to detect speech, music and speaker gender:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ina-foss/inaSpeechSegmenter">https://github.com/ina-foss/inaSpeechSegmenter</a></p>
<p>speech music detection using keras:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/qlemaire22/speech-music-detection">https://github.com/qlemaire22/speech-music-detection</a></p>
<p>awesome deep learning music:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ybayle/awesome-deep-learning-music">https://github.com/ybayle/awesome-deep-learning-music</a></p>
<p>music genre classification&#x2F; Music Classification&#x2F; Music Recommendation&#x2F; Music search</p>
<p><a target="_blank" rel="noopener" href="https://github.com/mlachmish/MusicGenreClassification">https://github.com/mlachmish/MusicGenreClassification</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/kristijanbartol/Deep-Music-Tagger">https://github.com/kristijanbartol/Deep-Music-Tagger</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/tae-jun/resemul">https://github.com/tae-jun/resemul</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Insiyaa/Music-Genre-Classification">https://github.com/Insiyaa/Music-Genre-Classification</a></p>
<p>music recognization service:</p>
<p>audioid soundhound</p>
<p>maybe you should consider some chinese tools? none there.</p>
<p>music radar recognize music:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/keshavbhatt/music-radar">https://github.com/keshavbhatt/music-radar</a></p>
<p>mousai using free audd api to recognize music:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/SeaDve/Mousai">https://github.com/SeaDve/Mousai</a></p>
<p>music emotion recognization:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/SeungHeonDoh/Music_Emotion_Recognition">https://github.com/SeungHeonDoh/Music_Emotion_Recognition</a></p>
<p>music tagging and recognization, using acoustic ids and community based music database:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/metabrainz/picard">https://github.com/metabrainz/picard</a></p>
<p><a target="_blank" rel="noopener" href="https://musicbrainz.org/doc/AcoustID">https://musicbrainz.org/doc/AcoustID</a></p>
<p>mixingbear(alike neuralmix):</p>
<p><a target="_blank" rel="noopener" href="https://github.com/dodiku/MixingBear">https://github.com/dodiku/MixingBear</a></p>
<p>madmom</p>
<p><a target="_blank" rel="noopener" href="https://github.com/CPJKU/madmom">https://github.com/CPJKU/madmom</a></p>
<p><a target="_blank" rel="noopener" href="http://madmom.readthedocs.org/">http://madmom.readthedocs.org</a></p>
<p>音乐分类 综合音频分析包</p>
<p>pyaudioanalysis</p>
<p>mathematica audio slience removal segmentation:</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/43165678">https://zhuanlan.zhihu.com/p/43165678</a></p>
<p>music21 for music recognition:</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/35140033">https://zhuanlan.zhihu.com/p/35140033</a></p>
<p>music21 for midi analysis:</p>
<p><a target="_blank" rel="noopener" href="https://pypi.org/project/music21/">https://pypi.org/project/music21/</a></p>
<p><a target="_blank" rel="noopener" href="https://music21.readthedocs.io/en/latest">https://music21.readthedocs.io/en/latest</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/73564852">https://zhuanlan.zhihu.com/p/73564852</a></p>
<p>sound recognition and localization:</p>
<p><a target="_blank" rel="noopener" href="https://reality.ai/automotive-sound-recognition-localization/">https://reality.ai/automotive-sound-recognition-localization/</a></p>
<p>urbansound8k dataset ( 6gb ):</p>
<p><a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/chrisfilo/urbansound8k">https://www.kaggle.com/datasets/chrisfilo/urbansound8k</a></p>
<p>fourier transform cat meow detection:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/EricDavidWells/MeowDetector">https://github.com/EricDavidWells/MeowDetector</a></p>
<p>building sound event classifier:</p>
<p><a target="_blank" rel="noopener" href="https://ignitarium.com/building-an-ai-based-sound-event-classifier/">https://ignitarium.com/building-an-ai-based-sound-event-classifier/</a></p>
<p>real time continuous sound event classification(usually via silence detection):</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e">https://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e</a></p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e">https://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e</a></p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@chathuranga.15/sound-event-classification-using-machine-learning-8768092beafc">https://medium.com/@chathuranga.15/sound-event-classification-using-machine-learning-8768092beafc</a></p>
<p>cry detection:</p>
<p><a target="_blank" rel="noopener" href="https://www.amberou.com/cry-detection">https://www.amberou.com/cry-detection</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/umangkk5/Infant-Cry-Detection-System/blob/master/site-packages/soundfile.py">https://github.com/umangkk5/Infant-Cry-Detection-System/blob/master/site-packages/soundfile.py</a></p>
<p>urbansound classifier:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/awln/urban8k-audio-classifier">https://github.com/awln/urban8k-audio-classifier</a></p>
<p>laugh detection:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ideo/LaughDetection">https://github.com/ideo/LaughDetection</a></p>
<p>gun shot detection:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/hasnainnaeem/Gunshot-Detection-in-Audio">https://github.com/hasnainnaeem/Gunshot-Detection-in-Audio</a></p>
<p>dog bark detector:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/t04glovern/dog-bark-detection">https://github.com/t04glovern/dog-bark-detection</a></p>
<p><a target="_blank" rel="noopener" href="https://devopstar.com/2020/04/13/dog-bark-detector-machine-learning-model">https://devopstar.com/2020/04/13/dog-bark-detector-machine-learning-model</a></p>
<p><a target="_blank" rel="noopener" href="https://dsp.stackexchange.com/questions/23466/detect-dog-barks">https://dsp.stackexchange.com/questions/23466/detect-dog-barks</a></p>
<p>获得音乐识别api 最好是qq音乐识别 国内识别引擎</p>
<p>不能识别就分析简介 有没有BGM</p>
<p>踩点 bpm以前的autoup项目里有 看看其他的分析软件有没有 premiere一键踩点插件可能有开源库支持</p>
<p>已有的踩点视频 可以切出无文字的片段 根据音乐结构区分高潮 开始 中间等部分 根据音乐类型标签归类视频</p>
<p>搞笑视频的话 有纯笑声比较好 动作幅度大的 不要有对话 反向截图 收集类似视频</p>

	
	</div>
  <a type="button" href="/blog/2022/05/11/de7d44f0-f3ae-4336-a009-64d75fbadd20/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-10 </div>
			<div class="article-title"><a href="/blog/2022/05/10/dda8d689-7017-4fdf-ba01-6b42b0aca3a5/" title="This article discusses various methods and tools for converting audio files to MIDI format, including COCA, audio classifiers, and taggers. It compares different audio-to-MIDI converter tools such as Polyphonic_track, audioToMidiConverter, PitchToMIDI, Tony, MusicTranscription, pYIN, Spleeter, and Musisep to transcribe polyphonic audio into MIDI format.">Video Cutting With Captioners, Video Classifiers, Audio Classifier, Audio Categorizer</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<p>you can cut based on video highlights, usually generated by counting “replay overlaps”, avaliable from youtube and bilibili, again needs supervised learning to recognize patterns and emit signals which we want</p>
<p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/CoCa-pytorch">COCA</a> using vit and palm for video captioning</p>
<p><a target="_blank" rel="noopener" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01/">audio classifier tutorial</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/AlexUserForVA/AudioTagger">audio tagger</a> visualize how audio classifier works</p>
<p>need to identify sounds like dog bark and gun shots, sobs, laughs. Open sourced.</p>
<p>May use sound analyzers.</p>
<p>audio2midi:</p>
<p><a target="_blank" rel="noopener" href="https://gist.github.com/natowi/d26c7e97443ec97e8032fb7e7596f0b0">https://gist.github.com/natowi/d26c7e97443ec97e8032fb7e7596f0b0</a></p>
<p>Recurrent Neural Network for generating piano MIDI-files from audio (MP3, WAV, etc.)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/BShakhovsky/PolyphonicPianoTranscription">https://github.com/BShakhovsky/PolyphonicPianoTranscription</a></p>
<p>A python program which performs an FFT on an audio file and produces a MIDI file from the results</p>
<p><a target="_blank" rel="noopener" href="https://github.com/NFJones/audio-to-midi">https://github.com/NFJones/audio-to-midi</a></p>
<p>Extract the melody from an audio file and export to MIDI</p>
<p><a target="_blank" rel="noopener" href="https://github.com/justinsalamon/audio_to_midi_melodia">https://github.com/justinsalamon/audio_to_midi_melodia</a></p>
<p>Performs pitch detection on a polyphonic audio source and outputs to MIDI</p>
<p><a target="_blank" rel="noopener" href="https://github.com/corbanbrook/spectrotune">https://github.com/corbanbrook/spectrotune</a></p>
<p>Program to detect pitch from wav files and write in time quantized MIDI</p>
<p><a target="_blank" rel="noopener" href="https://github.com/vaibhavnayel/Audio-to-MIDI-converter">https://github.com/vaibhavnayel/Audio-to-MIDI-converter</a></p>
<p>A CNN which converts piano audio to a simplified MIDI format</p>
<p><a target="_blank" rel="noopener" href="https://github.com/hartmetzls/audio_to_midi">https://github.com/hartmetzls/audio_to_midi</a></p>
<p>An application of vocal melody extraction.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/bill317996/Audio-to-midi">https://github.com/bill317996/Audio-to-midi</a></p>
<p>Transcribes polyphonic piano pieces from audio (MP3, WAV, etc.) into MIDI-files</p>
<p><a target="_blank" rel="noopener" href="https://github.com/BShakhovsky/PianoAudioToMidi">https://github.com/BShakhovsky/PianoAudioToMidi</a></p>
<p>Polyphonic pitch tracking in real time using machine learning algorithms</p>
<p><a target="_blank" rel="noopener" href="https://github.com/jaym910/polyphonic_track">https://github.com/jaym910/polyphonic_track</a></p>
<p>Audio to MIDI converter</p>
<p><a target="_blank" rel="noopener" href="https://github.com/sbaeunker/audioToMidiConverter">https://github.com/sbaeunker/audioToMidiConverter</a></p>
<p>Explore Transcribing Techniques to auto convert audio to midi</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Goldspear/audio2midi">https://github.com/Goldspear/audio2midi</a></p>
<p>PitchToMIDI</p>
<p><a target="_blank" rel="noopener" href="https://github.com/KatoIppei/PitchToMIDI">https://github.com/KatoIppei/PitchToMIDI</a> See releases</p>
<p>Piano &amp; Drums</p>
<p><a target="_blank" rel="noopener" href="https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription">https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription</a></p>
<p>Tony: a tool for melody transcription</p>
<p><a target="_blank" rel="noopener" href="https://www.sonicvisualiser.org/tony/">https://www.sonicvisualiser.org/tony/</a> <a target="_blank" rel="noopener" href="https://github.com/sonic-visualiser/tony">https://github.com/sonic-visualiser/tony</a> <a target="_blank" rel="noopener" href="https://code.soundsoftware.ac.uk/projects/tony">https://code.soundsoftware.ac.uk/projects/tony</a> (<a target="_blank" rel="noopener" href="https://github.com/mikulas-mrva/tony2max">https://github.com/mikulas-mrva/tony2max</a>)</p>
<p>MusicTranscription</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ClaraBing/CS229-MusicTranscription">https://github.com/ClaraBing/CS229-MusicTranscription</a></p>
<p>pYIN</p>
<p><a target="_blank" rel="noopener" href="https://code.soundsoftware.ac.uk/projects/pyin">https://code.soundsoftware.ac.uk/projects/pyin</a> <a target="_blank" rel="noopener" href="https://github.com/ronggong/pypYIN">https://github.com/ronggong/pypYIN</a> (python)</p>
<p>Onsets and Frames Transcription (Piano &amp; Drums)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription">https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription</a> <a target="_blank" rel="noopener" href="https://piano-scribe.glitch.me/">https://piano-scribe.glitch.me/</a></p>
<p>WaoN</p>
<p><a target="_blank" rel="noopener" href="https://sourceforge.net/projects/waon/">https://sourceforge.net/projects/waon/</a></p>
<p>audio2midi conversion works great with prior source separation <a target="_blank" rel="noopener" href="https://github.com/deezer/spleeter">https://github.com/deezer/spleeter</a> or others like <a target="_blank" rel="noopener" href="https://github.com/rgcda/Musisep">https://github.com/rgcda/Musisep</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/10/dda8d689-7017-4fdf-ba01-6b42b0aca3a5/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-09 </div>
			<div class="article-title"><a href="/blog/2022/05/09/3a3ef73e-a3b4-47f8-8493-ac570d5c6667/" title="Video Anticensor for Bilibili Tarot is an AI-powered tool that enhances images through various techniques, such as colorization, style transfer, glitch effects, and more. It transforms grayscale images into colorful masterpieces by applying dithering, chroma shift, overlays, and filters, making it a versatile solution for content creators on Bilibili.">Video Anticensor</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="Video-Anticensor-For-Bilibili-Tarot"><a href="#Video-Anticensor-For-Bilibili-Tarot" class="headerlink" title="Video Anticensor For Bilibili Tarot"></a>Video Anticensor For Bilibili Tarot</h1><p><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/1161285?channelType=0&channel=0">paddlegan</a> coloring images</p>
<p>could use p5 to do part of the job.</p>
<p>video:</p>
<p>style transfer</p>
<p>glitch</p>
<p>picture to sketch -&gt; ai painting</p>
<p>grayscale -&gt; ai coloring</p>
<p>dithering</p>
<p>chroma shift(hue)</p>
<p>(gradient&#x2F;video) overlay</p>
<p>dashing&#x2F;filtering, could be done in 2 frames or more</p>
<p>random pixel noise</p>
<p>text:</p>
<p>inverted canny edge</p>
<p>handwritten font</p>
<p>italic</p>
<p>pixelize, blur</p>
<p>boxing texts</p>
<p>slashing texts</p>
<p>rotating texts (30 degree?)</p>
<p>coloring texts</p>
<p>different font size</p>
<p>(randomly) censor words into letters</p>
<p>reshape (decrese height or width)</p>
<p>audio:</p>
<p>vocoder</p>
<p>style change</p>
<p>pitch change</p>

	
	</div>
  <a type="button" href="/blog/2022/05/09/3a3ef73e-a3b4-47f8-8493-ac570d5c6667/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-09 </div>
			<div class="article-title"><a href="/blog/2022/05/09/3452de1f-29a3-4a1a-839f-b2033860292a/" title="AI-based code generation tools like CodeGeeX, a free version of Copilot/Codex, are gaining attention for their features such as translation and support for VSCode plugins.">Copilot_Codex Alternative</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<h1 id="Copilot-Codex-alternative"><a href="#Copilot-Codex-alternative" class="headerlink" title="Copilot&#x2F;Codex alternative"></a>Copilot&#x2F;Codex alternative</h1><p>use chatgpt instead, when it is free.</p>
<p>tsinghua (again!) introduced a similar open source model called <a target="_blank" rel="noopener" href="https://github.com/THUDM/CodeGeeX">codegeex</a>, having better performance than <a target="_blank" rel="noopener" href="https://github.com/dpfried/incoder">incoder</a> (by meta) and codegen with vscode plugin support, able to generate and <strong>translate</strong> code. the info is found on <a target="_blank" rel="noopener" href="https://tuna.moe/events/">tuna events</a> and you can download video&#x2F;scripts for some events. trained on <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/THUDM/humaneval-x">humaneval-x</a> dataset for code generation. it also provides <a target="_blank" rel="noopener" href="https://tuna.moe/blog/">blog</a> and <a target="_blank" rel="noopener" href="https://podcast.tuna.moe/">podcast</a></p>
<p>Codegen</p>
<p><a target="_blank" rel="noopener" href="https://github.com/salesforce/CodeGen">https://github.com/salesforce/CodeGen</a></p>
<p>copilot self-hosted powered by codegen (lots of vram, maybe for mac studio 128gb, however it only supports nvidia gpu):</p>
<p><a target="_blank" rel="noopener" href="https://github.com/moyix/fauxpilot">https://github.com/moyix/fauxpilot</a></p>
<p>code autocomplete</p>
<p><a target="_blank" rel="noopener" href="https://github.com/shibing624/code-autocomplete">https://github.com/shibing624/code-autocomplete</a></p>
<p>codegpt python token completion</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/mrm8488/CodeGPT-small-finetuned-python-token-completion">https://huggingface.co/mrm8488/CodeGPT-small-finetuned-python-token-completion</a></p>
<p>codegpt</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/microsoft/CodeGPT-small-py-adaptedGPT2">https://huggingface.co/microsoft/CodeGPT-small-py-adaptedGPT2</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/microsoft/CodeGPT-small-py">https://huggingface.co/microsoft/CodeGPT-small-py</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/microsoft/CodeXGLUE/issues/75">https://github.com/microsoft/CodeXGLUE/issues/75</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/microsoft/CodeXGLUE/issues/36">https://github.com/microsoft/CodeXGLUE/issues/36</a></p>
<p>codebert</p>
<p><a target="_blank" rel="noopener" href="https://github.com/microsoft/CodeBERT">https://github.com/microsoft/CodeBERT</a></p>
<p>code-gpt-neox</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Linyxus/code-gpt-neox">https://github.com/Linyxus/code-gpt-neox</a></p>
<p>Captain Stack</p>
<p><a target="_blank" rel="noopener" href="https://github.com/hieunc229/copilot-clone">https://github.com/hieunc229/copilot-clone</a></p>
<p>clara</p>
<p><a target="_blank" rel="noopener" href="https://github.com/badboysm890/clara-copilot">https://github.com/badboysm890/clara-copilot</a></p>
<p>gpt-code-clippy</p>
<p><a target="_blank" rel="noopener" href="https://github.com/CodedotAl/code-clippy-vscode">https://github.com/CodedotAl/code-clippy-vscode</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/ncoop57/gpt-code-clippy">https://github.com/ncoop57/gpt-code-clippy</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/CodedotAl/gpt-code-clippy">https://github.com/CodedotAl/gpt-code-clippy</a></p>
<p><a target="_blank" rel="noopener" href="https://discuss.huggingface.co/t/pretrain-gpt-neo-for-open-source-github-copilot-model/7678?u=ncoop57">https://discuss.huggingface.co/t/pretrain-gpt-neo-for-open-source-github-copilot-model/7678?u=ncoop57</a></p>
<p><a target="_blank" rel="noopener" href="https://gpt3demo.com/apps/gpt-code-clippy-gpt-cc">https://gpt3demo.com/apps/gpt-code-clippy-gpt-cc</a></p>
<p><a target="_blank" rel="noopener" href="https://seart-ghs.si.usi.ch/">https://seart-ghs.si.usi.ch/</a> (github search engine)</p>
<p>kite</p>
<p><a target="_blank" rel="noopener" href="https://kite.com/integrations/jupyter/">https://kite.com/integrations/jupyter/</a></p>
<p>second mate</p>
<p><a target="_blank" rel="noopener" href="https://github.com/samrawal/emacs-secondmate">https://github.com/samrawal/emacs-secondmate</a></p>
<p>asm dude</p>
<p><a target="_blank" rel="noopener" href="https://github.com/HJLebbink/asm-dude">https://github.com/HJLebbink/asm-dude</a></p>
<p>youcompleteme</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ycm-core/YouCompleteMe">https://github.com/ycm-core/YouCompleteMe</a></p>
<p>code-lms(polycoder)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/VHellendoorn/Code-LMs#models">https://github.com/VHellendoorn/Code-LMs#models</a></p>
<p><a target="_blank" rel="noopener" href="https://zenodo.org/record/6363556">https://zenodo.org/record/6363556</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/09/3452de1f-29a3-4a1a-839f-b2033860292a/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-07 </div>
			<div class="article-title"><a href="/blog/2022/05/07/f7c45c1f-982e-41ca-bf82-1d4f37499b71/" title="The &#39;Pyjom Producer&#39; is a process designed for analyzing audio and video separately. Audio can be processed in chunks or split tracks, allowing for more efficient analysis. However, to analyze the video, it needs to be iterated frame by frame.">pyjom producer</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<p>video and audio needs to be analysised separately.</p>
<p>audio can be processed by chunks, splited tracks, while video can be itered frame by frame.</p>

	
	</div>
  <a type="button" href="/blog/2022/05/07/f7c45c1f-982e-41ca-bf82-1d4f37499b71/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-06 </div>
			<div class="article-title"><a href="/blog/2022/05/06/828d50cf-9486-4c4a-a8b2-3cbc4b6c9690/" title="This text provides a solution for accessing the Linux command line (tty) when Xorg fails. It describes how to boot into the command line by entering &#39;3&#39; after the longest line of boot commands, and suggests using SSH to collect logs even if there are interface issues.">Boot Into Linux Commandline (Tty)</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<p>when xorg fails, one must use commandline to debug problems.</p>
<p>put ‘3’ after the longest line of boot commands.</p>
<p>use ssh to collect logs even if the main interface is stuck somehow (like libinput faliure)</p>
<p>reference:</p>
<p><a target="_blank" rel="noopener" href="https://www.linuxandubuntu.com/home/how-to-boot-into-linux-command-line/amp">https://www.linuxandubuntu.com/home/how-to-boot-into-linux-command-line/amp</a></p>

	
	</div>
  <a type="button" href="/blog/2022/05/06/828d50cf-9486-4c4a-a8b2-3cbc4b6c9690/#more" class="btn btn-default more">Read More</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-05-06 </div>
			<div class="article-title"><a href="/blog/2022/05/06/9db1c565-9e79-4d67-a377-e5ddea7ced05/" title="This article provides a solution to troubleshoot input issues with the libwacom library on Arch Linux ARM and Kali Linux. The article suggests modifying the xorg.conf file as referenced in a troubleshooting guide for resolution.">Letsketch Libwacom</a></div>
		</h3>
	


			  
<div class="entry">

  <div class="row">
	
	
		<p>working on archlinux arm:</p>
<p>libwacom 2.1.0-1</p>
<p>not working on kali linux:</p>
<p>libwacom-bin 2.2.0-1</p>
<p>full reference:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/DIGImend/digimend-kernel-drivers/issues/514">https://github.com/DIGImend/digimend-kernel-drivers/issues/514</a></p>
<p>sudo nano &#x2F;etc&#x2F;X11&#x2F;xorg.conf</p>
<p>Section “InputClass”</p>
<p>Identifier “Tablet”</p>
<p>Driver “wacom”</p>
<p>MatchDevicePath “&#x2F;dev&#x2F;input&#x2F;event*”</p>
<p>MatchUSBID “6161:4d15”</p>
<p>EndSection</p>
<p>to debug input problems:</p>
<p><a target="_blank" rel="noopener" href="https://wiki.ubuntu.com/DebuggingMouseDetection#:~:text=In%20case%20your%20mouse%20stops%20working%20after%20a,your%20mouse%20stops%20working.%20...%20More%20items...%20">https://wiki.ubuntu.com/DebuggingMouseDetection#:~:text=In%20case%20your%20mouse%20stops%20working%20after%20a,your%20mouse%20stops%20working.%20...%20More%20items...%20</a></p>
<p>check &#x2F;etc&#x2F;logs&#x2F;Xorg.0.logs</p>

	
	</div>
  <a type="button" href="/blog/2022/05/06/9db1c565-9e79-4d67-a377-e5ddea7ced05/#more" class="btn btn-default more">Read More</a>
</div>

           
		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">
<ul class="pagination">
	 
		
		<li class="prev"><a href="/blog/page/46/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i> Prev</a></li>
  		

        <li><a href="/blog/"><i class="fa fa-home"></i>Home</a></li>

		
		   <li class="next"> <a href="/blog/page/48/" class="alignright next">Next<i class="fa fa-arrow-circle-o-right"></i></a> </li>
        
	
</ul>
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="Search" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/agi_computer_control/" title="Autonomous computer agent" target="_blank"]);">Project Cybergod</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media content automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/prometheous/" title="Automated documentation, AI+IR(RAG)" target="_blank"]);">Project Prometheus</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/pyjom/" title="Media Content Automation" target="_blank"]);">Project Pyjom</a></li>
	
		<li><i class="fa fa-github"></i><a href="https://github.com/james4ever0/my_blog_source/" title="Source code of my blog"" target="_blank"]);">Blog Source Code</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/james4ever0" title="My Github account" target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://samoyedsun.github.io/" title="Samoyedsun's Blog" target="_blank"]);">Samoyedsun&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://atlant1c.cn/" title="Atlant1c's Blog" target="_blank"]);">Atlant1c&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://www.gregoryuan.com/" title="Gregoryuan's Blog" target="_blank"]);">Gregoryuan&#39;s Blog</a></li>
	
		<li><i class="fa fa-book"></i><a href="https://yubingtao.netlify.app/" title="Yubingtao's Blog" target="_blank"]);">Yubingtao&#39;s Blog</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	

</div> <!-- row-fluid -->


    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2024 James Brown
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/blog/js/jquery.imagesloaded.min.js"></script>
<script src="/blog/js/gallery.js"></script>
<script src="/blog/js/bootstrap.min.js"></script>
<script src="/blog/js/main.js"></script>
<script src="/blog/js/search.js"></script> 


<link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/blog/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/blog/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


</body>
</html>